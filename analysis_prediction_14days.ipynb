{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import math \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/Desktop/analysis/code\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/wuyue/Desktop/analysis/stock/\"\n",
    "files = os.listdir(path)\n",
    "valid_file = []\n",
    "\n",
    "for file in files:\n",
    "    if file[-4:] == \".csv\":\n",
    "        valid_file.append(file)\n",
    "        \n",
    "print (len(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the fuctions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sign of a number\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    else:\n",
    "        return (0)\n",
    "    \n",
    "  \n",
    "def sgn_0(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    if x < 0:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "# the number of pos and neg in a list determine the general trend\n",
    "def sgn_num(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += 1\n",
    "        if i <= 0:\n",
    "            ne += 1\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)    \n",
    "\n",
    "# the value of pos and neg sum determine the \n",
    "def sgn_total(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += i\n",
    "        if i <= 0:\n",
    "            ne += abs(i)\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "def sqrt_abs(x):\n",
    "    if x > 0:\n",
    "        return math.log(x, 10)\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -math.log(abs(x), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_split(l, m):\n",
    "    n = int(math.ceil(len(l)/float(m)))\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def mix(l):\n",
    "    res_sum = []\n",
    "    for i in range(0, len(l[0])):\n",
    "        res = []\n",
    "        for lst in l:\n",
    "            res.append(lst[i])\n",
    "        res_sum.append(res)\n",
    "    return res_sum\n",
    "\n",
    "def cut(l, n):\n",
    "    res = []\n",
    "    for i in range(0, n):\n",
    "        res.append(l[i::n])\n",
    "    return res\n",
    "\n",
    "def slic(l, n, m):\n",
    "    res = []\n",
    "    for i in range (1, n+1):\n",
    "        res.append(l[60*i+1:60*i+m+1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n",
      "31.101278116666666 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "training_data_total = []\n",
    "training_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_part = open_price[-700:]\n",
    "            open_price_list = open_price[-700:-100]\n",
    "            open_price_list_split = chunks(open_price_list, 60)\n",
    "            open_price_list_testing = open_price[-100:]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_part = high_price[-700:]\n",
    "            high_price_list = high_price[-700:-100]\n",
    "            high_price_list_split = chunks(high_price_list, 60)\n",
    "            high_price_list_testing = high_price[-100:]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_part = low_price[-700:]\n",
    "            low_price_list = low_price[-700:-100]\n",
    "            low_price_list_split = chunks(low_price_list, 60)\n",
    "            low_price_list_testing = low_price[-100:]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_part = close_price[-700:]\n",
    "            close_price_list = close_price[-700:-100]\n",
    "            close_price_list_split = chunks(close_price_list, 60)\n",
    "            close_price_list_testing = close_price[-100:]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_part = volume[-700:]\n",
    "            volume_list = volume[-700:-100]\n",
    "            volume_list_split = chunks(volume_list, 60)\n",
    "            volume_list_testing = volume[-100:]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_part = change[-700:]\n",
    "            change_list = change[-700:-100]\n",
    "            change_list_split = chunks(change_list, 60)\n",
    "            change_list_testing = change[-100:]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_part = typical_price[-700:]\n",
    "            typical_price_list = typical_price[-700:-100]\n",
    "            typical_price_list_split = chunks(typical_price_list, 60)\n",
    "            typical_price_list_testing = typical_price[-100:]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_part = middle_price[-700:]\n",
    "            middle_price_list = middle_price[-700:-100]\n",
    "            middle_price_list_split = chunks(middle_price_list, 60)\n",
    "            middle_price_list_testing = middle_price[-100:]\n",
    "    \n",
    "    training_list = [open_price_list_split, high_price_list_split, low_price_list_split, close_price_list_split, \\\n",
    "                    volume_list_split, change_list_split, typical_price_list_split, middle_price_list_split]\n",
    "\n",
    "    training_list_mixed = mix(training_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in training_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 49\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/51\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/26\n",
    "        EMA_25 = []\n",
    "        for i in range(26,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-24:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        training_data = stock_feature_list[:-1]\n",
    "        training_data_total.append(training_data)\n",
    "        \n",
    "        training_label = stock_feature_list[-1]\n",
    "        training_label_total.append(training_label)\n",
    "        \n",
    "\n",
    "print (len(training_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n"
     ]
    }
   ],
   "source": [
    "transformer = RobustScaler().fit(training_data_total)\n",
    "data = transformer.transform(training_data_total)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the validation model 5 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46035\n",
      "22.945892633333337 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "validation_data_total = []\n",
    "validation_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list = open_price[-700:]\n",
    "            open_price_list_split_5 = slic(open_price_list, 9, 14)\n",
    "            \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list = high_price[-700:]\n",
    "            high_price_list_split_5 = slic(high_price_list, 9, 14)\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list = low_price[-700:]\n",
    "            low_price_list_split_5 = slic(low_price_list, 9, 14)\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list = close_price[-700:]\n",
    "            close_price_list_split_5 = slic(close_price_list, 9, 14)\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list = volume[-700:]\n",
    "            volume_list_split_5 = slic(volume_list, 9, 14)\n",
    "        \n",
    "            change.append(row[7])\n",
    "            change_list = change[-700:]\n",
    "            change_list_split_5 = slic(change_list, 9, 14)\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list = typical_price[-700:]\n",
    "            typical_price_list_split_5 = slic(typical_price_list, 9, 14)\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list = middle_price[-700:]\n",
    "            middle_price_list_split_5 = slic(middle_price_list, 9, 14)\n",
    "    \n",
    "    validation_list = [open_price_list_split_5, high_price_list_split_5, low_price_list_split_5, close_price_list_split_5, \\\n",
    "                    volume_list_split_5, change_list_split_5, typical_price_list_split_5, middle_price_list_split_5]\n",
    "\n",
    "    validation_list_mixed = mix(validation_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in validation_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/(negative_money_flow+1))\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 4\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/6\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/3\n",
    "        EMA_25 = []\n",
    "        for i in range(3,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-2:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/(1+cr_neg_sum))\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        validation_data = stock_feature_list[:-1]\n",
    "        validation_data_total.append(validation_data)\n",
    "        \n",
    "        validation_label = stock_feature_list[-1]\n",
    "        validation_label_total.append(validation_label)\n",
    "        \n",
    "\n",
    "print (len(validation_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_v = RobustScaler().fit(validation_data_total)\n",
    "validation_data = transformer_v.transform(validation_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3.6839338500000016 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "testing_data_total = []\n",
    "testing_label_total = []\n",
    "testing_list_total = []\n",
    "\n",
    "count_term=1\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list_testing = open_price[-100:-86]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list_testing = high_price[-100:-86]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list_testing = low_price[-100:-86]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list_testing = close_price[-100:-86]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list_testing = volume[-100:-86]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_list_testing = change[-100:-86]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list_testing = typical_price[-100:-86]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list_testing = middle_price[-100:-86]\n",
    "    \n",
    "    testing_list = [open_price_list_testing, high_price_list_testing, low_price_list_testing, close_price_list_testing, \\\n",
    "                    volume_list_testing, change_list_testing, typical_price_list_testing, middle_price_list_testing]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_list = []\n",
    "    abs_list = []\n",
    "    \n",
    "    for flt in testing_list[5]:\n",
    "        abs_list.append(abs(flt))\n",
    "        if flt > 0:\n",
    "            pos_list.append(flt)\n",
    "    \n",
    "    abs_sum = float('%.3f' % sum(abs_list))\n",
    "    pos_sum = float('%.3f' % sum(pos_list))\n",
    "    raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "    RSI = float('%.3f' % raw_rsi)\n",
    "    stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    indicator_list = [0.5] \n",
    "    \n",
    "    money_flow_list = [vol*tp for vol, tp in zip(testing_list[4], testing_list[6])]\n",
    "    total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "    for i in range(len(testing_list[6])-1):\n",
    "        det = sgn(float('%.2f' % (testing_list[6][i+1] - testing_list[6][i])))\n",
    "        indicator_list.append(det)\n",
    "       \n",
    "    positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "    positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "    negative_money_flow = total_money_flow - positive_money_flow\n",
    "    money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "    raw_mfi = 100-100/(1+money_rate)\n",
    "    MFI = float('%.3f' % raw_mfi)\n",
    "    stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "    if len(testing_list[3]) >= 3:\n",
    "        raw_rsv = 100*(close_price_list_testing[-1] - min(close_price_list_testing))/(max(close_price_list_testing) - min(close_price_list_testing))\n",
    "    RSV = float('%.3f' % raw_rsv)\n",
    "    stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = testing_list[3][-1] - testing_list[3][-5]\n",
    "    bx = testing_list[3][-5]\n",
    "    raw_roc = 100*ax/bx\n",
    "    ROC = float('%.3f' % raw_roc)\n",
    "    stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "    square_sum_5 = []\n",
    "    TP_5 = mean(testing_list[6][-5:])\n",
    "    MA_5 = mean(testing_list[3][-5:])\n",
    "    for i in testing_list[3][-5:]:\n",
    "        square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "    raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "    CCI = float('%.3f' % raw_cci)\n",
    "    stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "    vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(testing_list[3], testing_list[1], testing_list[2])))\n",
    "    \n",
    "    va = []\n",
    "    va_change_list = []\n",
    "    va.append(testing_list[4][0])\n",
    "    \n",
    "    for i in range(0, len(testing_list[4])-1):\n",
    "        va.append(va[i] + vol_para[i]*testing_list[4][i+1])\n",
    "    \n",
    "    for i in range(0, len(va)-1):\n",
    "        va_change_list.append(va[i+1] - va[i])\n",
    "    va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "    if abs(va_change_rate) > 0.1:\n",
    "        VA = sgn(va_change_rate)\n",
    "    else:\n",
    "        VA = sgn_num(va_change_list)\n",
    "    stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    closing_change_list = []\n",
    "\n",
    "    for i in range(0, len(testing_list[3])-1):\n",
    "        closing_change_list.append(testing_list[3][i+1]-testing_list[3][i])\n",
    "   \n",
    "    closing_price_list_pvt = testing_list[3][1:]\n",
    "    volume_list_pvt = volume_list_testing[1:]\n",
    "    pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "    raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "    PVT = float('%.3f' % raw_pvt)\n",
    "    stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sign_closing_change_list = []\n",
    "    for i in closing_change_list:\n",
    "        sign_closing_change_list.append(sgn_0(i))\n",
    "    obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, testing_list[4][1:])))\n",
    "    raw_obv = sqrt_abs(sum(obv_list))\n",
    "    OBV = float('%.3f' % raw_obv)\n",
    "    stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exp_len = 49\n",
    "    exp_starting = len(testing_list[3]) - exp_len\n",
    "    price_list_50 = [mean(testing_list[3][:exp_starting])] + testing_list[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "    const_50 = 2/51\n",
    "    EMA_50 = []\n",
    "    for i in range(1,len(price_list_50)):\n",
    "        raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "        ema_50 = float('%.3f' % raw_ema_50)\n",
    "        EMA_50.append(ema_50)\n",
    "    \n",
    "    const_25 = 2/26\n",
    "    EMA_25 = []\n",
    "    for i in range(26,len(price_list_50)):\n",
    "        raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "        ema_25 = float('%.3f' % raw_ema_25)\n",
    "        EMA_25.append(ema_25)\n",
    "        \n",
    "    EMA_50c = EMA_50[-24:]\n",
    "    EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "    EMA_mean = np.mean(EMA_diff)*100\n",
    "    EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "    stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "    stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "    stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cr_pos = []\n",
    "    cr_neg = []\n",
    "    \n",
    "    middle_price_list_c = testing_list[7][:-1]\n",
    "    closing_price_list_c = testing_list[3][1:]\n",
    "    cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "    for i in cr_list:\n",
    "        if i > 0:\n",
    "            cr_pos.append(i)\n",
    "        else:\n",
    "            cr_neg.append(abs(i))\n",
    "    \n",
    "    cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "    cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "    raw_cr = 100*(cr_pos_sum/(cr_neg_sum+1))\n",
    "    CR = float('%.3f' % raw_cr)\n",
    "    stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "    square_sum = []\n",
    "    MA = mean(testing_list[3])\n",
    "    MB = mean(testing_list[3][:-1])\n",
    "    \n",
    "    for i in testing_list[3]:\n",
    "        square_sum.append((i-MA)**2)\n",
    "    MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "    raw_UP = MB+2*MD\n",
    "    raw_DN = MB-2*MD\n",
    "    UP = float('%.3f' % raw_UP)\n",
    "    DN = float('%.3f' % raw_DN)\n",
    "    stock_feature_dict[\"UP\"] = UP\n",
    "    stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        \n",
    "    if testing_list[3][-1] > testing_list[3][0]:\n",
    "        stock_feature_dict[\"change_c\"] = 1\n",
    "    else:\n",
    "        stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "    stock_feature_list = list(stock_feature_dict.values())\n",
    "    stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "    stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "    testing_data = stock_feature_list[:-1]\n",
    "    testing_data_total.append(testing_data)\n",
    "        \n",
    "    testing_label = stock_feature_list[-1]\n",
    "    testing_label_total.append(testing_label)\n",
    "\n",
    "    \n",
    "    \n",
    "print (len(testing_list_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_testing = RobustScaler().fit(testing_data_total)\n",
    "data_testing = transformer_testing.transform(testing_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree has accuracy on validation 0.7540566959921798\n",
      "decision tree has precision on validation 0.75\n",
      "decision tree has recall on validation 0.803175775480059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.70      0.73      2407\n",
      "           1       0.75      0.80      0.78      2708\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.75      0.75      0.75      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1682  725]\n",
      " [ 533 2175]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5616813294232649\n",
      "decision tree has precision on testing 0.8503207412687099\n",
      "decision tree has recall on testing 0.36992248062015504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.89      0.60      1890\n",
      "           1       0.85      0.37      0.52      3225\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      5115\n",
      "   macro avg       0.65      0.63      0.56      5115\n",
      "weighted avg       0.70      0.56      0.55      5115\n",
      "\n",
      "[[1680  210]\n",
      " [2032 1193]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.78455522971652\n",
      "log reg has precision on validation 0.7377146240378922\n",
      "log reg has recall on validation 0.9202363367799113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.63      0.73      2407\n",
      "           1       0.74      0.92      0.82      2708\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.81      0.78      0.78      5115\n",
      "weighted avg       0.80      0.78      0.78      5115\n",
      "\n",
      "[[1521  886]\n",
      " [ 216 2492]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.4162267839687194\n",
      "log reg has precision on testing 0.9917695473251029\n",
      "log reg has recall on testing 0.07472868217054264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       0.99      0.07      0.14      3225\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.69      0.54      0.35      5115\n",
      "weighted avg       0.77      0.42      0.29      5115\n",
      "\n",
      "[[1888    2]\n",
      " [2984  241]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5495601173020528\n",
      "naive bayes has precision on validation 0.5404971932638332\n",
      "naive bayes has recall on validation 0.9955686853766618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.05      0.09      2407\n",
      "           1       0.54      1.00      0.70      2708\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5115\n",
      "   macro avg       0.72      0.52      0.40      5115\n",
      "weighted avg       0.71      0.55      0.41      5115\n",
      "\n",
      "[[ 115 2292]\n",
      " [  12 2696]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.36950146627565983\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       0.00      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.18      0.50      0.27      5115\n",
      "weighted avg       0.14      0.37      0.20      5115\n",
      "\n",
      "[[1890    0]\n",
      " [3225    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7853372434017595\n",
      "svm has precision on validation 0.7381656804733728\n",
      "svm has recall on validation 0.9213441654357459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.63      0.73      2407\n",
      "           1       0.74      0.92      0.82      2708\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.81      0.78      0.78      5115\n",
      "weighted avg       0.80      0.79      0.78      5115\n",
      "\n",
      "[[1522  885]\n",
      " [ 213 2495]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.41837732160312807\n",
      "svm has precision on testing 0.996031746031746\n",
      "svm has recall on testing 0.07782945736434109\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       1.00      0.08      0.14      3225\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.69      0.54      0.35      5115\n",
      "weighted avg       0.77      0.42      0.30      5115\n",
      "\n",
      "[[1889    1]\n",
      " [2974  251]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8039100684261975\n",
      "random forest has precision on validation 0.7640136265097554\n",
      "random forest has recall on validation 0.9110044313146234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.68      0.77      2407\n",
      "           1       0.76      0.91      0.83      2708\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.82      0.80      0.80      5115\n",
      "weighted avg       0.81      0.80      0.80      5115\n",
      "\n",
      "[[1645  762]\n",
      " [ 241 2467]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7704789833822092\n",
      "random forest has precision on testing 0.8973266175900814\n",
      "random forest has recall on testing 0.718139534883721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 909 2316]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7874877810361681\n",
      "decision tree has precision on validation 0.763909224011713\n",
      "decision tree has recall on validation 0.8252273625939106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.75      0.78      2586\n",
      "           1       0.76      0.83      0.79      2529\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1941  645]\n",
      " [ 442 2087]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.770674486803519\n",
      "decision tree has precision on testing 0.8973663826491092\n",
      "decision tree has recall on testing 0.7184496124031008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 908 2317]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8461388074291301\n",
      "log reg has precision on validation 0.7833441769681198\n",
      "log reg has recall on validation 0.952155001977066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.74      0.83      2586\n",
      "           1       0.78      0.95      0.86      2529\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.85      0.84      5115\n",
      "weighted avg       0.86      0.85      0.84      5115\n",
      "\n",
      "[[1920  666]\n",
      " [ 121 2408]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.7951124144672532\n",
      "log reg has precision on testing 0.8925351604760188\n",
      "log reg has recall on testing 0.7674418604651163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.84      0.75      1890\n",
      "           1       0.89      0.77      0.83      3225\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.80      0.79      5115\n",
      "weighted avg       0.81      0.80      0.80      5115\n",
      "\n",
      "[[1592  298]\n",
      " [ 750 2475]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5638318670576735\n",
      "naive bayes has precision on validation 0.5313025210084034\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.14      0.24      2586\n",
      "           1       0.53      1.00      0.69      2529\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      5115\n",
      "   macro avg       0.77      0.57      0.47      5115\n",
      "weighted avg       0.77      0.56      0.47      5115\n",
      "\n",
      "[[ 355 2231]\n",
      " [   0 2529]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.37282502443792764\n",
      "naive bayes has precision on testing 0.639344262295082\n",
      "naive bayes has recall on testing 0.012093023255813953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.99      0.54      1890\n",
      "           1       0.64      0.01      0.02      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.50      0.50      0.28      5115\n",
      "weighted avg       0.54      0.37      0.21      5115\n",
      "\n",
      "[[1868   22]\n",
      " [3186   39]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8058651026392962\n",
      "svm has precision on validation 0.7459961563100577\n",
      "svm has recall on validation 0.9209173586397785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.69      0.78      2586\n",
      "           1       0.75      0.92      0.82      2529\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.82      0.81      0.80      5115\n",
      "weighted avg       0.82      0.81      0.80      5115\n",
      "\n",
      "[[1793  793]\n",
      " [ 200 2329]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.4027370478983382\n",
      "svm has precision on testing 0.9829545454545454\n",
      "svm has recall on testing 0.05364341085271318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      1.00      0.55      1890\n",
      "           1       0.98      0.05      0.10      3225\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.68      0.53      0.33      5115\n",
      "weighted avg       0.76      0.40      0.27      5115\n",
      "\n",
      "[[1887    3]\n",
      " [3052  173]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8324535679374389\n",
      "random forest has precision on validation 0.7746386333771353\n",
      "random forest has recall on validation 0.9323843416370107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.73      0.82      2586\n",
      "           1       0.77      0.93      0.85      2529\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.85      0.83      0.83      5115\n",
      "weighted avg       0.85      0.83      0.83      5115\n",
      "\n",
      "[[1900  686]\n",
      " [ 171 2358]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.770674486803519\n",
      "random forest has precision on testing 0.8973663826491092\n",
      "random forest has recall on testing 0.7184496124031008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 908 2317]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7786901270772238\n",
      "decision tree has precision on validation 0.766399416909621\n",
      "decision tree has recall on validation 0.8107170393215112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.75      0.77      2521\n",
      "           1       0.77      0.81      0.79      2594\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.78      0.78      5115\n",
      "weighted avg       0.78      0.78      0.78      5115\n",
      "\n",
      "[[1880  641]\n",
      " [ 491 2103]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7327468230694038\n",
      "decision tree has precision on testing 0.7998708844415752\n",
      "decision tree has recall on testing 0.7683720930232558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.67      0.65      1890\n",
      "           1       0.80      0.77      0.78      3225\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5115\n",
      "   macro avg       0.71      0.72      0.72      5115\n",
      "weighted avg       0.74      0.73      0.73      5115\n",
      "\n",
      "[[1270  620]\n",
      " [ 747 2478]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7980449657869013\n",
      "log reg has precision on validation 0.7461368653421634\n",
      "log reg has recall on validation 0.9121048573631457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.68      0.77      2521\n",
      "           1       0.75      0.91      0.82      2594\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.81      0.80      0.79      5115\n",
      "weighted avg       0.81      0.80      0.80      5115\n",
      "\n",
      "[[1716  805]\n",
      " [ 228 2366]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.4310850439882698\n",
      "log reg has precision on testing 0.9618768328445748\n",
      "log reg has recall on testing 0.10170542635658915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.99      0.56      1890\n",
      "           1       0.96      0.10      0.18      3225\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      5115\n",
      "   macro avg       0.68      0.55      0.37      5115\n",
      "weighted avg       0.75      0.43      0.32      5115\n",
      "\n",
      "[[1877   13]\n",
      " [2897  328]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5921798631476051\n",
      "naive bayes has precision on validation 0.554389721627409\n",
      "naive bayes has recall on validation 0.9980724749421742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.17      0.30      2521\n",
      "           1       0.55      1.00      0.71      2594\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.77      0.59      0.50      5115\n",
      "weighted avg       0.77      0.59      0.51      5115\n",
      "\n",
      "[[ 440 2081]\n",
      " [   5 2589]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3696969696969697\n",
      "naive bayes has precision on testing 0.5555555555555556\n",
      "naive bayes has recall on testing 0.0015503875968992248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       0.56      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.46      0.50      0.27      5115\n",
      "weighted avg       0.49      0.37      0.20      5115\n",
      "\n",
      "[[1886    4]\n",
      " [3220    5]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7951124144672532\n",
      "svm has precision on validation 0.7455527318932655\n",
      "svm has recall on validation 0.9047802621434079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.68      0.77      2521\n",
      "           1       0.75      0.90      0.82      2594\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.81      0.79      0.79      5115\n",
      "weighted avg       0.81      0.80      0.79      5115\n",
      "\n",
      "[[1720  801]\n",
      " [ 247 2347]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.4207233626588465\n",
      "svm has precision on testing 0.9712230215827338\n",
      "svm has recall on testing 0.08372093023255814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       0.97      0.08      0.15      3225\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.68      0.54      0.36      5115\n",
      "weighted avg       0.76      0.42      0.30      5115\n",
      "\n",
      "[[1882    8]\n",
      " [2955  270]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8250244379276638\n",
      "random forest has precision on validation 0.7777051323962079\n",
      "random forest has recall on validation 0.9171164225134927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.73      0.80      2521\n",
      "           1       0.78      0.92      0.84      2594\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.82      0.82      5115\n",
      "weighted avg       0.84      0.83      0.82      5115\n",
      "\n",
      "[[1841  680]\n",
      " [ 215 2379]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7702834799608993\n",
      "random forest has precision on testing 0.8972868217054264\n",
      "random forest has recall on testing 0.7178294573643411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 910 2315]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7947214076246334\n",
      "decision tree has precision on validation 0.8375104427736006\n",
      "decision tree has recall on validation 0.7520630157539385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.84      0.80      2449\n",
      "           1       0.84      0.75      0.79      2666\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.80      0.80      0.79      5115\n",
      "weighted avg       0.80      0.79      0.79      5115\n",
      "\n",
      "[[2060  389]\n",
      " [ 661 2005]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.37008797653958947\n",
      "decision tree has precision on testing 1.0\n",
      "decision tree has recall on testing 0.0009302325581395349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       1.00      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.68      0.50      0.27      5115\n",
      "weighted avg       0.77      0.37      0.20      5115\n",
      "\n",
      "[[1890    0]\n",
      " [3222    3]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.6680351906158358\n",
      "log reg has precision on validation 0.7439516129032258\n",
      "log reg has recall on validation 0.5536384096024006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.79      0.70      2449\n",
      "           1       0.74      0.55      0.63      2666\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.68      0.67      0.67      5115\n",
      "weighted avg       0.68      0.67      0.66      5115\n",
      "\n",
      "[[1941  508]\n",
      " [1190 1476]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6275659824046921\n",
      "log reg has precision on testing 0.7572096648480124\n",
      "log reg has recall on testing 0.6024806201550388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.67      0.57      1890\n",
      "           1       0.76      0.60      0.67      3225\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.63      0.64      0.62      5115\n",
      "weighted avg       0.66      0.63      0.63      5115\n",
      "\n",
      "[[1267  623]\n",
      " [1282 1943]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5212121212121212\n",
      "naive bayes has precision on validation 0.5212121212121212\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2449\n",
      "           1       0.52      1.00      0.69      2666\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5115\n",
      "   macro avg       0.26      0.50      0.34      5115\n",
      "weighted avg       0.27      0.52      0.36      5115\n",
      "\n",
      "[[   0 2449]\n",
      " [   0 2666]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.6304985337243402\n",
      "naive bayes has precision on testing 0.6304985337243402\n",
      "naive bayes has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1890\n",
      "           1       0.63      1.00      0.77      3225\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.32      0.50      0.39      5115\n",
      "weighted avg       0.40      0.63      0.49      5115\n",
      "\n",
      "[[   0 1890]\n",
      " [   0 3225]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8392961876832845\n",
      "svm has precision on validation 0.8129667345553293\n",
      "svm has recall on validation 0.8983495873968492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.78      0.82      2449\n",
      "           1       0.81      0.90      0.85      2666\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.84      0.84      5115\n",
      "weighted avg       0.84      0.84      0.84      5115\n",
      "\n",
      "[[1898  551]\n",
      " [ 271 2395]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.4121212121212121\n",
      "svm has precision on testing 0.9954545454545455\n",
      "svm has recall on testing 0.06790697674418604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       1.00      0.07      0.13      3225\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.69      0.53      0.34      5115\n",
      "weighted avg       0.77      0.41      0.29      5115\n",
      "\n",
      "[[1889    1]\n",
      " [3006  219]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.864711632453568\n",
      "random forest has precision on validation 0.8375512995896033\n",
      "random forest has recall on validation 0.9186046511627907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.81      0.85      2449\n",
      "           1       0.84      0.92      0.88      2666\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.86      0.86      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[1974  475]\n",
      " [ 217 2449]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7702834799608993\n",
      "random forest has precision on testing 0.8972868217054264\n",
      "random forest has recall on testing 0.7178294573643411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 910 2315]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7849462365591398\n",
      "decision tree has precision on validation 0.7902592301649647\n",
      "decision tree has recall on validation 0.7804499612102405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.79      0.78      2537\n",
      "           1       0.79      0.78      0.79      2578\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.78      0.78      5115\n",
      "weighted avg       0.79      0.78      0.78      5115\n",
      "\n",
      "[[2003  534]\n",
      " [ 566 2012]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7765395894428152\n",
      "decision tree has precision on testing 0.8067177371832646\n",
      "decision tree has recall on testing 0.8489922480620155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.65      0.68      1890\n",
      "           1       0.81      0.85      0.83      3225\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.76      0.75      0.76      5115\n",
      "weighted avg       0.77      0.78      0.77      5115\n",
      "\n",
      "[[1234  656]\n",
      " [ 487 2738]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8312805474095797\n",
      "log reg has precision on validation 0.7801372100620713\n",
      "log reg has recall on validation 0.9262994569433669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.73      0.81      2537\n",
      "           1       0.78      0.93      0.85      2578\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.83      0.83      5115\n",
      "weighted avg       0.84      0.83      0.83      5115\n",
      "\n",
      "[[1864  673]\n",
      " [ 190 2388]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.4289345063538612\n",
      "log reg has precision on testing 0.9810126582278481\n",
      "log reg has recall on testing 0.09612403100775194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       0.98      0.10      0.18      3225\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      5115\n",
      "   macro avg       0.69      0.55      0.37      5115\n",
      "weighted avg       0.76      0.43      0.32      5115\n",
      "\n",
      "[[1884    6]\n",
      " [2915  310]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6789833822091886\n",
      "naive bayes has precision on validation 0.6112167300380228\n",
      "naive bayes has recall on validation 0.9976726144297905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.36      0.52      2537\n",
      "           1       0.61      1.00      0.76      2578\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.80      0.68      0.64      5115\n",
      "weighted avg       0.80      0.68      0.64      5115\n",
      "\n",
      "[[ 901 1636]\n",
      " [   6 2572]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3704789833822092\n",
      "naive bayes has precision on testing 0.5714285714285714\n",
      "naive bayes has recall on testing 0.006201550387596899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.99      0.54      1890\n",
      "           1       0.57      0.01      0.01      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.47      0.50      0.28      5115\n",
      "weighted avg       0.50      0.37      0.21      5115\n",
      "\n",
      "[[1875   15]\n",
      " [3205   20]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8330400782013685\n",
      "svm has precision on validation 0.7798701298701298\n",
      "svm has recall on validation 0.9317300232738557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.73      0.81      2537\n",
      "           1       0.78      0.93      0.85      2578\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.85      0.83      0.83      5115\n",
      "weighted avg       0.85      0.83      0.83      5115\n",
      "\n",
      "[[1859  678]\n",
      " [ 176 2402]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.4240469208211144\n",
      "svm has precision on testing 0.979381443298969\n",
      "svm has recall on testing 0.08837209302325581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       0.98      0.09      0.16      3225\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.68      0.54      0.36      5115\n",
      "weighted avg       0.76      0.42      0.31      5115\n",
      "\n",
      "[[1884    6]\n",
      " [2940  285]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8457478005865102\n",
      "random forest has precision on validation 0.7955071027419888\n",
      "random forest has recall on validation 0.9340574088440652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.76      0.83      2537\n",
      "           1       0.80      0.93      0.86      2578\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.85      0.84      5115\n",
      "weighted avg       0.86      0.85      0.84      5115\n",
      "\n",
      "[[1918  619]\n",
      " [ 170 2408]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7702834799608993\n",
      "random forest has precision on testing 0.8972868217054264\n",
      "random forest has recall on testing 0.7178294573643411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 910 2315]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.798435972629521\n",
      "decision tree has precision on validation 0.8190954773869347\n",
      "decision tree has recall on validation 0.85145282402873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.72      0.74      2052\n",
      "           1       0.82      0.85      0.83      3063\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1476  576]\n",
      " [ 455 2608]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.6670576735092865\n",
      "decision tree has precision on testing 0.6658674803836094\n",
      "decision tree has recall on testing 0.9472868217054263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.19      0.30      1890\n",
      "           1       0.67      0.95      0.78      3225\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.67      0.57      0.54      5115\n",
      "weighted avg       0.67      0.67      0.60      5115\n",
      "\n",
      "[[ 357 1533]\n",
      " [ 170 3055]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8355816226783969\n",
      "log reg has precision on validation 0.8057237204182719\n",
      "log reg has recall on validation 0.9559255631733594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.66      0.76      2052\n",
      "           1       0.81      0.96      0.87      3063\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.86      0.81      0.82      5115\n",
      "weighted avg       0.85      0.84      0.83      5115\n",
      "\n",
      "[[1346  706]\n",
      " [ 135 2928]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.43655913978494626\n",
      "log reg has precision on testing 0.9750692520775623\n",
      "log reg has recall on testing 0.10914728682170542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      1890\n",
      "           1       0.98      0.11      0.20      3225\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      5115\n",
      "   macro avg       0.69      0.55      0.38      5115\n",
      "weighted avg       0.76      0.44      0.33      5115\n",
      "\n",
      "[[1881    9]\n",
      " [2873  352]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7434995112414468\n",
      "naive bayes has precision on validation 0.7004808793221892\n",
      "naive bayes has recall on validation 0.9986940907606922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.36      0.53      2052\n",
      "           1       0.70      1.00      0.82      3063\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      5115\n",
      "   macro avg       0.85      0.68      0.68      5115\n",
      "weighted avg       0.82      0.74      0.71      5115\n",
      "\n",
      "[[ 744 1308]\n",
      " [   4 3059]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.36950146627565983\n",
      "naive bayes has precision on testing 0.5\n",
      "naive bayes has recall on testing 0.000310077519379845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       0.50      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.43      0.50      0.27      5115\n",
      "weighted avg       0.45      0.37      0.20      5115\n",
      "\n",
      "[[1889    1]\n",
      " [3224    1]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8408602150537634\n",
      "svm has precision on validation 0.8107211936999171\n",
      "svm has recall on validation 0.9578844270323212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.67      0.77      2052\n",
      "           1       0.81      0.96      0.88      3063\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.86      0.81      0.82      5115\n",
      "weighted avg       0.85      0.84      0.84      5115\n",
      "\n",
      "[[1367  685]\n",
      " [ 129 2934]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.43499511241446726\n",
      "svm has precision on testing 0.9883381924198251\n",
      "svm has recall on testing 0.10511627906976745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      1890\n",
      "           1       0.99      0.11      0.19      3225\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      5115\n",
      "   macro avg       0.69      0.55      0.38      5115\n",
      "weighted avg       0.77      0.43      0.33      5115\n",
      "\n",
      "[[1886    4]\n",
      " [2886  339]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8606060606060606\n",
      "random forest has precision on validation 0.844574780058651\n",
      "random forest has recall on validation 0.940254652301665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.74      0.81      2052\n",
      "           1       0.84      0.94      0.89      3063\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.84      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1522  530]\n",
      " [ 183 2880]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.770674486803519\n",
      "random forest has precision on testing 0.8973663826491092\n",
      "random forest has recall on testing 0.7184496124031008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 908 2317]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7521016617790811\n",
      "decision tree has precision on validation 0.6537009063444109\n",
      "decision tree has recall on validation 0.8314121037463977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.70      0.77      3033\n",
      "           1       0.65      0.83      0.73      2082\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.76      0.76      0.75      5115\n",
      "weighted avg       0.77      0.75      0.75      5115\n",
      "\n",
      "[[2116  917]\n",
      " [ 351 1731]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.17008797653958943\n",
      "decision tree has precision on testing 0.25121951219512195\n",
      "decision tree has recall on testing 0.15968992248062017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.12      0.19      0.14      1890\n",
      "           1       0.25      0.16      0.20      3225\n",
      "\n",
      "   micro avg       0.17      0.17      0.17      5115\n",
      "   macro avg       0.18      0.17      0.17      5115\n",
      "weighted avg       0.20      0.17      0.18      5115\n",
      "\n",
      "[[ 355 1535]\n",
      " [2710  515]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7749755620723363\n",
      "log reg has precision on validation 0.6623648412975236\n",
      "log reg has recall on validation 0.9121037463976945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.68      0.78      3033\n",
      "           1       0.66      0.91      0.77      2082\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.79      0.80      0.77      5115\n",
      "weighted avg       0.81      0.77      0.78      5115\n",
      "\n",
      "[[2065  968]\n",
      " [ 183 1899]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.443010752688172\n",
      "log reg has precision on testing 0.9585365853658536\n",
      "log reg has recall on testing 0.12186046511627907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.99      0.57      1890\n",
      "           1       0.96      0.12      0.22      3225\n",
      "\n",
      "   micro avg       0.44      0.44      0.44      5115\n",
      "   macro avg       0.68      0.56      0.39      5115\n",
      "weighted avg       0.75      0.44      0.35      5115\n",
      "\n",
      "[[1873   17]\n",
      " [2832  393]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7513196480938417\n",
      "naive bayes has precision on validation 0.6245387453874539\n",
      "naive bayes has recall on validation 0.9755043227665706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.60      0.74      3033\n",
      "           1       0.62      0.98      0.76      2082\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.80      0.79      0.75      5115\n",
      "weighted avg       0.83      0.75      0.75      5115\n",
      "\n",
      "[[1812 1221]\n",
      " [  51 2031]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.36930596285434997\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       0.00      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.18      0.50      0.27      5115\n",
      "weighted avg       0.14      0.37      0.20      5115\n",
      "\n",
      "[[1889    1]\n",
      " [3225    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7792766373411535\n",
      "svm has precision on validation 0.6660857441617288\n",
      "svm has recall on validation 0.9178674351585014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.68      0.79      3033\n",
      "           1       0.67      0.92      0.77      2082\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.79      0.80      0.78      5115\n",
      "weighted avg       0.82      0.78      0.78      5115\n",
      "\n",
      "[[2075  958]\n",
      " [ 171 1911]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.42482893450635384\n",
      "svm has precision on testing 0.9764309764309764\n",
      "svm has recall on testing 0.08992248062015504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      1.00      0.56      1890\n",
      "           1       0.98      0.09      0.16      3225\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.68      0.54      0.36      5115\n",
      "weighted avg       0.76      0.42      0.31      5115\n",
      "\n",
      "[[1883    7]\n",
      " [2935  290]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8140762463343109\n",
      "random forest has precision on validation 0.7125140924464487\n",
      "random forest has recall on validation 0.9106628242074928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.75      0.83      3033\n",
      "           1       0.71      0.91      0.80      2082\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.82      0.83      0.81      5115\n",
      "weighted avg       0.84      0.81      0.82      5115\n",
      "\n",
      "[[2268  765]\n",
      " [ 186 1896]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.770674486803519\n",
      "random forest has precision on testing 0.8973663826491092\n",
      "random forest has recall on testing 0.7184496124031008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 908 2317]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.818572825024438\n",
      "decision tree has precision on validation 0.8531679517264499\n",
      "decision tree has recall on validation 0.8385502471169687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.79      0.78      2080\n",
      "           1       0.85      0.84      0.85      3035\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.81      0.81      0.81      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1642  438]\n",
      " [ 490 2545]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.3708699902248289\n",
      "decision tree has precision on testing 1.0\n",
      "decision tree has recall on testing 0.0021705426356589145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      1.00      0.54      1890\n",
      "           1       1.00      0.00      0.00      3225\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.69      0.50      0.27      5115\n",
      "weighted avg       0.77      0.37      0.20      5115\n",
      "\n",
      "[[1890    0]\n",
      " [3218    7]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8173998044965787\n",
      "log reg has precision on validation 0.8593910366062265\n",
      "log reg has recall on validation 0.8276771004942339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.80      0.78      2080\n",
      "           1       0.86      0.83      0.84      3035\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1669  411]\n",
      " [ 523 2512]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6347996089931573\n",
      "log reg has precision on testing 0.6332220695071668\n",
      "log reg has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.01      0.02      1890\n",
      "           1       0.63      1.00      0.78      3225\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.82      0.51      0.40      5115\n",
      "weighted avg       0.77      0.63      0.50      5115\n",
      "\n",
      "[[  22 1868]\n",
      " [   0 3225]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6097751710654936\n",
      "naive bayes has precision on validation 0.6041290839847665\n",
      "naive bayes has recall on validation 0.9930807248764415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.05      0.10      2080\n",
      "           1       0.60      0.99      0.75      3035\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      5115\n",
      "   macro avg       0.72      0.52      0.42      5115\n",
      "weighted avg       0.70      0.61      0.48      5115\n",
      "\n",
      "[[ 105 1975]\n",
      " [  21 3014]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.19257086999022482\n",
      "naive bayes has precision on testing 0.28380315336837075\n",
      "naive bayes has recall on testing 0.1841860465116279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.13      0.21      0.16      1890\n",
      "           1       0.28      0.18      0.22      3225\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      5115\n",
      "   macro avg       0.21      0.20      0.19      5115\n",
      "weighted avg       0.23      0.19      0.20      5115\n",
      "\n",
      "[[ 391 1499]\n",
      " [2631  594]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8428152492668621\n",
      "svm has precision on validation 0.8043656207366985\n",
      "svm has recall on validation 0.971334431630972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.66      0.77      2080\n",
      "           1       0.80      0.97      0.88      3035\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.87      0.81      0.83      5115\n",
      "weighted avg       0.86      0.84      0.84      5115\n",
      "\n",
      "[[1363  717]\n",
      " [  87 2948]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8527859237536657\n",
      "svm has precision on testing 0.8582608695652174\n",
      "svm has recall on testing 0.9181395348837209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.74      0.79      1890\n",
      "           1       0.86      0.92      0.89      3225\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.85      0.83      0.84      5115\n",
      "weighted avg       0.85      0.85      0.85      5115\n",
      "\n",
      "[[1401  489]\n",
      " [ 264 2961]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8688172043010752\n",
      "random forest has precision on validation 0.8577481840193705\n",
      "random forest has recall on validation 0.9337726523887974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.77      0.83      2080\n",
      "           1       0.86      0.93      0.89      3035\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.85      0.86      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1610  470]\n",
      " [ 201 2834]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7702834799608993\n",
      "random forest has precision on testing 0.8972868217054264\n",
      "random forest has recall on testing 0.7178294573643411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 910 2315]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7902248289345064\n",
      "decision tree has precision on validation 0.7874762808349146\n",
      "decision tree has recall on validation 0.8017774343122102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.78      0.79      2527\n",
      "           1       0.79      0.80      0.79      2588\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1967  560]\n",
      " [ 513 2075]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5180840664711632\n",
      "decision tree has precision on testing 0.6008492569002123\n",
      "decision tree has recall on testing 0.702015503875969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.20      0.24      1890\n",
      "           1       0.60      0.70      0.65      3225\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5115\n",
      "   macro avg       0.44      0.45      0.44      5115\n",
      "weighted avg       0.48      0.52      0.50      5115\n",
      "\n",
      "[[ 386 1504]\n",
      " [ 961 2264]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7691104594330401\n",
      "log reg has precision on validation 0.6932161494095029\n",
      "log reg has recall on validation 0.9752704791344667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.56      0.70      2527\n",
      "           1       0.69      0.98      0.81      2588\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.82      0.77      0.76      5115\n",
      "weighted avg       0.82      0.77      0.76      5115\n",
      "\n",
      "[[1410 1117]\n",
      " [  64 2524]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6334310850439883\n",
      "log reg has precision on testing 0.632404864652805\n",
      "log reg has recall on testing 0.9996899224806202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.01      0.02      1890\n",
      "           1       0.63      1.00      0.77      3225\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.79      0.50      0.40      5115\n",
      "weighted avg       0.75      0.63      0.49      5115\n",
      "\n",
      "[[  16 1874]\n",
      " [   1 3224]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5536656891495602\n",
      "naive bayes has precision on validation 0.5317245683378407\n",
      "naive bayes has recall on validation 0.9876352395672334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.11      0.19      2527\n",
      "           1       0.53      0.99      0.69      2588\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5115\n",
      "   macro avg       0.71      0.55      0.44      5115\n",
      "weighted avg       0.71      0.55      0.45      5115\n",
      "\n",
      "[[ 276 2251]\n",
      " [  32 2556]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.17888563049853373\n",
      "naive bayes has precision on testing 0.21804511278195488\n",
      "naive bayes has recall on testing 0.11689922480620155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.16      0.28      0.20      1890\n",
      "           1       0.22      0.12      0.15      3225\n",
      "\n",
      "   micro avg       0.18      0.18      0.18      5115\n",
      "   macro avg       0.19      0.20      0.18      5115\n",
      "weighted avg       0.20      0.18      0.17      5115\n",
      "\n",
      "[[ 538 1352]\n",
      " [2848  377]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8265884652981427\n",
      "svm has precision on validation 0.7515527950310559\n",
      "svm has recall on validation 0.981839258114374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.67      0.79      2527\n",
      "           1       0.75      0.98      0.85      2588\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.86      0.82      0.82      5115\n",
      "weighted avg       0.86      0.83      0.82      5115\n",
      "\n",
      "[[1687  840]\n",
      " [  47 2541]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8482893450635386\n",
      "svm has precision on testing 0.8383531362254767\n",
      "svm has recall on testing 0.9407751937984496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.69      0.77      1890\n",
      "           1       0.84      0.94      0.89      3225\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.82      0.83      5115\n",
      "weighted avg       0.85      0.85      0.84      5115\n",
      "\n",
      "[[1305  585]\n",
      " [ 191 3034]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8592375366568915\n",
      "random forest has precision on validation 0.815114709851552\n",
      "random forest has recall on validation 0.9335394126738794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.78      0.85      2527\n",
      "           1       0.82      0.93      0.87      2588\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.86      0.86      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[1979  548]\n",
      " [ 172 2416]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7702834799608993\n",
      "random forest has precision on testing 0.8972868217054264\n",
      "random forest has recall on testing 0.7178294573643411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.86      0.73      1890\n",
      "           1       0.90      0.72      0.80      3225\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.79      0.77      5115\n",
      "weighted avg       0.80      0.77      0.77      5115\n",
      "\n",
      "[[1625  265]\n",
      " [ 910 2315]]\n",
      "============================================================\n",
      "29.949082999999973 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.clock()\n",
    "\n",
    "dt_val_acc = []\n",
    "dt_testing_acc = []\n",
    "\n",
    "log_val_acc = []\n",
    "log_testing_acc = []\n",
    "\n",
    "nb_val_acc = []\n",
    "nb_testing_acc = []\n",
    "\n",
    "svm_val_acc = []\n",
    "svm_testing_acc = []\n",
    "\n",
    "rf_val_acc = []\n",
    "rf_testing_acc = []\n",
    "\n",
    "\n",
    "training_data_split = cut(data, 9)\n",
    "training_label_split = cut(training_label_total, 9)\n",
    "\n",
    "validation_data_split = cut(validation_data, 9)\n",
    "validation_label_split = cut(validation_label_total, 9)\n",
    "\n",
    "# print (training_data_split[2])\n",
    "\n",
    "for i in range (0, 9):\n",
    "    training_sub_list = []\n",
    "    training_sub_list.append(training_data_split[i])\n",
    "    training_sub_list.append(training_label_split[i])\n",
    "    \n",
    "    validation_sub_list = []\n",
    "    validation_sub_list.append(validation_data_split[i])\n",
    "    validation_sub_list.append(validation_label_split[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1 = tree.DecisionTreeClassifier()\n",
    "    dt_model = model1.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    dt_result = dt_model.predict(validation_sub_list[0])\n",
    "    dt_testing_result = dt_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"decision tree has accuracy on validation\", accuracy_score(validation_sub_list[-1], dt_result))\n",
    "    dt_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], dt_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on validation\", precision_score(validation_sub_list[-1], dt_result))\n",
    "    print (\"decision tree has recall on validation\", recall_score(validation_sub_list[-1], dt_result))\n",
    "    print (classification_report(validation_sub_list[-1], dt_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], dt_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"decision tree has accuracy on testing\", accuracy_score(testing_label_total, dt_testing_result))\n",
    "    dt_testing_acc.append(float(format(accuracy_score(testing_label_total, dt_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on testing\", precision_score(testing_label_total, dt_testing_result))\n",
    "    print (\"decision tree has recall on testing\", recall_score(testing_label_total, dt_testing_result))\n",
    "    print (classification_report(testing_label_total, dt_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, dt_testing_result))    \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model2 = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr')\n",
    "    log_model = model2.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    log_result = log_model.predict(validation_sub_list[0])\n",
    "    log_testing_result = log_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"log reg has accuracy on validation\", accuracy_score(validation_sub_list[-1], log_result))\n",
    "    log_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], log_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on validation\", precision_score(validation_sub_list[-1], log_result))\n",
    "    print (\"log reg has recall on validation\", recall_score(validation_sub_list[-1], log_result))\n",
    "    print (classification_report(validation_sub_list[-1], log_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], log_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"log reg has accuracy on testing\", accuracy_score(testing_label_total, log_testing_result))\n",
    "    log_testing_acc.append(float(format(accuracy_score(testing_label_total, log_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on testing\", precision_score(testing_label_total, log_testing_result))\n",
    "    print (\"log reg has recall on testing\", recall_score(testing_label_total, log_testing_result))\n",
    "    print (classification_report(testing_label_total, log_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, log_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "   \n",
    "\n",
    "    \n",
    "    model3 = GaussianNB()\n",
    "    nb_model = model3.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    nb_result = nb_model.predict(validation_sub_list[0])\n",
    "    nb_testing_result = nb_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"naive bayes has accuracy on validation\", accuracy_score(validation_sub_list[-1], nb_result))\n",
    "    nb_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], nb_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on validation\", precision_score(validation_sub_list[-1], nb_result))\n",
    "    print (\"naive bayes has recall on validation\", recall_score(validation_sub_list[-1], nb_result))\n",
    "    print (classification_report(validation_sub_list[-1], nb_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], nb_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"naive bayes has accuracy on testing\", accuracy_score(testing_label_total, nb_testing_result))\n",
    "    nb_testing_acc.append(float(format(accuracy_score(testing_label_total, nb_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on testing\", precision_score(testing_label_total, nb_testing_result))\n",
    "    print (\"naive bayes has recall on testing\", recall_score(testing_label_total, nb_testing_result))\n",
    "    print (classification_report(testing_label_total, nb_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, nb_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model4 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    svm_model = model4.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    svm_result = svm_model.predict(validation_sub_list[0])\n",
    "    svm_testing_result = svm_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"svm has accuracy on validation\", accuracy_score(validation_sub_list[-1], svm_result))\n",
    "    svm_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], svm_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on validation\", precision_score(validation_sub_list[-1], svm_result))\n",
    "    print (\"svm has recall on validation\", recall_score(validation_sub_list[-1], svm_result))\n",
    "    print (classification_report(validation_sub_list[-1], svm_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], svm_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"svm has accuracy on testing\", accuracy_score(testing_label_total, svm_testing_result))\n",
    "    svm_testing_acc.append(float(format(accuracy_score(testing_label_total, svm_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on testing\", precision_score(testing_label_total, svm_testing_result))\n",
    "    print (\"svm has recall on testing\", recall_score(testing_label_total, svm_testing_result))\n",
    "    print (classification_report(testing_label_total, svm_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, svm_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model5 = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n",
    "    rf_model = model5.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    rf_result = rf_model.predict(validation_sub_list[0])\n",
    "    rf_testing_result = rf_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"random forest has accuracy on validation\", accuracy_score(validation_sub_list[-1], rf_result))\n",
    "    rf_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], rf_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on validation\", precision_score(validation_sub_list[-1], rf_result))\n",
    "    print (\"random forest has recall on validation\", recall_score(validation_sub_list[-1], rf_result))\n",
    "    print (classification_report(validation_sub_list[-1], rf_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], rf_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"random forest has accuracy on testing\", accuracy_score(testing_label_total, rf_testing_result))\n",
    "    rf_testing_acc.append(float(format(accuracy_score(testing_label_total, rf_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on testing\", precision_score(testing_label_total, rf_testing_result))\n",
    "    print (\"random forest has recall on testing\", recall_score(testing_label_total, rf_testing_result))\n",
    "    print (classification_report(testing_label_total, rf_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, rf_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "end = time.clock()\n",
    "print ((end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.754, 0.787, 0.779, 0.795, 0.785, 0.798, 0.752, 0.819, 0.79]\n",
      "[0.562, 0.771, 0.733, 0.37, 0.777, 0.667, 0.17, 0.371, 0.518] "
     ]
    }
   ],
   "source": [
    "print (dt_val_acc, end = \"\\n\")\n",
    "print (dt_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.785, 0.846, 0.798, 0.668, 0.831, 0.836, 0.775, 0.817, 0.769]\n",
      "[0.416, 0.795, 0.431, 0.628, 0.429, 0.437, 0.443, 0.635, 0.633] "
     ]
    }
   ],
   "source": [
    "print (log_val_acc, end = \"\\n\")\n",
    "print (log_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55, 0.564, 0.592, 0.521, 0.679, 0.743, 0.751, 0.61, 0.554]\n",
      "[0.37, 0.373, 0.37, 0.63, 0.37, 0.37, 0.369, 0.193, 0.179] "
     ]
    }
   ],
   "source": [
    "print (nb_val_acc, end = \"\\n\")\n",
    "print (nb_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.785, 0.806, 0.795, 0.839, 0.833, 0.841, 0.779, 0.843, 0.827]\n",
      "[0.418, 0.403, 0.421, 0.412, 0.424, 0.435, 0.425, 0.853, 0.848] "
     ]
    }
   ],
   "source": [
    "print (svm_val_acc, end = \"\\n\")\n",
    "print (svm_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.804, 0.832, 0.825, 0.865, 0.846, 0.861, 0.814, 0.869, 0.859]\n",
      "[0.77, 0.771, 0.77, 0.77, 0.77, 0.771, 0.771, 0.77, 0.77] "
     ]
    }
   ],
   "source": [
    "print (rf_val_acc, end = \"\\n\")\n",
    "print (rf_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
