{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import math \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/Desktop/analysis/code\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/wuyue/Desktop/analysis/stock/\"\n",
    "files = os.listdir(path)\n",
    "valid_file = []\n",
    "\n",
    "for file in files:\n",
    "    if file[-4:] == \".csv\":\n",
    "        valid_file.append(file)\n",
    "        \n",
    "print (len(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the fuctions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sign of a number\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    else:\n",
    "        return (0)\n",
    "    \n",
    "  \n",
    "def sgn_0(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    if x < 0:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "# the number of pos and neg in a list determine the general trend\n",
    "def sgn_num(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += 1\n",
    "        if i <= 0:\n",
    "            ne += 1\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)    \n",
    "\n",
    "# the value of pos and neg sum determine the \n",
    "def sgn_total(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += i\n",
    "        if i <= 0:\n",
    "            ne += abs(i)\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "def sqrt_abs(x):\n",
    "    if x > 0:\n",
    "        return math.log(x, 10)\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -math.log(abs(x), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_split(l, m):\n",
    "    n = int(math.ceil(len(l)/float(m)))\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def mix(l):\n",
    "    res_sum = []\n",
    "    for i in range(0, len(l[0])):\n",
    "        res = []\n",
    "        for lst in l:\n",
    "            res.append(lst[i])\n",
    "        res_sum.append(res)\n",
    "    return res_sum\n",
    "\n",
    "def cut(l, n):\n",
    "    res = []\n",
    "    for i in range(0, n):\n",
    "        res.append(l[i::n])\n",
    "    return res\n",
    "\n",
    "def slic(l, n, m):\n",
    "    res = []\n",
    "    for i in range (1, n+1):\n",
    "        res.append(l[60*i+1:60*i+m+1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n",
      "31.291112983333335 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "training_data_total = []\n",
    "training_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_part = open_price[-700:]\n",
    "            open_price_list = open_price[-700:-100]\n",
    "            open_price_list_split = chunks(open_price_list, 60)\n",
    "            open_price_list_testing = open_price[-100:]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_part = high_price[-700:]\n",
    "            high_price_list = high_price[-700:-100]\n",
    "            high_price_list_split = chunks(high_price_list, 60)\n",
    "            high_price_list_testing = high_price[-100:]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_part = low_price[-700:]\n",
    "            low_price_list = low_price[-700:-100]\n",
    "            low_price_list_split = chunks(low_price_list, 60)\n",
    "            low_price_list_testing = low_price[-100:]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_part = close_price[-700:]\n",
    "            close_price_list = close_price[-700:-100]\n",
    "            close_price_list_split = chunks(close_price_list, 60)\n",
    "            close_price_list_testing = close_price[-100:]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_part = volume[-700:]\n",
    "            volume_list = volume[-700:-100]\n",
    "            volume_list_split = chunks(volume_list, 60)\n",
    "            volume_list_testing = volume[-100:]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_part = change[-700:]\n",
    "            change_list = change[-700:-100]\n",
    "            change_list_split = chunks(change_list, 60)\n",
    "            change_list_testing = change[-100:]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_part = typical_price[-700:]\n",
    "            typical_price_list = typical_price[-700:-100]\n",
    "            typical_price_list_split = chunks(typical_price_list, 60)\n",
    "            typical_price_list_testing = typical_price[-100:]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_part = middle_price[-700:]\n",
    "            middle_price_list = middle_price[-700:-100]\n",
    "            middle_price_list_split = chunks(middle_price_list, 60)\n",
    "            middle_price_list_testing = middle_price[-100:]\n",
    "    \n",
    "    training_list = [open_price_list_split, high_price_list_split, low_price_list_split, close_price_list_split, \\\n",
    "                    volume_list_split, change_list_split, typical_price_list_split, middle_price_list_split]\n",
    "\n",
    "    training_list_mixed = mix(training_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in training_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 49\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/51\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/26\n",
    "        EMA_25 = []\n",
    "        for i in range(26,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-24:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        training_data = stock_feature_list[:-1]\n",
    "        training_data_total.append(training_data)\n",
    "        \n",
    "        training_label = stock_feature_list[-1]\n",
    "        training_label_total.append(training_label)\n",
    "        \n",
    "\n",
    "print (len(training_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n"
     ]
    }
   ],
   "source": [
    "transformer = RobustScaler().fit(training_data_total)\n",
    "data = transformer.transform(training_data_total)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the validation model 5 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46035\n",
      "24.310094166666666 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "validation_data_total = []\n",
    "validation_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list = open_price[-700:]\n",
    "            open_price_list_split_5 = slic(open_price_list, 9, 28)\n",
    "            \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list = high_price[-700:]\n",
    "            high_price_list_split_5 = slic(high_price_list, 9, 28)\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list = low_price[-700:]\n",
    "            low_price_list_split_5 = slic(low_price_list, 9, 28)\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list = close_price[-700:]\n",
    "            close_price_list_split_5 = slic(close_price_list, 9, 28)\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list = volume[-700:]\n",
    "            volume_list_split_5 = slic(volume_list, 9, 28)\n",
    "        \n",
    "            change.append(row[7])\n",
    "            change_list = change[-700:]\n",
    "            change_list_split_5 = slic(change_list, 9, 28)\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list = typical_price[-700:]\n",
    "            typical_price_list_split_5 = slic(typical_price_list, 9, 28)\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list = middle_price[-700:]\n",
    "            middle_price_list_split_5 = slic(middle_price_list, 9, 28)\n",
    "    \n",
    "    validation_list = [open_price_list_split_5, high_price_list_split_5, low_price_list_split_5, close_price_list_split_5, \\\n",
    "                    volume_list_split_5, change_list_split_5, typical_price_list_split_5, middle_price_list_split_5]\n",
    "\n",
    "    validation_list_mixed = mix(validation_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in validation_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/(negative_money_flow+1))\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 4\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/6\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/3\n",
    "        EMA_25 = []\n",
    "        for i in range(3,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-2:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/(1+cr_neg_sum))\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        validation_data = stock_feature_list[:-1]\n",
    "        validation_data_total.append(validation_data)\n",
    "        \n",
    "        validation_label = stock_feature_list[-1]\n",
    "        validation_label_total.append(validation_label)\n",
    "        \n",
    "\n",
    "print (len(validation_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_v = RobustScaler().fit(validation_data_total)\n",
    "validation_data = transformer_v.transform(validation_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3.0550746499999986 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "testing_data_total = []\n",
    "testing_label_total = []\n",
    "testing_list_total = []\n",
    "\n",
    "count_term=1\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list_testing = open_price[-100:-72]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list_testing = high_price[-100:-72]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list_testing = low_price[-100:-72]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list_testing = close_price[-100:-72]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list_testing = volume[-100:-72]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_list_testing = change[-100:-72]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list_testing = typical_price[-100:-72]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list_testing = middle_price[-100:-72]\n",
    "    \n",
    "    testing_list = [open_price_list_testing, high_price_list_testing, low_price_list_testing, close_price_list_testing, \\\n",
    "                    volume_list_testing, change_list_testing, typical_price_list_testing, middle_price_list_testing]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_list = []\n",
    "    abs_list = []\n",
    "    \n",
    "    for flt in testing_list[5]:\n",
    "        abs_list.append(abs(flt))\n",
    "        if flt > 0:\n",
    "            pos_list.append(flt)\n",
    "    \n",
    "    abs_sum = float('%.3f' % sum(abs_list))\n",
    "    pos_sum = float('%.3f' % sum(pos_list))\n",
    "    raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "    RSI = float('%.3f' % raw_rsi)\n",
    "    stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    indicator_list = [0.5] \n",
    "    \n",
    "    money_flow_list = [vol*tp for vol, tp in zip(testing_list[4], testing_list[6])]\n",
    "    total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "    for i in range(len(testing_list[6])-1):\n",
    "        det = sgn(float('%.2f' % (testing_list[6][i+1] - testing_list[6][i])))\n",
    "        indicator_list.append(det)\n",
    "       \n",
    "    positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "    positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "    negative_money_flow = total_money_flow - positive_money_flow\n",
    "    money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "    raw_mfi = 100-100/(1+money_rate)\n",
    "    MFI = float('%.3f' % raw_mfi)\n",
    "    stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "    if len(testing_list[3]) >= 3:\n",
    "        raw_rsv = 100*(close_price_list_testing[-1] - min(close_price_list_testing))/(max(close_price_list_testing) - min(close_price_list_testing))\n",
    "    RSV = float('%.3f' % raw_rsv)\n",
    "    stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = testing_list[3][-1] - testing_list[3][-5]\n",
    "    bx = testing_list[3][-5]\n",
    "    raw_roc = 100*ax/bx\n",
    "    ROC = float('%.3f' % raw_roc)\n",
    "    stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "    square_sum_5 = []\n",
    "    TP_5 = mean(testing_list[6][-5:])\n",
    "    MA_5 = mean(testing_list[3][-5:])\n",
    "    for i in testing_list[3][-5:]:\n",
    "        square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "    raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "    CCI = float('%.3f' % raw_cci)\n",
    "    stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "    vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(testing_list[3], testing_list[1], testing_list[2])))\n",
    "    \n",
    "    va = []\n",
    "    va_change_list = []\n",
    "    va.append(testing_list[4][0])\n",
    "    \n",
    "    for i in range(0, len(testing_list[4])-1):\n",
    "        va.append(va[i] + vol_para[i]*testing_list[4][i+1])\n",
    "    \n",
    "    for i in range(0, len(va)-1):\n",
    "        va_change_list.append(va[i+1] - va[i])\n",
    "    va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "    if abs(va_change_rate) > 0.1:\n",
    "        VA = sgn(va_change_rate)\n",
    "    else:\n",
    "        VA = sgn_num(va_change_list)\n",
    "    stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    closing_change_list = []\n",
    "\n",
    "    for i in range(0, len(testing_list[3])-1):\n",
    "        closing_change_list.append(testing_list[3][i+1]-testing_list[3][i])\n",
    "   \n",
    "    closing_price_list_pvt = testing_list[3][1:]\n",
    "    volume_list_pvt = volume_list_testing[1:]\n",
    "    pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "    raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "    PVT = float('%.3f' % raw_pvt)\n",
    "    stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sign_closing_change_list = []\n",
    "    for i in closing_change_list:\n",
    "        sign_closing_change_list.append(sgn_0(i))\n",
    "    obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, testing_list[4][1:])))\n",
    "    raw_obv = sqrt_abs(sum(obv_list))\n",
    "    OBV = float('%.3f' % raw_obv)\n",
    "    stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exp_len = 49\n",
    "    exp_starting = len(testing_list[3]) - exp_len\n",
    "    price_list_50 = [mean(testing_list[3][:exp_starting])] + testing_list[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "    const_50 = 2/51\n",
    "    EMA_50 = []\n",
    "    for i in range(1,len(price_list_50)):\n",
    "        raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "        ema_50 = float('%.3f' % raw_ema_50)\n",
    "        EMA_50.append(ema_50)\n",
    "    \n",
    "    const_25 = 2/26\n",
    "    EMA_25 = []\n",
    "    for i in range(26,len(price_list_50)):\n",
    "        raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "        ema_25 = float('%.3f' % raw_ema_25)\n",
    "        EMA_25.append(ema_25)\n",
    "        \n",
    "    EMA_50c = EMA_50[-24:]\n",
    "    EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "    EMA_mean = np.mean(EMA_diff)*100\n",
    "    EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "    stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "    stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "    stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cr_pos = []\n",
    "    cr_neg = []\n",
    "    \n",
    "    middle_price_list_c = testing_list[7][:-1]\n",
    "    closing_price_list_c = testing_list[3][1:]\n",
    "    cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "    for i in cr_list:\n",
    "        if i > 0:\n",
    "            cr_pos.append(i)\n",
    "        else:\n",
    "            cr_neg.append(abs(i))\n",
    "    \n",
    "    cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "    cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "    raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "    CR = float('%.3f' % raw_cr)\n",
    "    stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "    square_sum = []\n",
    "    MA = mean(testing_list[3])\n",
    "    MB = mean(testing_list[3][:-1])\n",
    "    \n",
    "    for i in testing_list[3]:\n",
    "        square_sum.append((i-MA)**2)\n",
    "    MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "    raw_UP = MB+2*MD\n",
    "    raw_DN = MB-2*MD\n",
    "    UP = float('%.3f' % raw_UP)\n",
    "    DN = float('%.3f' % raw_DN)\n",
    "    stock_feature_dict[\"UP\"] = UP\n",
    "    stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        \n",
    "    if testing_list[3][-1] > testing_list[3][0]:\n",
    "        stock_feature_dict[\"change_c\"] = 1\n",
    "    else:\n",
    "        stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "    stock_feature_list = list(stock_feature_dict.values())\n",
    "    stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "    stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "    testing_data = stock_feature_list[:-1]\n",
    "    testing_data_total.append(testing_data)\n",
    "        \n",
    "    testing_label = stock_feature_list[-1]\n",
    "    testing_label_total.append(testing_label)\n",
    "\n",
    "    \n",
    "    \n",
    "print (len(testing_list_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_testing = RobustScaler().fit(testing_data_total)\n",
    "data_testing = transformer_testing.transform(testing_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree has accuracy on validation 0.7882697947214077\n",
      "decision tree has precision on validation 0.7464991023339318\n",
      "decision tree has recall on validation 0.8464983713355049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.73      0.78      2659\n",
      "           1       0.75      0.85      0.79      2456\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1953  706]\n",
      " [ 377 2079]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5057673509286412\n",
      "decision tree has precision on testing 0.8545135845749343\n",
      "decision tree has recall on testing 0.2921786035361103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.91      0.56      1778\n",
      "           1       0.85      0.29      0.44      3337\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      5115\n",
      "   macro avg       0.63      0.60      0.50      5115\n",
      "weighted avg       0.70      0.51      0.48      5115\n",
      "\n",
      "[[1612  166]\n",
      " [2362  975]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8258064516129032\n",
      "log reg has precision on validation 0.7667916808728265\n",
      "log reg has recall on validation 0.9157166123778502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.74      0.82      2659\n",
      "           1       0.77      0.92      0.83      2456\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.83      0.83      5115\n",
      "weighted avg       0.84      0.83      0.82      5115\n",
      "\n",
      "[[1975  684]\n",
      " [ 207 2249]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.3479960899315738\n",
      "log reg has precision on testing 0.75\n",
      "log reg has recall on testing 0.0008990110878034162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.75      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.55      0.50      0.26      5115\n",
      "weighted avg       0.61      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3334    3]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.49638318670576737\n",
      "naive bayes has precision on validation 0.4880335061826885\n",
      "naive bayes has recall on validation 0.9963355048859935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.03      0.07      2659\n",
      "           1       0.49      1.00      0.66      2456\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      5115\n",
      "   macro avg       0.70      0.52      0.36      5115\n",
      "weighted avg       0.71      0.50      0.35      5115\n",
      "\n",
      "[[  92 2567]\n",
      " [   9 2447]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3474095796676442\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.17      0.50      0.26      5115\n",
      "weighted avg       0.12      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3337    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8246334310850439\n",
      "svm has precision on validation 0.7654068777664284\n",
      "svm has recall on validation 0.9153094462540716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.74      0.81      2659\n",
      "           1       0.77      0.92      0.83      2456\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.83      0.83      0.82      5115\n",
      "weighted avg       0.84      0.82      0.82      5115\n",
      "\n",
      "[[1970  689]\n",
      " [ 208 2248]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3479960899315738\n",
      "svm has precision on testing 0.75\n",
      "svm has recall on testing 0.0008990110878034162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.75      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.55      0.50      0.26      5115\n",
      "weighted avg       0.61      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3334    3]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8494623655913979\n",
      "random forest has precision on validation 0.8012866333095068\n",
      "random forest has recall on validation 0.9128664495114006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.79      0.85      2659\n",
      "           1       0.80      0.91      0.85      2456\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.85      0.85      0.85      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[2103  556]\n",
      " [ 214 2242]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7460410557184751\n",
      "random forest has precision on testing 0.8234920634920635\n",
      "random forest has recall on testing 0.7773449205873539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.65      1778\n",
      "           1       0.82      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1222  556]\n",
      " [ 743 2594]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8365591397849462\n",
      "decision tree has precision on validation 0.6368386675375571\n",
      "decision tree has recall on validation 0.7768924302788844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.86      0.89      3860\n",
      "           1       0.64      0.78      0.70      1255\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.78      0.82      0.79      5115\n",
      "weighted avg       0.85      0.84      0.84      5115\n",
      "\n",
      "[[3304  556]\n",
      " [ 280  975]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5763440860215053\n",
      "decision tree has precision on testing 0.6425438596491229\n",
      "decision tree has recall on testing 0.7902307461792029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.31      0.17      0.22      1778\n",
      "           1       0.64      0.79      0.71      3337\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      5115\n",
      "   macro avg       0.48      0.48      0.47      5115\n",
      "weighted avg       0.53      0.58      0.54      5115\n",
      "\n",
      "[[ 311 1467]\n",
      " [ 700 2637]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8875855327468231\n",
      "log reg has precision on validation 0.7297297297297297\n",
      "log reg has recall on validation 0.8605577689243028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.90      0.92      3860\n",
      "           1       0.73      0.86      0.79      1255\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5115\n",
      "   macro avg       0.84      0.88      0.86      5115\n",
      "weighted avg       0.90      0.89      0.89      5115\n",
      "\n",
      "[[3460  400]\n",
      " [ 175 1080]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.5953079178885631\n",
      "log reg has precision on testing 0.9922299922299922\n",
      "log reg has recall on testing 0.38267905304165417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.99      0.63      1778\n",
      "           1       0.99      0.38      0.55      3337\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.73      0.69      0.59      5115\n",
      "weighted avg       0.81      0.60      0.58      5115\n",
      "\n",
      "[[1768   10]\n",
      " [2060 1277]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.34271749755620723\n",
      "naive bayes has precision on validation 0.2718215291314707\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.13      0.23      3860\n",
      "           1       0.27      1.00      0.43      1255\n",
      "\n",
      "   micro avg       0.34      0.34      0.34      5115\n",
      "   macro avg       0.64      0.56      0.33      5115\n",
      "weighted avg       0.82      0.34      0.28      5115\n",
      "\n",
      "[[ 498 3362]\n",
      " [   0 1255]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3487781036168133\n",
      "naive bayes has precision on testing 0.7142857142857143\n",
      "naive bayes has recall on testing 0.0029967036260113876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.71      0.00      0.01      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.53      0.50      0.26      5115\n",
      "weighted avg       0.59      0.35      0.18      5115\n",
      "\n",
      "[[1774    4]\n",
      " [3327   10]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8494623655913979\n",
      "svm has precision on validation 0.6531901452937461\n",
      "svm has recall on validation 0.8239043824701195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.86      0.90      3860\n",
      "           1       0.65      0.82      0.73      1255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.80      0.84      0.81      5115\n",
      "weighted avg       0.87      0.85      0.85      5115\n",
      "\n",
      "[[3311  549]\n",
      " [ 221 1034]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.34760508308895405\n",
      "svm has precision on testing 0.5\n",
      "svm has recall on testing 0.00029967036260113877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.50      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.42      0.50      0.26      5115\n",
      "weighted avg       0.45      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3336    1]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8703812316715542\n",
      "random forest has precision on validation 0.6907216494845361\n",
      "random forest has recall on validation 0.8541832669322709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.91      3860\n",
      "           1       0.69      0.85      0.76      1255\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.82      0.86      0.84      5115\n",
      "weighted avg       0.89      0.87      0.87      5115\n",
      "\n",
      "[[3380  480]\n",
      " [ 183 1072]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7470185728250245\n",
      "random forest has precision on testing 0.8252148997134671\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.66      1778\n",
      "           1       0.83      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1229  549]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8031280547409579\n",
      "decision tree has precision on validation 0.8196943972835314\n",
      "decision tree has recall on validation 0.8352941176470589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.76      0.77      2225\n",
      "           1       0.82      0.84      0.83      2890\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1694  531]\n",
      " [ 476 2414]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7687194525904203\n",
      "decision tree has precision on testing 0.8338499690018599\n",
      "decision tree has recall on testing 0.8061132753970632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.70      0.68      1778\n",
      "           1       0.83      0.81      0.82      3337\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.75      0.75      0.75      5115\n",
      "weighted avg       0.77      0.77      0.77      5115\n",
      "\n",
      "[[1242  536]\n",
      " [ 647 2690]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8281524926686217\n",
      "log reg has precision on validation 0.8191050460171374\n",
      "log reg has recall on validation 0.8930795847750865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.74      0.79      2225\n",
      "           1       0.82      0.89      0.85      2890\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.83      0.82      0.82      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1655  570]\n",
      " [ 309 2581]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.3487781036168133\n",
      "log reg has precision on testing 1.0\n",
      "log reg has recall on testing 0.0017980221756068325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       1.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.67      0.50      0.26      5115\n",
      "weighted avg       0.77      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3331    6]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6447702834799609\n",
      "naive bayes has precision on validation 0.6142218437300404\n",
      "naive bayes has recall on validation 0.9982698961937716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.19      0.31      2225\n",
      "           1       0.61      1.00      0.76      2890\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.80      0.59      0.54      5115\n",
      "weighted avg       0.78      0.64      0.57      5115\n",
      "\n",
      "[[ 413 1812]\n",
      " [   5 2885]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.34760508308895405\n",
      "naive bayes has precision on testing 0.5\n",
      "naive bayes has recall on testing 0.00029967036260113877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.50      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.42      0.50      0.26      5115\n",
      "weighted avg       0.45      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3336    1]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.827761485826002\n",
      "svm has precision on validation 0.8198026106335562\n",
      "svm has recall on validation 0.8910034602076125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.75      0.79      2225\n",
      "           1       0.82      0.89      0.85      2890\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.83      0.82      0.82      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1659  566]\n",
      " [ 315 2575]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3478005865102639\n",
      "svm has precision on testing 0.6666666666666666\n",
      "svm has recall on testing 0.0005993407252022775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.67      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.51      0.50      0.26      5115\n",
      "weighted avg       0.56      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3335    2]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8541544477028348\n",
      "random forest has precision on validation 0.8442517662170841\n",
      "random forest has recall on validation 0.9096885813148788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.78      0.82      2225\n",
      "           1       0.84      0.91      0.88      2890\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.85      0.85      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[1740  485]\n",
      " [ 261 2629]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7458455522971652\n",
      "random forest has precision on testing 0.8230256898192198\n",
      "random forest has recall on testing 0.7776445909499551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.65      1778\n",
      "           1       0.82      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1220  558]\n",
      " [ 742 2595]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8027370478983382\n",
      "decision tree has precision on validation 0.8746483276023758\n",
      "decision tree has recall on validation 0.8214914856136231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.77      0.72      1709\n",
      "           1       0.87      0.82      0.85      3406\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.78      0.79      0.78      5115\n",
      "weighted avg       0.81      0.80      0.81      5115\n",
      "\n",
      "[[1308  401]\n",
      " [ 608 2798]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.20821114369501467\n",
      "decision tree has precision on testing 0.27620841180163214\n",
      "decision tree has recall on testing 0.13185495954450105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.18      0.35      0.24      1778\n",
      "           1       0.28      0.13      0.18      3337\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      5115\n",
      "   macro avg       0.23      0.24      0.21      5115\n",
      "weighted avg       0.24      0.21      0.20      5115\n",
      "\n",
      "[[ 625 1153]\n",
      " [2897  440]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.6013685239491691\n",
      "log reg has precision on validation 0.7443689667500893\n",
      "log reg has recall on validation 0.6112742219612448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.43      0.58      0.49      1709\n",
      "           1       0.74      0.61      0.67      3406\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.59      0.60      0.58      5115\n",
      "weighted avg       0.64      0.60      0.61      5115\n",
      "\n",
      "[[ 994  715]\n",
      " [1324 2082]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.5872922776148582\n",
      "log reg has precision on testing 0.753305785123967\n",
      "log reg has recall on testing 0.5462990710218759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      0.66      0.53      1778\n",
      "           1       0.75      0.55      0.63      3337\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.60      0.61      0.58      5115\n",
      "weighted avg       0.64      0.59      0.60      5115\n",
      "\n",
      "[[1181  597]\n",
      " [1514 1823]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6658846529814272\n",
      "naive bayes has precision on validation 0.6658846529814272\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1709\n",
      "           1       0.67      1.00      0.80      3406\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.33      0.50      0.40      5115\n",
      "weighted avg       0.44      0.67      0.53      5115\n",
      "\n",
      "[[   0 1709]\n",
      " [   0 3406]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.6523949169110459\n",
      "naive bayes has precision on testing 0.6523949169110459\n",
      "naive bayes has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1778\n",
      "           1       0.65      1.00      0.79      3337\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.33      0.50      0.39      5115\n",
      "weighted avg       0.43      0.65      0.52      5115\n",
      "\n",
      "[[   0 1778]\n",
      " [   0 3337]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8742913000977517\n",
      "svm has precision on validation 0.9021834061135371\n",
      "svm has recall on validation 0.9098649442160892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.80      0.81      1709\n",
      "           1       0.90      0.91      0.91      3406\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.86      0.86      0.86      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1373  336]\n",
      " [ 307 3099]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.34760508308895405\n",
      "svm has precision on testing 0.5\n",
      "svm has recall on testing 0.00029967036260113877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.50      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.42      0.50      0.26      5115\n",
      "weighted avg       0.45      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3336    1]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8811339198435972\n",
      "random forest has precision on validation 0.9008595988538682\n",
      "random forest has recall on validation 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.80      0.82      1709\n",
      "           1       0.90      0.92      0.91      3406\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.87      0.86      0.86      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1363  346]\n",
      " [ 262 3144]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7478005865102639\n",
      "random forest has precision on testing 0.8266836897542291\n",
      "random forest has recall on testing 0.7761462391369494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.66      1778\n",
      "           1       0.83      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.74      0.73      5115\n",
      "weighted avg       0.76      0.75      0.75      5115\n",
      "\n",
      "[[1235  543]\n",
      " [ 747 2590]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7982404692082111\n",
      "decision tree has precision on validation 0.8176934097421203\n",
      "decision tree has recall on validation 0.8136136849607983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.78      0.78      2309\n",
      "           1       0.82      0.81      0.82      2806\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1800  509]\n",
      " [ 523 2283]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.6701857282502444\n",
      "decision tree has precision on testing 0.6935710933833881\n",
      "decision tree has recall on testing 0.8858255918489661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.27      0.36      1778\n",
      "           1       0.69      0.89      0.78      3337\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.62      0.58      0.57      5115\n",
      "weighted avg       0.64      0.67      0.63      5115\n",
      "\n",
      "[[ 472 1306]\n",
      " [ 381 2956]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8525904203323558\n",
      "log reg has precision on validation 0.8342019543973941\n",
      "log reg has recall on validation 0.9126870990734142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.78      0.83      2309\n",
      "           1       0.83      0.91      0.87      2806\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.85      0.85      5115\n",
      "weighted avg       0.85      0.85      0.85      5115\n",
      "\n",
      "[[1800  509]\n",
      " [ 245 2561]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.3487781036168133\n",
      "log reg has precision on testing 1.0\n",
      "log reg has recall on testing 0.0017980221756068325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       1.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.67      0.50      0.26      5115\n",
      "weighted avg       0.77      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3331    6]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7219941348973608\n",
      "naive bayes has precision on validation 0.6646834840552118\n",
      "naive bayes has recall on validation 0.9953670705630792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.39      0.56      2309\n",
      "           1       0.66      1.00      0.80      2806\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      5115\n",
      "   macro avg       0.83      0.69      0.68      5115\n",
      "weighted avg       0.81      0.72      0.69      5115\n",
      "\n",
      "[[ 900 1409]\n",
      " [  13 2793]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3481915933528837\n",
      "naive bayes has precision on testing 0.6666666666666666\n",
      "naive bayes has recall on testing 0.0017980221756068325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.67      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.51      0.50      0.26      5115\n",
      "weighted avg       0.56      0.35      0.18      5115\n",
      "\n",
      "[[1775    3]\n",
      " [3331    6]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8525904203323558\n",
      "svm has precision on validation 0.8326848249027238\n",
      "svm has recall on validation 0.9151817533856023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.78      0.83      2309\n",
      "           1       0.83      0.92      0.87      2806\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.86      0.85      0.85      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[1793  516]\n",
      " [ 238 2568]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3481915933528837\n",
      "svm has precision on testing 1.0\n",
      "svm has recall on testing 0.0008990110878034162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       1.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.67      0.50      0.26      5115\n",
      "weighted avg       0.77      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3334    3]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8566959921798631\n",
      "random forest has precision on validation 0.8381729200652529\n",
      "random forest has recall on validation 0.9155381325730577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.79      0.83      2309\n",
      "           1       0.84      0.92      0.88      2806\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.85      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1813  496]\n",
      " [ 237 2569]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7470185728250245\n",
      "random forest has precision on testing 0.8252148997134671\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.66      1778\n",
      "           1       0.83      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1229  549]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8152492668621701\n",
      "decision tree has precision on validation 0.8597033374536465\n",
      "decision tree has recall on validation 0.8499847234952643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.75      0.75      1842\n",
      "           1       0.86      0.85      0.85      3273\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1388  454]\n",
      " [ 491 2782]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.6539589442815249\n",
      "decision tree has precision on testing 0.6803222094361335\n",
      "decision tree has recall on testing 0.8858255918489661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.22      0.31      1778\n",
      "           1       0.68      0.89      0.77      3337\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.59      0.55      0.54      5115\n",
      "weighted avg       0.62      0.65      0.61      5115\n",
      "\n",
      "[[ 389 1389]\n",
      " [ 381 2956]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8641251221896383\n",
      "log reg has precision on validation 0.8718984420080784\n",
      "log reg has recall on validation 0.9233119462267033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.76      0.80      1842\n",
      "           1       0.87      0.92      0.90      3273\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1398  444]\n",
      " [ 251 3022]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.3487781036168133\n",
      "log reg has precision on testing 1.0\n",
      "log reg has recall on testing 0.0017980221756068325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       1.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.67      0.50      0.26      5115\n",
      "weighted avg       0.77      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3331    6]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7992179863147605\n",
      "naive bayes has precision on validation 0.7633677298311444\n",
      "naive bayes has recall on validation 0.9945004582951421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.45      0.62      1842\n",
      "           1       0.76      0.99      0.86      3273\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.87      0.72      0.74      5115\n",
      "weighted avg       0.84      0.80      0.78      5115\n",
      "\n",
      "[[ 833 1009]\n",
      " [  18 3255]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3474095796676442\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.17      0.50      0.26      5115\n",
      "weighted avg       0.12      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3337    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8649071358748778\n",
      "svm has precision on validation 0.8707639287765652\n",
      "svm has recall on validation 0.9263672471738467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.76      0.80      1842\n",
      "           1       0.87      0.93      0.90      3273\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1392  450]\n",
      " [ 241 3032]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.34838709677419355\n",
      "svm has precision on testing 0.8333333333333334\n",
      "svm has recall on testing 0.0014983518130056938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.83      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.59      0.50      0.26      5115\n",
      "weighted avg       0.66      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3332    5]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8733137829912023\n",
      "random forest has precision on validation 0.8928464531577373\n",
      "random forest has recall on validation 0.9113962725328445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.81      0.82      1842\n",
      "           1       0.89      0.91      0.90      3273\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.86      0.86      0.86      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1484  358]\n",
      " [ 290 2983]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.747605083088954\n",
      "random forest has precision on testing 0.8260038240917782\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.66      1778\n",
      "           1       0.83      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.76      0.75      0.75      5115\n",
      "\n",
      "[[1232  546]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.78455522971652\n",
      "decision tree has precision on validation 0.7379134860050891\n",
      "decision tree has recall on validation 0.7823741007194245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.79      0.80      2891\n",
      "           1       0.74      0.78      0.76      2224\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.78      0.78      5115\n",
      "weighted avg       0.79      0.78      0.79      5115\n",
      "\n",
      "[[2273  618]\n",
      " [ 484 1740]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.17458455522971653\n",
      "decision tree has precision on testing 0.27225939269171384\n",
      "decision tree has recall on testing 0.1585256218160024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.11      0.20      0.15      1778\n",
      "           1       0.27      0.16      0.20      3337\n",
      "\n",
      "   micro avg       0.17      0.17      0.17      5115\n",
      "   macro avg       0.19      0.18      0.17      5115\n",
      "weighted avg       0.22      0.17      0.18      5115\n",
      "\n",
      "[[ 364 1414]\n",
      " [2808  529]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8381231671554252\n",
      "log reg has precision on validation 0.7853638593622241\n",
      "log reg has recall on validation 0.8637589928057554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.82      0.85      2891\n",
      "           1       0.79      0.86      0.82      2224\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.84      0.84      5115\n",
      "weighted avg       0.84      0.84      0.84      5115\n",
      "\n",
      "[[2366  525]\n",
      " [ 303 1921]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.34916911045943305\n",
      "log reg has precision on testing 1.0\n",
      "log reg has recall on testing 0.00239736290080911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       1.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.67      0.50      0.26      5115\n",
      "weighted avg       0.77      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3329    8]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.8672531769305963\n",
      "naive bayes has precision on validation 0.791839818662637\n",
      "naive bayes has recall on validation 0.9424460431654677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.81      0.87      2891\n",
      "           1       0.79      0.94      0.86      2224\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.88      0.87      5115\n",
      "weighted avg       0.88      0.87      0.87      5115\n",
      "\n",
      "[[2340  551]\n",
      " [ 128 2096]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.34760508308895405\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.00      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.17      0.50      0.26      5115\n",
      "weighted avg       0.12      0.35      0.18      5115\n",
      "\n",
      "[[1778    0]\n",
      " [3337    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8437927663734115\n",
      "svm has precision on validation 0.7867203219315896\n",
      "svm has recall on validation 0.8790467625899281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.82      0.86      2891\n",
      "           1       0.79      0.88      0.83      2224\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.85      0.84      5115\n",
      "weighted avg       0.85      0.84      0.84      5115\n",
      "\n",
      "[[2361  530]\n",
      " [ 269 1955]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3479960899315738\n",
      "svm has precision on testing 0.75\n",
      "svm has recall on testing 0.0008990110878034162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1778\n",
      "           1       0.75      0.00      0.00      3337\n",
      "\n",
      "   micro avg       0.35      0.35      0.35      5115\n",
      "   macro avg       0.55      0.50      0.26      5115\n",
      "weighted avg       0.61      0.35      0.18      5115\n",
      "\n",
      "[[1777    1]\n",
      " [3334    3]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8639296187683284\n",
      "random forest has precision on validation 0.8310225303292894\n",
      "random forest has recall on validation 0.862410071942446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.87      0.88      2891\n",
      "           1       0.83      0.86      0.85      2224\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.86      0.86      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[2501  390]\n",
      " [ 306 1918]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7468230694037146\n",
      "random forest has precision on testing 0.8249522597071929\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.65      1778\n",
      "           1       0.82      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1228  550]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8490713587487781\n",
      "decision tree has precision on validation 0.891425046267736\n",
      "decision tree has recall on validation 0.8731117824773413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.80      0.79      1805\n",
      "           1       0.89      0.87      0.88      3310\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.83      0.84      0.84      5115\n",
      "weighted avg       0.85      0.85      0.85      5115\n",
      "\n",
      "[[1453  352]\n",
      " [ 420 2890]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.3163245356793744\n",
      "decision tree has precision on testing 0.42248062015503873\n",
      "decision tree has recall on testing 0.1306562780940965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.66      0.40      1778\n",
      "           1       0.42      0.13      0.20      3337\n",
      "\n",
      "   micro avg       0.32      0.32      0.32      5115\n",
      "   macro avg       0.36      0.40      0.30      5115\n",
      "weighted avg       0.38      0.32      0.27      5115\n",
      "\n",
      "[[1182  596]\n",
      " [2901  436]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8191593352883676\n",
      "log reg has precision on validation 0.906026557711951\n",
      "log reg has recall on validation 0.8039274924471299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.85      0.77      1805\n",
      "           1       0.91      0.80      0.85      3310\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.80      0.83      0.81      5115\n",
      "weighted avg       0.83      0.82      0.82      5115\n",
      "\n",
      "[[1529  276]\n",
      " [ 649 2661]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6471163245356794\n",
      "log reg has precision on testing 0.6506095163193079\n",
      "log reg has recall on testing 0.9916092298471681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.03      0.00      0.00      1778\n",
      "           1       0.65      0.99      0.79      3337\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.34      0.50      0.39      5115\n",
      "weighted avg       0.44      0.65      0.51      5115\n",
      "\n",
      "[[   1 1777]\n",
      " [  28 3309]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6961876832844575\n",
      "naive bayes has precision on validation 0.6832985386221294\n",
      "naive bayes has recall on validation 0.988821752265861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.16      0.27      1805\n",
      "           1       0.68      0.99      0.81      3310\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.78      0.57      0.54      5115\n",
      "weighted avg       0.75      0.70      0.62      5115\n",
      "\n",
      "[[ 288 1517]\n",
      " [  37 3273]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.2842619745845552\n",
      "naive bayes has precision on testing 0.4485387547649301\n",
      "naive bayes has recall on testing 0.4231345519928079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.02      0.02      0.02      1778\n",
      "           1       0.45      0.42      0.44      3337\n",
      "\n",
      "   micro avg       0.28      0.28      0.28      5115\n",
      "   macro avg       0.23      0.22      0.23      5115\n",
      "weighted avg       0.30      0.28      0.29      5115\n",
      "\n",
      "[[  42 1736]\n",
      " [1925 1412]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8789833822091887\n",
      "svm has precision on validation 0.893306050862321\n",
      "svm has recall on validation 0.923262839879154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.80      0.82      1805\n",
      "           1       0.89      0.92      0.91      3310\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.87      0.86      0.87      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1440  365]\n",
      " [ 254 3056]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8027370478983382\n",
      "svm has precision on testing 0.9529182879377431\n",
      "svm has recall on testing 0.7338927180101887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.93      0.77      1778\n",
      "           1       0.95      0.73      0.83      3337\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.83      0.80      5115\n",
      "weighted avg       0.85      0.80      0.81      5115\n",
      "\n",
      "[[1657  121]\n",
      " [ 888 2449]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8887585532746823\n",
      "random forest has precision on validation 0.90849478390462\n",
      "random forest has recall on validation 0.9208459214501511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.83      0.84      1805\n",
      "           1       0.91      0.92      0.91      3310\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5115\n",
      "   macro avg       0.88      0.88      0.88      5115\n",
      "weighted avg       0.89      0.89      0.89      5115\n",
      "\n",
      "[[1498  307]\n",
      " [ 262 3048]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7468230694037146\n",
      "random forest has precision on testing 0.8249522597071929\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.65      1778\n",
      "           1       0.82      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1228  550]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8189638318670577\n",
      "decision tree has precision on validation 0.8677656962469309\n",
      "decision tree has recall on validation 0.8183923255044657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.82      0.79      2092\n",
      "           1       0.87      0.82      0.84      3023\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1715  377]\n",
      " [ 549 2474]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.6250244379276637\n",
      "decision tree has precision on testing 0.6684872951792923\n",
      "decision tree has recall on testing 0.8435720707222055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.21      0.28      1778\n",
      "           1       0.67      0.84      0.75      3337\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.55      0.53      0.52      5115\n",
      "weighted avg       0.58      0.63      0.59      5115\n",
      "\n",
      "[[ 382 1396]\n",
      " [ 522 2815]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8590420332355816\n",
      "log reg has precision on validation 0.8849498327759198\n",
      "log reg has recall on validation 0.8752894475686405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.84      0.83      2092\n",
      "           1       0.88      0.88      0.88      3023\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.85      0.86      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1748  344]\n",
      " [ 377 2646]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6512218963831867\n",
      "log reg has precision on testing 0.6519866901546291\n",
      "log reg has recall on testing 0.9982019778243931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1778\n",
      "           1       0.65      1.00      0.79      3337\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.33      0.50      0.39      5115\n",
      "weighted avg       0.43      0.65      0.51      5115\n",
      "\n",
      "[[   0 1778]\n",
      " [   6 3331]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7110459433040078\n",
      "naive bayes has precision on validation 0.6759280346162605\n",
      "naive bayes has recall on validation 0.9818061528283163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.32      0.48      2092\n",
      "           1       0.68      0.98      0.80      3023\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5115\n",
      "   macro avg       0.80      0.65      0.64      5115\n",
      "weighted avg       0.78      0.71      0.67      5115\n",
      "\n",
      "[[ 669 1423]\n",
      " [  55 2968]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.25298142717497557\n",
      "naive bayes has precision on testing 0.41768707482993195\n",
      "naive bayes has recall on testing 0.3679952052741984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.03      0.04      0.03      1778\n",
      "           1       0.42      0.37      0.39      3337\n",
      "\n",
      "   micro avg       0.25      0.25      0.25      5115\n",
      "   macro avg       0.22      0.20      0.21      5115\n",
      "weighted avg       0.28      0.25      0.27      5115\n",
      "\n",
      "[[  66 1712]\n",
      " [2109 1228]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8795698924731182\n",
      "svm has precision on validation 0.8924029996739485\n",
      "svm has recall on validation 0.9053919947072444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.84      0.85      2092\n",
      "           1       0.89      0.91      0.90      3023\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.88      0.87      0.88      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1762  330]\n",
      " [ 286 2737]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8371456500488759\n",
      "svm has precision on testing 0.9552727272727273\n",
      "svm has recall on testing 0.7872340425531915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.93      0.80      1778\n",
      "           1       0.96      0.79      0.86      3337\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.83      0.86      0.83      5115\n",
      "weighted avg       0.87      0.84      0.84      5115\n",
      "\n",
      "[[1655  123]\n",
      " [ 710 2627]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8672531769305963\n",
      "random forest has precision on validation 0.8898868928809048\n",
      "random forest has recall on validation 0.8848825669864373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.84      0.84      2092\n",
      "           1       0.89      0.88      0.89      3023\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.86      0.86      0.86      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1761  331]\n",
      " [ 348 2675]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7472140762463343\n",
      "random forest has precision on testing 0.8254777070063695\n",
      "random forest has recall on testing 0.7767455798621516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.66      1778\n",
      "           1       0.83      0.78      0.80      3337\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.72      0.73      0.73      5115\n",
      "weighted avg       0.76      0.75      0.75      5115\n",
      "\n",
      "[[1230  548]\n",
      " [ 745 2592]]\n",
      "============================================================\n",
      "23.516585999999734 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.clock()\n",
    "\n",
    "dt_val_acc = []\n",
    "dt_testing_acc = []\n",
    "\n",
    "log_val_acc = []\n",
    "log_testing_acc = []\n",
    "\n",
    "nb_val_acc = []\n",
    "nb_testing_acc = []\n",
    "\n",
    "svm_val_acc = []\n",
    "svm_testing_acc = []\n",
    "\n",
    "rf_val_acc = []\n",
    "rf_testing_acc = []\n",
    "\n",
    "\n",
    "training_data_split = cut(data, 9)\n",
    "training_label_split = cut(training_label_total, 9)\n",
    "\n",
    "validation_data_split = cut(validation_data, 9)\n",
    "validation_label_split = cut(validation_label_total, 9)\n",
    "\n",
    "# print (training_data_split[2])\n",
    "\n",
    "for i in range (0, 9):\n",
    "    training_sub_list = []\n",
    "    training_sub_list.append(training_data_split[i])\n",
    "    training_sub_list.append(training_label_split[i])\n",
    "    \n",
    "    validation_sub_list = []\n",
    "    validation_sub_list.append(validation_data_split[i])\n",
    "    validation_sub_list.append(validation_label_split[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1 = tree.DecisionTreeClassifier()\n",
    "    dt_model = model1.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    dt_result = dt_model.predict(validation_sub_list[0])\n",
    "    dt_testing_result = dt_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"decision tree has accuracy on validation\", accuracy_score(validation_sub_list[-1], dt_result))\n",
    "    dt_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], dt_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on validation\", precision_score(validation_sub_list[-1], dt_result))\n",
    "    print (\"decision tree has recall on validation\", recall_score(validation_sub_list[-1], dt_result))\n",
    "    print (classification_report(validation_sub_list[-1], dt_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], dt_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"decision tree has accuracy on testing\", accuracy_score(testing_label_total, dt_testing_result))\n",
    "    dt_testing_acc.append(float(format(accuracy_score(testing_label_total, dt_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on testing\", precision_score(testing_label_total, dt_testing_result))\n",
    "    print (\"decision tree has recall on testing\", recall_score(testing_label_total, dt_testing_result))\n",
    "    print (classification_report(testing_label_total, dt_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, dt_testing_result))    \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model2 = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr')\n",
    "    log_model = model2.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    log_result = log_model.predict(validation_sub_list[0])\n",
    "    log_testing_result = log_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"log reg has accuracy on validation\", accuracy_score(validation_sub_list[-1], log_result))\n",
    "    log_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], log_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on validation\", precision_score(validation_sub_list[-1], log_result))\n",
    "    print (\"log reg has recall on validation\", recall_score(validation_sub_list[-1], log_result))\n",
    "    print (classification_report(validation_sub_list[-1], log_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], log_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"log reg has accuracy on testing\", accuracy_score(testing_label_total, log_testing_result))\n",
    "    log_testing_acc.append(float(format(accuracy_score(testing_label_total, log_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on testing\", precision_score(testing_label_total, log_testing_result))\n",
    "    print (\"log reg has recall on testing\", recall_score(testing_label_total, log_testing_result))\n",
    "    print (classification_report(testing_label_total, log_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, log_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "   \n",
    "\n",
    "    \n",
    "    model3 = GaussianNB()\n",
    "    nb_model = model3.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    nb_result = nb_model.predict(validation_sub_list[0])\n",
    "    nb_testing_result = nb_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"naive bayes has accuracy on validation\", accuracy_score(validation_sub_list[-1], nb_result))\n",
    "    nb_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], nb_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on validation\", precision_score(validation_sub_list[-1], nb_result))\n",
    "    print (\"naive bayes has recall on validation\", recall_score(validation_sub_list[-1], nb_result))\n",
    "    print (classification_report(validation_sub_list[-1], nb_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], nb_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"naive bayes has accuracy on testing\", accuracy_score(testing_label_total, nb_testing_result))\n",
    "    nb_testing_acc.append(float(format(accuracy_score(testing_label_total, nb_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on testing\", precision_score(testing_label_total, nb_testing_result))\n",
    "    print (\"naive bayes has recall on testing\", recall_score(testing_label_total, nb_testing_result))\n",
    "    print (classification_report(testing_label_total, nb_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, nb_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model4 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    svm_model = model4.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    svm_result = svm_model.predict(validation_sub_list[0])\n",
    "    svm_testing_result = svm_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"svm has accuracy on validation\", accuracy_score(validation_sub_list[-1], svm_result))\n",
    "    svm_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], svm_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on validation\", precision_score(validation_sub_list[-1], svm_result))\n",
    "    print (\"svm has recall on validation\", recall_score(validation_sub_list[-1], svm_result))\n",
    "    print (classification_report(validation_sub_list[-1], svm_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], svm_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"svm has accuracy on testing\", accuracy_score(testing_label_total, svm_testing_result))\n",
    "    svm_testing_acc.append(float(format(accuracy_score(testing_label_total, svm_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on testing\", precision_score(testing_label_total, svm_testing_result))\n",
    "    print (\"svm has recall on testing\", recall_score(testing_label_total, svm_testing_result))\n",
    "    print (classification_report(testing_label_total, svm_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, svm_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model5 = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n",
    "    rf_model = model5.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    rf_result = rf_model.predict(validation_sub_list[0])\n",
    "    rf_testing_result = rf_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"random forest has accuracy on validation\", accuracy_score(validation_sub_list[-1], rf_result))\n",
    "    rf_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], rf_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on validation\", precision_score(validation_sub_list[-1], rf_result))\n",
    "    print (\"random forest has recall on validation\", recall_score(validation_sub_list[-1], rf_result))\n",
    "    print (classification_report(validation_sub_list[-1], rf_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], rf_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"random forest has accuracy on testing\", accuracy_score(testing_label_total, rf_testing_result))\n",
    "    rf_testing_acc.append(float(format(accuracy_score(testing_label_total, rf_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on testing\", precision_score(testing_label_total, rf_testing_result))\n",
    "    print (\"random forest has recall on testing\", recall_score(testing_label_total, rf_testing_result))\n",
    "    print (classification_report(testing_label_total, rf_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, rf_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "end = time.clock()\n",
    "print ((end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.788, 0.837, 0.803, 0.803, 0.798, 0.815, 0.785, 0.849, 0.819]\n",
      "[0.506, 0.576, 0.769, 0.208, 0.67, 0.654, 0.175, 0.316, 0.625] "
     ]
    }
   ],
   "source": [
    "print (dt_val_acc, end = \"\\n\")\n",
    "print (dt_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.826, 0.888, 0.828, 0.601, 0.853, 0.864, 0.838, 0.819, 0.859]\n",
      "[0.348, 0.595, 0.349, 0.587, 0.349, 0.349, 0.349, 0.647, 0.651] "
     ]
    }
   ],
   "source": [
    "print (log_val_acc, end = \"\\n\")\n",
    "print (log_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.496, 0.343, 0.645, 0.666, 0.722, 0.799, 0.867, 0.696, 0.711]\n",
      "[0.347, 0.349, 0.348, 0.652, 0.348, 0.347, 0.348, 0.284, 0.253] "
     ]
    }
   ],
   "source": [
    "print (nb_val_acc, end = \"\\n\")\n",
    "print (nb_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.825, 0.849, 0.828, 0.874, 0.853, 0.865, 0.844, 0.879, 0.88]\n",
      "[0.348, 0.348, 0.348, 0.348, 0.348, 0.348, 0.348, 0.803, 0.837] "
     ]
    }
   ],
   "source": [
    "print (svm_val_acc, end = \"\\n\")\n",
    "print (svm_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.849, 0.87, 0.854, 0.881, 0.857, 0.873, 0.864, 0.889, 0.867]\n",
      "[0.746, 0.747, 0.746, 0.748, 0.747, 0.748, 0.747, 0.747, 0.747] "
     ]
    }
   ],
   "source": [
    "print (rf_val_acc, end = \"\\n\")\n",
    "print (rf_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
