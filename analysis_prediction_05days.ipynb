{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import math \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/Desktop/analysis/code\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/wuyue/Desktop/analysis/stock/\"\n",
    "files = os.listdir(path)\n",
    "valid_file = []\n",
    "\n",
    "for file in files:\n",
    "    if file[-4:] == \".csv\":\n",
    "        valid_file.append(file)\n",
    "        \n",
    "print (len(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the fuctions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sign of a number\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    else:\n",
    "        return (0)\n",
    "    \n",
    "  \n",
    "def sgn_0(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    if x < 0:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "# the number of pos and neg in a list determine the general trend\n",
    "def sgn_num(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += 1\n",
    "        if i <= 0:\n",
    "            ne += 1\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)    \n",
    "\n",
    "# the value of pos and neg sum determine the \n",
    "def sgn_total(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += i\n",
    "        if i <= 0:\n",
    "            ne += abs(i)\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "def sqrt_abs(x):\n",
    "    if x > 0:\n",
    "        return math.log(x, 10)\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -math.log(abs(x), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_split(l, m):\n",
    "    n = int(math.ceil(len(l)/float(m)))\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def mix(l):\n",
    "    res_sum = []\n",
    "    for i in range(0, len(l[0])):\n",
    "        res = []\n",
    "        for lst in l:\n",
    "            res.append(lst[i])\n",
    "        res_sum.append(res)\n",
    "    return res_sum\n",
    "\n",
    "def cut(l, n):\n",
    "    res = []\n",
    "    for i in range(0, n):\n",
    "        res.append(l[i::n])\n",
    "    return res\n",
    "\n",
    "def slic(l, n, m):\n",
    "    res = []\n",
    "    for i in range (1, n+1):\n",
    "        res.append(l[60*i+1:60*i+m+1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n",
      "15.31215825 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "training_data_total = []\n",
    "training_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_part = open_price[-700:]\n",
    "            open_price_list = open_price[-700:-100]\n",
    "            open_price_list_split = chunks(open_price_list, 60)\n",
    "            open_price_list_testing = open_price[-100:]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_part = high_price[-700:]\n",
    "            high_price_list = high_price[-700:-100]\n",
    "            high_price_list_split = chunks(high_price_list, 60)\n",
    "            high_price_list_testing = high_price[-100:]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_part = low_price[-700:]\n",
    "            low_price_list = low_price[-700:-100]\n",
    "            low_price_list_split = chunks(low_price_list, 60)\n",
    "            low_price_list_testing = low_price[-100:]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_part = close_price[-700:]\n",
    "            close_price_list = close_price[-700:-100]\n",
    "            close_price_list_split = chunks(close_price_list, 60)\n",
    "            close_price_list_testing = close_price[-100:]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_part = volume[-700:]\n",
    "            volume_list = volume[-700:-100]\n",
    "            volume_list_split = chunks(volume_list, 60)\n",
    "            volume_list_testing = volume[-100:]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_part = change[-700:]\n",
    "            change_list = change[-700:-100]\n",
    "            change_list_split = chunks(change_list, 60)\n",
    "            change_list_testing = change[-100:]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_part = typical_price[-700:]\n",
    "            typical_price_list = typical_price[-700:-100]\n",
    "            typical_price_list_split = chunks(typical_price_list, 60)\n",
    "            typical_price_list_testing = typical_price[-100:]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_part = middle_price[-700:]\n",
    "            middle_price_list = middle_price[-700:-100]\n",
    "            middle_price_list_split = chunks(middle_price_list, 60)\n",
    "            middle_price_list_testing = middle_price[-100:]\n",
    "    \n",
    "    training_list = [open_price_list_split, high_price_list_split, low_price_list_split, close_price_list_split, \\\n",
    "                    volume_list_split, change_list_split, typical_price_list_split, middle_price_list_split]\n",
    "\n",
    "    training_list_mixed = mix(training_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in training_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 49\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/51\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/26\n",
    "        EMA_25 = []\n",
    "        for i in range(26,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-24:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        training_data = stock_feature_list[:-1]\n",
    "        training_data_total.append(training_data)\n",
    "        \n",
    "        training_label = stock_feature_list[-1]\n",
    "        training_label_total.append(training_label)\n",
    "        \n",
    "\n",
    "print (len(training_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n"
     ]
    }
   ],
   "source": [
    "transformer = RobustScaler().fit(training_data_total)\n",
    "data = transformer.transform(training_data_total)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the validation model 5 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46035\n",
      "10.032259183333334 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "validation_data_total = []\n",
    "validation_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list = open_price[-700:]\n",
    "            open_price_list_split_5 = slic(open_price_list, 9, 5)\n",
    "            \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list = high_price[-700:]\n",
    "            high_price_list_split_5 = slic(high_price_list, 9, 5)\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list = low_price[-700:]\n",
    "            low_price_list_split_5 = slic(low_price_list, 9, 5)\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list = close_price[-700:]\n",
    "            close_price_list_split_5 = slic(close_price_list, 9, 5)\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list = volume[-700:]\n",
    "            volume_list_split_5 = slic(volume_list, 9, 5)\n",
    "        \n",
    "            change.append(row[7])\n",
    "            change_list = change[-700:]\n",
    "            change_list_split_5 = slic(change_list, 9, 5)\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list = typical_price[-700:]\n",
    "            typical_price_list_split_5 = slic(typical_price_list, 9, 5)\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list = middle_price[-700:]\n",
    "            middle_price_list_split_5 = slic(middle_price_list, 9, 5)\n",
    "    \n",
    "    validation_list = [open_price_list_split_5, high_price_list_split_5, low_price_list_split_5, close_price_list_split_5, \\\n",
    "                    volume_list_split_5, change_list_split_5, typical_price_list_split_5, middle_price_list_split_5]\n",
    "\n",
    "    validation_list_mixed = mix(validation_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in validation_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/(negative_money_flow+1))\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 4\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/6\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/3\n",
    "        EMA_25 = []\n",
    "        for i in range(3,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-2:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/(1+cr_neg_sum))\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        validation_data = stock_feature_list[:-1]\n",
    "        validation_data_total.append(validation_data)\n",
    "        \n",
    "        validation_label = stock_feature_list[-1]\n",
    "        validation_label_total.append(validation_label)\n",
    "        \n",
    "\n",
    "print (len(validation_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_v = RobustScaler().fit(validation_data_total)\n",
    "validation_data = transformer_v.transform(validation_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.5549510499999997 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "testing_data_total = []\n",
    "testing_label_total = []\n",
    "testing_list_total = []\n",
    "\n",
    "count_term=1\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list_testing = open_price[-100:-95]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list_testing = high_price[-100:-95]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list_testing = low_price[-100:-95]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list_testing = close_price[-100:-95]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list_testing = volume[-100:-95]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_list_testing = change[-100:-95]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list_testing = typical_price[-100:-95]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list_testing = middle_price[-100:-95]\n",
    "    \n",
    "    testing_list = [open_price_list_testing, high_price_list_testing, low_price_list_testing, close_price_list_testing, \\\n",
    "                    volume_list_testing, change_list_testing, typical_price_list_testing, middle_price_list_testing]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_list = []\n",
    "    abs_list = []\n",
    "    \n",
    "    for flt in testing_list[5]:\n",
    "        abs_list.append(abs(flt))\n",
    "        if flt > 0:\n",
    "            pos_list.append(flt)\n",
    "    \n",
    "    abs_sum = float('%.3f' % sum(abs_list))\n",
    "    pos_sum = float('%.3f' % sum(pos_list))\n",
    "    raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "    RSI = float('%.3f' % raw_rsi)\n",
    "    stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    indicator_list = [0.5] \n",
    "    \n",
    "    money_flow_list = [vol*tp for vol, tp in zip(testing_list[4], testing_list[6])]\n",
    "    total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "    for i in range(len(testing_list[6])-1):\n",
    "        det = sgn(float('%.2f' % (testing_list[6][i+1] - testing_list[6][i])))\n",
    "        indicator_list.append(det)\n",
    "       \n",
    "    positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "    positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "    negative_money_flow = total_money_flow - positive_money_flow\n",
    "    money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "    raw_mfi = 100-100/(1+money_rate)\n",
    "    MFI = float('%.3f' % raw_mfi)\n",
    "    stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "    if len(testing_list[3]) >= 3:\n",
    "        raw_rsv = 100*(close_price_list_testing[-1] - min(close_price_list_testing))/(max(close_price_list_testing) - min(close_price_list_testing))\n",
    "    RSV = float('%.3f' % raw_rsv)\n",
    "    stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = testing_list[3][-1] - testing_list[3][-5]\n",
    "    bx = testing_list[3][-5]\n",
    "    raw_roc = 100*ax/bx\n",
    "    ROC = float('%.3f' % raw_roc)\n",
    "    stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "    square_sum_5 = []\n",
    "    TP_5 = mean(testing_list[6][-5:])\n",
    "    MA_5 = mean(testing_list[3][-5:])\n",
    "    for i in testing_list[3][-5:]:\n",
    "        square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "    raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "    CCI = float('%.3f' % raw_cci)\n",
    "    stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "    vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(testing_list[3], testing_list[1], testing_list[2])))\n",
    "    \n",
    "    va = []\n",
    "    va_change_list = []\n",
    "    va.append(testing_list[4][0])\n",
    "    \n",
    "    for i in range(0, len(testing_list[4])-1):\n",
    "        va.append(va[i] + vol_para[i]*testing_list[4][i+1])\n",
    "    \n",
    "    for i in range(0, len(va)-1):\n",
    "        va_change_list.append(va[i+1] - va[i])\n",
    "    va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "    if abs(va_change_rate) > 0.1:\n",
    "        VA = sgn(va_change_rate)\n",
    "    else:\n",
    "        VA = sgn_num(va_change_list)\n",
    "    stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    closing_change_list = []\n",
    "\n",
    "    for i in range(0, len(testing_list[3])-1):\n",
    "        closing_change_list.append(testing_list[3][i+1]-testing_list[3][i])\n",
    "   \n",
    "    closing_price_list_pvt = testing_list[3][1:]\n",
    "    volume_list_pvt = volume_list_testing[1:]\n",
    "    pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "    raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "    PVT = float('%.3f' % raw_pvt)\n",
    "    stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sign_closing_change_list = []\n",
    "    for i in closing_change_list:\n",
    "        sign_closing_change_list.append(sgn_0(i))\n",
    "    obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, testing_list[4][1:])))\n",
    "    raw_obv = sqrt_abs(sum(obv_list))\n",
    "    OBV = float('%.3f' % raw_obv)\n",
    "    stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exp_len = 49\n",
    "    exp_starting = len(testing_list[3]) - exp_len\n",
    "    price_list_50 = [mean(testing_list[3][:exp_starting])] + testing_list[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "    const_50 = 2/51\n",
    "    EMA_50 = []\n",
    "    for i in range(1,len(price_list_50)):\n",
    "        raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "        ema_50 = float('%.3f' % raw_ema_50)\n",
    "        EMA_50.append(ema_50)\n",
    "    \n",
    "    const_25 = 2/26\n",
    "    EMA_25 = []\n",
    "    for i in range(26,len(price_list_50)):\n",
    "        raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "        ema_25 = float('%.3f' % raw_ema_25)\n",
    "        EMA_25.append(ema_25)\n",
    "        \n",
    "    EMA_50c = EMA_50[-24:]\n",
    "    EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "    EMA_mean = np.mean(EMA_diff)*100\n",
    "    EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "    stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "    stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "    stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cr_pos = []\n",
    "    cr_neg = []\n",
    "    \n",
    "    middle_price_list_c = testing_list[7][:-1]\n",
    "    closing_price_list_c = testing_list[3][1:]\n",
    "    cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "    for i in cr_list:\n",
    "        if i > 0:\n",
    "            cr_pos.append(i)\n",
    "        else:\n",
    "            cr_neg.append(abs(i))\n",
    "    \n",
    "    cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "    cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "    raw_cr = 100*(cr_pos_sum/(cr_neg_sum+1))\n",
    "    CR = float('%.3f' % raw_cr)\n",
    "    stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "    square_sum = []\n",
    "    MA = mean(testing_list[3])\n",
    "    MB = mean(testing_list[3][:-1])\n",
    "    \n",
    "    for i in testing_list[3]:\n",
    "        square_sum.append((i-MA)**2)\n",
    "    MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "    raw_UP = MB+2*MD\n",
    "    raw_DN = MB-2*MD\n",
    "    UP = float('%.3f' % raw_UP)\n",
    "    DN = float('%.3f' % raw_DN)\n",
    "    stock_feature_dict[\"UP\"] = UP\n",
    "    stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        \n",
    "    if testing_list[3][-1] > testing_list[3][0]:\n",
    "        stock_feature_dict[\"change_c\"] = 1\n",
    "    else:\n",
    "        stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "    stock_feature_list = list(stock_feature_dict.values())\n",
    "    stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "    stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "    testing_data = stock_feature_list[:-1]\n",
    "    testing_data_total.append(testing_data)\n",
    "        \n",
    "    testing_label = stock_feature_list[-1]\n",
    "    testing_label_total.append(testing_label)\n",
    "    \n",
    "    \n",
    "print (len(testing_list_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_testing = RobustScaler().fit(testing_data_total)\n",
    "data_testing = transformer_testing.transform(testing_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree has accuracy on validation 0.7534701857282502\n",
      "decision tree has precision on validation 0.7102376599634369\n",
      "decision tree has recall on validation 0.7125171939477304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.78      0.78      2934\n",
      "           1       0.71      0.71      0.71      2181\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.75      0.75      0.75      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[2300  634]\n",
      " [ 627 1554]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5133919843597263\n",
      "decision tree has precision on testing 0.8473767885532592\n",
      "decision tree has recall on testing 0.3169788878977104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.89      0.56      1752\n",
      "           1       0.85      0.32      0.46      3363\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      5115\n",
      "   macro avg       0.63      0.60      0.51      5115\n",
      "weighted avg       0.70      0.51      0.49      5115\n",
      "\n",
      "[[1560  192]\n",
      " [2297 1066]]\n",
      "-1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7620723362658847\n",
      "log reg has precision on validation 0.6986809563066777\n",
      "log reg has recall on validation 0.7771664374140302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.75      0.78      2934\n",
      "           1       0.70      0.78      0.74      2181\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.76      0.76      0.76      5115\n",
      "weighted avg       0.77      0.76      0.76      5115\n",
      "\n",
      "[[2203  731]\n",
      " [ 486 1695]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.670772238514174\n",
      "log reg has precision on testing 0.942074776197999\n",
      "log reg has recall on testing 0.5319655069878085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.94      0.66      1752\n",
      "           1       0.94      0.53      0.68      3363\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.73      0.73      0.67      5115\n",
      "weighted avg       0.79      0.67      0.67      5115\n",
      "\n",
      "[[1642  110]\n",
      " [1574 1789]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.48367546432062564\n",
      "naive bayes has precision on validation 0.45200333889816363\n",
      "naive bayes has recall on validation 0.9931224209078404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.10      0.19      2934\n",
      "           1       0.45      0.99      0.62      2181\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5115\n",
      "   macro avg       0.70      0.55      0.41      5115\n",
      "weighted avg       0.74      0.48      0.37      5115\n",
      "\n",
      "[[ 308 2626]\n",
      " [  15 2166]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3423264907135875\n",
      "naive bayes has precision on testing 0.3333333333333333\n",
      "naive bayes has recall on testing 0.0002973535533749628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.34      1.00      0.51      1752\n",
      "           1       0.33      0.00      0.00      3363\n",
      "\n",
      "   micro avg       0.34      0.34      0.34      5115\n",
      "   macro avg       0.34      0.50      0.26      5115\n",
      "weighted avg       0.34      0.34      0.18      5115\n",
      "\n",
      "[[1750    2]\n",
      " [3362    1]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7626588465298143\n",
      "svm has precision on validation 0.7000413736036408\n",
      "svm has recall on validation 0.7757909215955984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.75      0.78      2934\n",
      "           1       0.70      0.78      0.74      2181\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.76      0.76      0.76      5115\n",
      "weighted avg       0.77      0.76      0.76      5115\n",
      "\n",
      "[[2209  725]\n",
      " [ 489 1692]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6764418377321603\n",
      "svm has precision on testing 0.9434060228452752\n",
      "svm has recall on testing 0.5402914064823074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.94      0.67      1752\n",
      "           1       0.94      0.54      0.69      3363\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.73      0.74      0.68      5115\n",
      "weighted avg       0.80      0.68      0.68      5115\n",
      "\n",
      "[[1643  109]\n",
      " [1546 1817]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.807624633431085\n",
      "random forest has precision on validation 0.7273072540827953\n",
      "random forest has recall on validation 0.8780375974323704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.76      0.82      2934\n",
      "           1       0.73      0.88      0.80      2181\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[2216  718]\n",
      " [ 266 1915]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8134897360703812\n",
      "random forest has precision on testing 0.912076633595621\n",
      "random forest has recall on testing 0.7927445732976509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1495  257]\n",
      " [ 697 2666]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8019550342130988\n",
      "decision tree has precision on validation 0.7732469512195121\n",
      "decision tree has recall on validation 0.8291785860237025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.78      0.80      2668\n",
      "           1       0.77      0.83      0.80      2447\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[2073  595]\n",
      " [ 418 2029]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.8074291300097751\n",
      "decision tree has precision on testing 0.9105662983425414\n",
      "decision tree has recall on testing 0.784121320249777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.85      0.75      1752\n",
      "           1       0.91      0.78      0.84      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.79      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.81      5115\n",
      "\n",
      "[[1493  259]\n",
      " [ 726 2637]]\n",
      "-1 -1\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.872336265884653\n",
      "log reg has precision on validation 0.8254716981132075\n",
      "log reg has recall on validation 0.9297098487944422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.82      0.87      2668\n",
      "           1       0.83      0.93      0.87      2447\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.88      0.87      0.87      5115\n",
      "weighted avg       0.88      0.87      0.87      5115\n",
      "\n",
      "[[2187  481]\n",
      " [ 172 2275]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.8285434995112414\n",
      "log reg has precision on testing 0.8374049945711184\n",
      "log reg has recall on testing 0.9173357121617604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.66      0.72      1752\n",
      "           1       0.84      0.92      0.88      3363\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.82      0.79      0.80      5115\n",
      "weighted avg       0.83      0.83      0.82      5115\n",
      "\n",
      "[[1153  599]\n",
      " [ 278 3085]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5796676441837733\n",
      "naive bayes has precision on validation 0.5323458941407101\n",
      "naive bayes has recall on validation 0.9987740089906008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.20      0.33      2668\n",
      "           1       0.53      1.00      0.69      2447\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      5115\n",
      "   macro avg       0.76      0.60      0.51      5115\n",
      "weighted avg       0.77      0.58      0.50      5115\n",
      "\n",
      "[[ 521 2147]\n",
      " [   3 2444]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.329227761485826\n",
      "naive bayes has precision on testing 0.33\n",
      "naive bayes has recall on testing 0.019625334522747548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.92      0.49      1752\n",
      "           1       0.33      0.02      0.04      3363\n",
      "\n",
      "   micro avg       0.33      0.33      0.33      5115\n",
      "   macro avg       0.33      0.47      0.26      5115\n",
      "weighted avg       0.33      0.33      0.19      5115\n",
      "\n",
      "[[1618  134]\n",
      " [3297   66]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.817008797653959\n",
      "svm has precision on validation 0.7681931132410366\n",
      "svm has recall on validation 0.8843481814466694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.76      0.81      2668\n",
      "           1       0.77      0.88      0.82      2447\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.82      0.82      0.82      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[2015  653]\n",
      " [ 283 2164]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6498533724340176\n",
      "svm has precision on testing 0.9415730337078652\n",
      "svm has recall on testing 0.4983645554564377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.94      0.65      1752\n",
      "           1       0.94      0.50      0.65      3363\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.72      0.72      0.65      5115\n",
      "weighted avg       0.79      0.65      0.65      5115\n",
      "\n",
      "[[1648  104]\n",
      " [1687 1676]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8428152492668621\n",
      "random forest has precision on validation 0.7789473684210526\n",
      "random forest has recall on validation 0.9374744585206375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.76      0.83      2668\n",
      "           1       0.78      0.94      0.85      2447\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.85      0.85      0.84      5115\n",
      "weighted avg       0.86      0.84      0.84      5115\n",
      "\n",
      "[[2017  651]\n",
      " [ 153 2294]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.911734519329456\n",
      "random forest has recall on testing 0.7924472197442759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1494  258]\n",
      " [ 698 2665]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7573802541544477\n",
      "decision tree has precision on validation 0.803914188934889\n",
      "decision tree has recall on validation 0.7478991596638656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.77      0.74      2259\n",
      "           1       0.80      0.75      0.77      2856\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.76      0.76      0.76      5115\n",
      "weighted avg       0.76      0.76      0.76      5115\n",
      "\n",
      "[[1738  521]\n",
      " [ 720 2136]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.636950146627566\n",
      "decision tree has precision on testing 0.7914086687306502\n",
      "decision tree has recall on testing 0.608088016651799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.69      0.57      1752\n",
      "           1       0.79      0.61      0.69      3363\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.64      0.65      0.63      5115\n",
      "weighted avg       0.68      0.64      0.65      5115\n",
      "\n",
      "[[1213  539]\n",
      " [1318 2045]]\n",
      "-1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.795503421309873\n",
      "log reg has precision on validation 0.8020694259012016\n",
      "log reg has recall on validation 0.8413865546218487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.74      0.76      2259\n",
      "           1       0.80      0.84      0.82      2856\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.79      5115\n",
      "\n",
      "[[1666  593]\n",
      " [ 453 2403]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.690713587487781\n",
      "log reg has precision on testing 0.9250596658711218\n",
      "log reg has recall on testing 0.576271186440678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.91      0.67      1752\n",
      "           1       0.93      0.58      0.71      3363\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.73      0.74      0.69      5115\n",
      "weighted avg       0.79      0.69      0.70      5115\n",
      "\n",
      "[[1595  157]\n",
      " [1425 1938]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6735092864125122\n",
      "naive bayes has precision on validation 0.6320124666073018\n",
      "naive bayes has recall on validation 0.9940476190476191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.27      0.42      2259\n",
      "           1       0.63      0.99      0.77      2856\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.80      0.63      0.60      5115\n",
      "weighted avg       0.78      0.67      0.62      5115\n",
      "\n",
      "[[ 606 1653]\n",
      " [  17 2839]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.32903225806451614\n",
      "naive bayes has precision on testing 0.17757009345794392\n",
      "naive bayes has recall on testing 0.005649717514124294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.95      0.49      1752\n",
      "           1       0.18      0.01      0.01      3363\n",
      "\n",
      "   micro avg       0.33      0.33      0.33      5115\n",
      "   macro avg       0.25      0.48      0.25      5115\n",
      "weighted avg       0.23      0.33      0.18      5115\n",
      "\n",
      "[[1664   88]\n",
      " [3344   19]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7943304007820137\n",
      "svm has precision on validation 0.8024815560026828\n",
      "svm has recall on validation 0.8378851540616247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.74      0.76      2259\n",
      "           1       0.80      0.84      0.82      2856\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1670  589]\n",
      " [ 463 2393]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6770283479960899\n",
      "svm has precision on testing 0.9318525996971226\n",
      "svm has recall on testing 0.5489146595301814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.92      0.66      1752\n",
      "           1       0.93      0.55      0.69      3363\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.72      0.74      0.68      5115\n",
      "weighted avg       0.79      0.68      0.68      5115\n",
      "\n",
      "[[1617  135]\n",
      " [1517 1846]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8402737047898339\n",
      "random forest has precision on validation 0.8264489273134806\n",
      "random forest has recall on validation 0.9037114845938375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.76      0.81      2259\n",
      "           1       0.83      0.90      0.86      2856\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.83      0.84      5115\n",
      "weighted avg       0.84      0.84      0.84      5115\n",
      "\n",
      "[[1717  542]\n",
      " [ 275 2581]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.9122987324426174\n",
      "random forest has recall on testing 0.791852512637526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1496  256]\n",
      " [ 700 2663]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7327468230694038\n",
      "decision tree has precision on validation 0.8909774436090225\n",
      "decision tree has recall on validation 0.7132694938440493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.78      0.63      1460\n",
      "           1       0.89      0.71      0.79      3655\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5115\n",
      "   macro avg       0.71      0.75      0.71      5115\n",
      "weighted avg       0.79      0.73      0.74      5115\n",
      "\n",
      "[[1141  319]\n",
      " [1048 2607]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.36774193548387096\n",
      "decision tree has precision on testing 0.9574468085106383\n",
      "decision tree has recall on testing 0.04014272970561998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      1.00      0.52      1752\n",
      "           1       0.96      0.04      0.08      3363\n",
      "\n",
      "   micro avg       0.37      0.37      0.37      5115\n",
      "   macro avg       0.65      0.52      0.30      5115\n",
      "weighted avg       0.75      0.37      0.23      5115\n",
      "\n",
      "[[1746    6]\n",
      " [3228  135]]\n",
      "-1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7171065493646139\n",
      "log reg has precision on validation 0.8319302465423932\n",
      "log reg has recall on validation 0.7570451436388509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.62      0.55      1460\n",
      "           1       0.83      0.76      0.79      3655\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      5115\n",
      "   macro avg       0.67      0.69      0.67      5115\n",
      "weighted avg       0.74      0.72      0.72      5115\n",
      "\n",
      "[[ 901  559]\n",
      " [ 888 2767]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.670772238514174\n",
      "log reg has precision on testing 0.8217707934074358\n",
      "log reg has recall on testing 0.6375260184359203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.73      0.60      1752\n",
      "           1       0.82      0.64      0.72      3363\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.67      0.69      0.66      5115\n",
      "weighted avg       0.72      0.67      0.68      5115\n",
      "\n",
      "[[1287  465]\n",
      " [1219 2144]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7145650048875856\n",
      "naive bayes has precision on validation 0.7145650048875856\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1460\n",
      "           1       0.71      1.00      0.83      3655\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5115\n",
      "   macro avg       0.36      0.50      0.42      5115\n",
      "weighted avg       0.51      0.71      0.60      5115\n",
      "\n",
      "[[   0 1460]\n",
      " [   0 3655]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.6574780058651026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes has precision on testing 0.6574780058651026\n",
      "naive bayes has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1752\n",
      "           1       0.66      1.00      0.79      3363\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5115\n",
      "   macro avg       0.33      0.50      0.40      5115\n",
      "weighted avg       0.43      0.66      0.52      5115\n",
      "\n",
      "[[   0 1752]\n",
      " [   0 3363]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.8256109481915933\n",
      "svm has precision on validation 0.8946015424164524\n",
      "svm has recall on validation 0.8569083447332422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.75      0.71      1460\n",
      "           1       0.89      0.86      0.88      3655\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.79      0.80      0.79      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1091  369]\n",
      " [ 523 3132]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6668621700879765\n",
      "svm has precision on testing 0.9447721179624665\n",
      "svm has recall on testing 0.5239369610466845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.94      0.66      1752\n",
      "           1       0.94      0.52      0.67      3363\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.73      0.73      0.67      5115\n",
      "weighted avg       0.79      0.67      0.67      5115\n",
      "\n",
      "[[1649  103]\n",
      " [1601 1762]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8774193548387097\n",
      "random forest has precision on validation 0.8998943475964079\n",
      "random forest has recall on validation 0.9321477428180575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.74      0.78      1460\n",
      "           1       0.90      0.93      0.92      3655\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1081  379]\n",
      " [ 248 3407]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.9125814192663696\n",
      "random forest has recall on testing 0.7915551590841511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1497  255]\n",
      " [ 701 2662]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8252199413489736\n",
      "decision tree has precision on validation 0.859980462390101\n",
      "decision tree has recall on validation 0.8505636070853462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.79      0.78      2010\n",
      "           1       0.86      0.85      0.86      3105\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.82      0.82      0.82      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1580  430]\n",
      " [ 464 2641]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5219941348973607\n",
      "decision tree has precision on testing 0.6230563002680966\n",
      "decision tree has recall on testing 0.6910496580434137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.25      0.20      0.22      1752\n",
      "           1       0.62      0.69      0.66      3363\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      5115\n",
      "   macro avg       0.44      0.44      0.44      5115\n",
      "weighted avg       0.50      0.52      0.51      5115\n",
      "\n",
      "[[ 346 1406]\n",
      " [1039 2324]]\n",
      "1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.858455522971652\n",
      "log reg has precision on validation 0.8502500735510444\n",
      "log reg has recall on validation 0.9307568438003221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.75      0.81      2010\n",
      "           1       0.85      0.93      0.89      3105\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1501  509]\n",
      " [ 215 2890]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6916911045943304\n",
      "log reg has precision on testing 0.9368884540117417\n",
      "log reg has recall on testing 0.5694320547130538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.93      0.67      1752\n",
      "           1       0.94      0.57      0.71      3363\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.73      0.75      0.69      5115\n",
      "weighted avg       0.80      0.69      0.70      5115\n",
      "\n",
      "[[1623  129]\n",
      " [1448 1915]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7262952101661779\n",
      "naive bayes has precision on validation 0.6900780379041248\n",
      "naive bayes has recall on validation 0.9967793880837359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.31      0.47      2010\n",
      "           1       0.69      1.00      0.82      3105\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5115\n",
      "   macro avg       0.84      0.65      0.64      5115\n",
      "weighted avg       0.81      0.73      0.68      5115\n",
      "\n",
      "[[ 620 1390]\n",
      " [  10 3095]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.32649071358748777\n",
      "naive bayes has precision on testing 0.22666666666666666\n",
      "naive bayes has recall on testing 0.010110020814748736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.93      0.49      1752\n",
      "           1       0.23      0.01      0.02      3363\n",
      "\n",
      "   micro avg       0.33      0.33      0.33      5115\n",
      "   macro avg       0.28      0.47      0.25      5115\n",
      "weighted avg       0.26      0.33      0.18      5115\n",
      "\n",
      "[[1636  116]\n",
      " [3329   34]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.8574780058651026\n",
      "svm has precision on validation 0.8469626168224299\n",
      "svm has recall on validation 0.9339774557165862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.74      0.80      2010\n",
      "           1       0.85      0.93      0.89      3105\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.86      0.86      0.85      5115\n",
      "\n",
      "[[1486  524]\n",
      " [ 205 2900]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6854349951124145\n",
      "svm has precision on testing 0.9371884346959123\n",
      "svm has recall on testing 0.5590246803449301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.93      0.67      1752\n",
      "           1       0.94      0.56      0.70      3363\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.73      0.74      0.68      5115\n",
      "weighted avg       0.80      0.69      0.69      5115\n",
      "\n",
      "[[1626  126]\n",
      " [1483 1880]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8748778103616813\n",
      "random forest has precision on validation 0.8516405135520685\n",
      "random forest has recall on validation 0.961352657004831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.74      0.82      2010\n",
      "           1       0.85      0.96      0.90      3105\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.89      0.85      0.86      5115\n",
      "weighted avg       0.88      0.87      0.87      5115\n",
      "\n",
      "[[1490  520]\n",
      " [ 120 2985]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.9120164327285176\n",
      "random forest has recall on testing 0.792149866190901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1495  257]\n",
      " [ 699 2664]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7826001955034213\n",
      "decision tree has precision on validation 0.7915355019237496\n",
      "decision tree has recall on validation 0.8143216984526809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.74      0.76      2336\n",
      "           1       0.79      0.81      0.80      2779\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.78      0.78      5115\n",
      "weighted avg       0.78      0.78      0.78      5115\n",
      "\n",
      "[[1740  596]\n",
      " [ 516 2263]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5718475073313783\n",
      "decision tree has precision on testing 0.6437147757902475\n",
      "decision tree has recall on testing 0.7811477847160273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.17      0.21      1752\n",
      "           1       0.64      0.78      0.71      3363\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      5115\n",
      "   macro avg       0.47      0.48      0.46      5115\n",
      "weighted avg       0.52      0.57      0.54      5115\n",
      "\n",
      "[[ 298 1454]\n",
      " [ 736 2627]]\n",
      "1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8089931573802541\n",
      "log reg has precision on validation 0.7820914214151534\n",
      "log reg has recall on validation 0.8988844908240374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.70      0.77      2336\n",
      "           1       0.78      0.90      0.84      2779\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.82      0.80      0.80      5115\n",
      "weighted avg       0.81      0.81      0.81      5115\n",
      "\n",
      "[[1640  696]\n",
      " [ 281 2498]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.7006842619745846\n",
      "log reg has precision on testing 0.9345351043643264\n",
      "log reg has recall on testing 0.5857865001486767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.92      0.68      1752\n",
      "           1       0.93      0.59      0.72      3363\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.74      0.75      0.70      5115\n",
      "weighted avg       0.80      0.70      0.71      5115\n",
      "\n",
      "[[1614  138]\n",
      " [1393 1970]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.693841642228739\n",
      "naive bayes has precision on validation 0.6411449848731673\n",
      "naive bayes has recall on validation 0.9913637999280317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.34      0.50      2336\n",
      "           1       0.64      0.99      0.78      2779\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.81      0.67      0.64      5115\n",
      "weighted avg       0.79      0.69      0.65      5115\n",
      "\n",
      "[[ 794 1542]\n",
      " [  24 2755]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3403714565004888\n",
      "naive bayes has precision on testing 0.17647058823529413\n",
      "naive bayes has recall on testing 0.0008920606601248885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.34      0.99      0.51      1752\n",
      "           1       0.18      0.00      0.00      3363\n",
      "\n",
      "   micro avg       0.34      0.34      0.34      5115\n",
      "   macro avg       0.26      0.50      0.25      5115\n",
      "weighted avg       0.23      0.34      0.17      5115\n",
      "\n",
      "[[1738   14]\n",
      " [3360    3]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.8152492668621701\n",
      "svm has precision on validation 0.7890920554854981\n",
      "svm has recall on validation 0.9006836991723641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.71      0.78      2336\n",
      "           1       0.79      0.90      0.84      2779\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.82      0.81      0.81      5115\n",
      "weighted avg       0.82      0.82      0.81      5115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1667  669]\n",
      " [ 276 2503]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.701466275659824\n",
      "svm has precision on testing 0.9421965317919075\n",
      "svm has recall on testing 0.5816235504014273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.93      0.68      1752\n",
      "           1       0.94      0.58      0.72      3363\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.74      0.76      0.70      5115\n",
      "weighted avg       0.80      0.70      0.71      5115\n",
      "\n",
      "[[1632  120]\n",
      " [1407 1956]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8453567937438905\n",
      "random forest has precision on validation 0.8167622689611217\n",
      "random forest has recall on validation 0.9222741993522849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.75      0.82      2336\n",
      "           1       0.82      0.92      0.87      2779\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.85      0.84      0.84      5115\n",
      "weighted avg       0.85      0.85      0.84      5115\n",
      "\n",
      "[[1761  575]\n",
      " [ 216 2563]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8129032258064516\n",
      "random forest has precision on testing 0.9114227086183311\n",
      "random forest has recall on testing 0.7924472197442759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1493  259]\n",
      " [ 698 2665]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7898338220918866\n",
      "decision tree has precision on validation 0.6120920278223649\n",
      "decision tree has recall on validation 0.7657295850066934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.80      0.84      3621\n",
      "           1       0.61      0.77      0.68      1494\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.75      0.78      0.76      5115\n",
      "weighted avg       0.81      0.79      0.80      5115\n",
      "\n",
      "[[2896  725]\n",
      " [ 350 1144]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.247702834799609\n",
      "decision tree has precision on testing 0.3986627664020059\n",
      "decision tree has recall on testing 0.2836752899197145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.11      0.18      0.14      1752\n",
      "           1       0.40      0.28      0.33      3363\n",
      "\n",
      "   micro avg       0.25      0.25      0.25      5115\n",
      "   macro avg       0.26      0.23      0.24      5115\n",
      "weighted avg       0.30      0.25      0.27      5115\n",
      "\n",
      "[[ 313 1439]\n",
      " [2409  954]]\n",
      "1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7935483870967742\n",
      "log reg has precision on validation 0.6070381231671554\n",
      "log reg has recall on validation 0.8313253012048193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.78      0.84      3621\n",
      "           1       0.61      0.83      0.70      1494\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.76      0.80      0.77      5115\n",
      "weighted avg       0.83      0.79      0.80      5115\n",
      "\n",
      "[[2817  804]\n",
      " [ 252 1242]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.7028347996089932\n",
      "log reg has precision on testing 0.9164030727519205\n",
      "log reg has recall on testing 0.6030330062444246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.89      0.67      1752\n",
      "           1       0.92      0.60      0.73      3363\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.73      0.75      0.70      5115\n",
      "weighted avg       0.79      0.70      0.71      5115\n",
      "\n",
      "[[1567  185]\n",
      " [1335 2028]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7573802541544477\n",
      "naive bayes has precision on validation 0.5480440562096468\n",
      "naive bayes has recall on validation 0.9658634538152611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.67      0.80      3621\n",
      "           1       0.55      0.97      0.70      1494\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.76      0.82      0.75      5115\n",
      "weighted avg       0.85      0.76      0.77      5115\n",
      "\n",
      "[[2431 1190]\n",
      " [  51 1443]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.34252199413489737\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.34      1.00      0.51      1752\n",
      "           1       0.00      0.00      0.00      3363\n",
      "\n",
      "   micro avg       0.34      0.34      0.34      5115\n",
      "   macro avg       0.17      0.50      0.26      5115\n",
      "weighted avg       0.12      0.34      0.17      5115\n",
      "\n",
      "[[1752    0]\n",
      " [3363    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7980449657869013\n",
      "svm has precision on validation 0.6131566028473245\n",
      "svm has recall on validation 0.8360107095046854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.78      0.85      3621\n",
      "           1       0.61      0.84      0.71      1494\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.77      0.81      0.78      5115\n",
      "weighted avg       0.83      0.80      0.81      5115\n",
      "\n",
      "[[2833  788]\n",
      " [ 245 1249]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6901270772238515\n",
      "svm has precision on testing 0.9375\n",
      "svm has recall on testing 0.5664585191793042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.93      0.67      1752\n",
      "           1       0.94      0.57      0.71      3363\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.73      0.75      0.69      5115\n",
      "weighted avg       0.80      0.69      0.69      5115\n",
      "\n",
      "[[1625  127]\n",
      " [1458 1905]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.832258064516129\n",
      "random forest has precision on validation 0.6568047337278107\n",
      "random forest has recall on validation 0.891566265060241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.81      0.87      3621\n",
      "           1       0.66      0.89      0.76      1494\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.80      0.85      0.81      5115\n",
      "weighted avg       0.86      0.83      0.84      5115\n",
      "\n",
      "[[2925  696]\n",
      " [ 162 1332]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.9114529914529914\n",
      "random forest has recall on testing 0.7927445732976509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1493  259]\n",
      " [ 697 2666]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.819941348973607\n",
      "decision tree has precision on validation 0.9010545905707196\n",
      "decision tree has recall on validation 0.8283433133732535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.80      0.74      1608\n",
      "           1       0.90      0.83      0.86      3507\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.79      0.81      0.80      5115\n",
      "weighted avg       0.83      0.82      0.82      5115\n",
      "\n",
      "[[1289  319]\n",
      " [ 602 2905]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.4797653958944281\n",
      "decision tree has precision on testing 0.9834710743801653\n",
      "decision tree has recall on testing 0.21231043710972347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.99      0.57      1752\n",
      "           1       0.98      0.21      0.35      3363\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      5115\n",
      "   macro avg       0.69      0.60      0.46      5115\n",
      "weighted avg       0.78      0.48      0.42      5115\n",
      "\n",
      "[[1740   12]\n",
      " [2649  714]]\n",
      "-1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8995112414467253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has precision on validation 0.9176667596985766\n",
      "log reg has recall on validation 0.9375534644995723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.82      0.84      1608\n",
      "           1       0.92      0.94      0.93      3507\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5115\n",
      "   macro avg       0.89      0.88      0.88      5115\n",
      "weighted avg       0.90      0.90      0.90      5115\n",
      "\n",
      "[[1313  295]\n",
      " [ 219 3288]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6819159335288367\n",
      "log reg has precision on testing 0.6739478957915832\n",
      "log reg has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.07      0.13      1752\n",
      "           1       0.67      1.00      0.81      3363\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.84      0.54      0.47      5115\n",
      "weighted avg       0.79      0.68      0.58      5115\n",
      "\n",
      "[[ 125 1627]\n",
      " [   0 3363]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6875855327468231\n",
      "naive bayes has precision on validation 0.6888229475766567\n",
      "naive bayes has recall on validation 0.9928714000570288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.02      0.04      1608\n",
      "           1       0.69      0.99      0.81      3507\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.64      0.51      0.43      5115\n",
      "weighted avg       0.66      0.69      0.57      5115\n",
      "\n",
      "[[  35 1573]\n",
      " [  25 3482]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.175366568914956\n",
      "naive bayes has precision on testing 0.1343028229255774\n",
      "naive bayes has recall on testing 0.046684507879869164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.19      0.42      0.26      1752\n",
      "           1       0.13      0.05      0.07      3363\n",
      "\n",
      "   micro avg       0.18      0.18      0.18      5115\n",
      "   macro avg       0.16      0.23      0.16      5115\n",
      "weighted avg       0.15      0.18      0.13      5115\n",
      "\n",
      "[[ 740 1012]\n",
      " [3206  157]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8942326490713588\n",
      "svm has precision on validation 0.8790899795501023\n",
      "svm has recall on validation 0.9806102081551183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.71      0.81      1608\n",
      "           1       0.88      0.98      0.93      3507\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5115\n",
      "   macro avg       0.91      0.84      0.87      5115\n",
      "weighted avg       0.90      0.89      0.89      5115\n",
      "\n",
      "[[1135  473]\n",
      " [  68 3439]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8488758553274682\n",
      "svm has precision on testing 0.8330761316872428\n",
      "svm has recall on testing 0.9631281593815046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.63      0.74      1752\n",
      "           1       0.83      0.96      0.89      3363\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.87      0.80      0.82      5115\n",
      "weighted avg       0.86      0.85      0.84      5115\n",
      "\n",
      "[[1103  649]\n",
      " [ 124 3239]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8825024437927663\n",
      "random forest has precision on validation 0.8946224877783813\n",
      "random forest has recall on validation 0.9392643284858854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.76      0.80      1608\n",
      "           1       0.89      0.94      0.92      3507\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.87      0.85      0.86      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1220  388]\n",
      " [ 213 3294]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8129032258064516\n",
      "random forest has precision on testing 0.912268677176148\n",
      "random forest has recall on testing 0.7915551590841511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1496  256]\n",
      " [ 701 2662]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7743890518084067\n",
      "decision tree has precision on validation 0.7803905938620964\n",
      "decision tree has recall on validation 0.7645450995704803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.78      0.78      2554\n",
      "           1       0.78      0.76      0.77      2561\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.77      0.77      5115\n",
      "weighted avg       0.77      0.77      0.77      5115\n",
      "\n",
      "[[2003  551]\n",
      " [ 603 1958]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.45395894428152495\n",
      "decision tree has precision on testing 0.6091954022988506\n",
      "decision tree has recall on testing 0.4727921498661909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.42      0.34      1752\n",
      "           1       0.61      0.47      0.53      3363\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      5115\n",
      "   macro avg       0.45      0.45      0.44      5115\n",
      "weighted avg       0.50      0.45      0.47      5115\n",
      "\n",
      "[[ 732 1020]\n",
      " [1773 1590]]\n",
      "-1 -1\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8140762463343109\n",
      "log reg has precision on validation 0.7366255144032922\n",
      "log reg has recall on validation 0.978524014057009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.65      0.78      2554\n",
      "           1       0.74      0.98      0.84      2561\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.85      0.81      0.81      5115\n",
      "weighted avg       0.85      0.81      0.81      5115\n",
      "\n",
      "[[1658  896]\n",
      " [  55 2506]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6762463343108505\n",
      "log reg has precision on testing 0.6701215866055411\n",
      "log reg has recall on testing 0.999702646446625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.06      0.10      1752\n",
      "           1       0.67      1.00      0.80      3363\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.83      0.53      0.45      5115\n",
      "weighted avg       0.78      0.68      0.56      5115\n",
      "\n",
      "[[  97 1655]\n",
      " [   1 3362]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5341153470185728\n",
      "naive bayes has precision on validation 0.5181484502446982\n",
      "naive bayes has recall on validation 0.9921905505661851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.07      0.14      2554\n",
      "           1       0.52      0.99      0.68      2561\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      5115\n",
      "   macro avg       0.71      0.53      0.41      5115\n",
      "weighted avg       0.71      0.53      0.41      5115\n",
      "\n",
      "[[ 191 2363]\n",
      " [  20 2541]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.1943304007820137\n",
      "naive bayes has precision on testing 0.08624454148471616\n",
      "naive bayes has recall on testing 0.023490930716622064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.22      0.52      0.31      1752\n",
      "           1       0.09      0.02      0.04      3363\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      5115\n",
      "   macro avg       0.15      0.27      0.17      5115\n",
      "weighted avg       0.13      0.19      0.13      5115\n",
      "\n",
      "[[ 915  837]\n",
      " [3284   79]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8582600195503421\n",
      "svm has precision on validation 0.7970873786407767\n",
      "svm has recall on validation 0.961733697774307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.75      0.84      2554\n",
      "           1       0.80      0.96      0.87      2561\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.86      0.86      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[1927  627]\n",
      " [  98 2463]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8334310850439882\n",
      "svm has precision on testing 0.8103831891223733\n",
      "svm has recall on testing 0.9747249479631281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.56      0.70      1752\n",
      "           1       0.81      0.97      0.88      3363\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.87      0.77      0.79      5115\n",
      "weighted avg       0.85      0.83      0.82      5115\n",
      "\n",
      "[[ 985  767]\n",
      " [  85 3278]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8424242424242424\n",
      "random forest has precision on validation 0.8054298642533937\n",
      "random forest has recall on validation 0.9035532994923858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.78      0.83      2554\n",
      "           1       0.81      0.90      0.85      2561\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.85      0.84      0.84      5115\n",
      "weighted avg       0.85      0.84      0.84      5115\n",
      "\n",
      "[[1995  559]\n",
      " [ 247 2314]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8130987292277615\n",
      "random forest has precision on testing 0.9122987324426174\n",
      "random forest has recall on testing 0.791852512637526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.85      0.76      1752\n",
      "           1       0.91      0.79      0.85      3363\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.82      0.80      5115\n",
      "weighted avg       0.83      0.81      0.82      5115\n",
      "\n",
      "[[1496  256]\n",
      " [ 700 2663]]\n",
      "============================================================\n",
      "19.35806700000012 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.clock()\n",
    "\n",
    "dt_val_acc = []\n",
    "dt_testing_acc = []\n",
    "\n",
    "log_val_acc = []\n",
    "log_testing_acc = []\n",
    "\n",
    "nb_val_acc = []\n",
    "nb_testing_acc = []\n",
    "\n",
    "svm_val_acc = []\n",
    "svm_testing_acc = []\n",
    "\n",
    "rf_val_acc = []\n",
    "rf_testing_acc = []\n",
    "\n",
    "\n",
    "training_data_split = cut(data, 9)\n",
    "training_label_split = cut(training_label_total, 9)\n",
    "\n",
    "validation_data_split = cut(validation_data, 9)\n",
    "validation_label_split = cut(validation_label_total, 9)\n",
    "\n",
    "# print (training_data_split[2])\n",
    "\n",
    "for i in range (0, 9):\n",
    "    training_sub_list = []\n",
    "    training_sub_list.append(training_data_split[i])\n",
    "    training_sub_list.append(training_label_split[i])\n",
    "    \n",
    "    validation_sub_list = []\n",
    "    validation_sub_list.append(validation_data_split[i])\n",
    "    validation_sub_list.append(validation_label_split[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1 = tree.DecisionTreeClassifier()\n",
    "    dt_model = model1.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    dt_result = dt_model.predict(validation_sub_list[0])\n",
    "    dt_testing_result = dt_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"decision tree has accuracy on validation\", accuracy_score(validation_sub_list[-1], dt_result))\n",
    "    dt_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], dt_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on validation\", precision_score(validation_sub_list[-1], dt_result))\n",
    "    print (\"decision tree has recall on validation\", recall_score(validation_sub_list[-1], dt_result))\n",
    "    print (classification_report(validation_sub_list[-1], dt_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], dt_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"decision tree has accuracy on testing\", accuracy_score(testing_label_total, dt_testing_result))\n",
    "    dt_testing_acc.append(float(format(accuracy_score(testing_label_total, dt_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on testing\", precision_score(testing_label_total, dt_testing_result))\n",
    "    print (\"decision tree has recall on testing\", recall_score(testing_label_total, dt_testing_result))\n",
    "    print (classification_report(testing_label_total, dt_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, dt_testing_result))\n",
    "    print ((dt_testing_result[0]), (testing_label_total[0]))\n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model2 = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr')\n",
    "    log_model = model2.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    log_result = log_model.predict(validation_sub_list[0])\n",
    "    log_testing_result = log_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"log reg has accuracy on validation\", accuracy_score(validation_sub_list[-1], log_result))\n",
    "    log_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], log_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on validation\", precision_score(validation_sub_list[-1], log_result))\n",
    "    print (\"log reg has recall on validation\", recall_score(validation_sub_list[-1], log_result))\n",
    "    print (classification_report(validation_sub_list[-1], log_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], log_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"log reg has accuracy on testing\", accuracy_score(testing_label_total, log_testing_result))\n",
    "    log_testing_acc.append(float(format(accuracy_score(testing_label_total, log_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on testing\", precision_score(testing_label_total, log_testing_result))\n",
    "    print (\"log reg has recall on testing\", recall_score(testing_label_total, log_testing_result))\n",
    "    print (classification_report(testing_label_total, log_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, log_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "   \n",
    "\n",
    "    \n",
    "    model3 = GaussianNB()\n",
    "    nb_model = model3.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    nb_result = nb_model.predict(validation_sub_list[0])\n",
    "    nb_testing_result = nb_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"naive bayes has accuracy on validation\", accuracy_score(validation_sub_list[-1], nb_result))\n",
    "    nb_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], nb_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on validation\", precision_score(validation_sub_list[-1], nb_result))\n",
    "    print (\"naive bayes has recall on validation\", recall_score(validation_sub_list[-1], nb_result))\n",
    "    print (classification_report(validation_sub_list[-1], nb_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], nb_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"naive bayes has accuracy on testing\", accuracy_score(testing_label_total, nb_testing_result))\n",
    "    nb_testing_acc.append(float(format(accuracy_score(testing_label_total, nb_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on testing\", precision_score(testing_label_total, nb_testing_result))\n",
    "    print (\"naive bayes has recall on testing\", recall_score(testing_label_total, nb_testing_result))\n",
    "    print (classification_report(testing_label_total, nb_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, nb_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model4 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    svm_model = model4.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    svm_result = svm_model.predict(validation_sub_list[0])\n",
    "    svm_testing_result = svm_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"svm has accuracy on validation\", accuracy_score(validation_sub_list[-1], svm_result))\n",
    "    svm_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], svm_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on validation\", precision_score(validation_sub_list[-1], svm_result))\n",
    "    print (\"svm has recall on validation\", recall_score(validation_sub_list[-1], svm_result))\n",
    "    print (classification_report(validation_sub_list[-1], svm_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], svm_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"svm has accuracy on testing\", accuracy_score(testing_label_total, svm_testing_result))\n",
    "    svm_testing_acc.append(float(format(accuracy_score(testing_label_total, svm_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on testing\", precision_score(testing_label_total, svm_testing_result))\n",
    "    print (\"svm has recall on testing\", recall_score(testing_label_total, svm_testing_result))\n",
    "    print (classification_report(testing_label_total, svm_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, svm_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model5 = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n",
    "    rf_model = model5.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    rf_result = rf_model.predict(validation_sub_list[0])\n",
    "    rf_testing_result = rf_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"random forest has accuracy on validation\", accuracy_score(validation_sub_list[-1], rf_result))\n",
    "    rf_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], rf_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on validation\", precision_score(validation_sub_list[-1], rf_result))\n",
    "    print (\"random forest has recall on validation\", recall_score(validation_sub_list[-1], rf_result))\n",
    "    print (classification_report(validation_sub_list[-1], rf_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], rf_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"random forest has accuracy on testing\", accuracy_score(testing_label_total, rf_testing_result))\n",
    "    rf_testing_acc.append(float(format(accuracy_score(testing_label_total, rf_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on testing\", precision_score(testing_label_total, rf_testing_result))\n",
    "    print (\"random forest has recall on testing\", recall_score(testing_label_total, rf_testing_result))\n",
    "    print (classification_report(testing_label_total, rf_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, rf_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "end = time.clock()\n",
    "print ((end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_val_acc\n",
    "# dt_testing_acc \n",
    "\n",
    "# log_val_acc \n",
    "# log_testing_acc \n",
    "\n",
    "# nb_val_acc \n",
    "# nb_testing_acc \n",
    "\n",
    "# svm_val_acc \n",
    "# svm_testing_acc \n",
    "\n",
    "# rf_val_acc \n",
    "# rf_testing_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.753, 0.802, 0.757, 0.733, 0.825, 0.783, 0.79, 0.82, 0.774]\n",
      "[0.513, 0.807, 0.637, 0.368, 0.522, 0.572, 0.248, 0.48, 0.454] "
     ]
    }
   ],
   "source": [
    "print (dt_val_acc, end = \"\\n\")\n",
    "print (dt_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.762, 0.872, 0.796, 0.717, 0.858, 0.809, 0.794, 0.9, 0.814]\n",
      "[0.671, 0.829, 0.691, 0.671, 0.692, 0.701, 0.703, 0.682, 0.676] "
     ]
    }
   ],
   "source": [
    "print (log_val_acc, end = \"\\n\")\n",
    "print (log_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.484, 0.58, 0.674, 0.715, 0.726, 0.694, 0.757, 0.688, 0.534]\n",
      "[0.342, 0.329, 0.329, 0.657, 0.326, 0.34, 0.343, 0.175, 0.194] "
     ]
    }
   ],
   "source": [
    "print (nb_val_acc, end = \"\\n\")\n",
    "print (nb_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.763, 0.817, 0.794, 0.826, 0.857, 0.815, 0.798, 0.894, 0.858]\n",
      "[0.676, 0.65, 0.677, 0.667, 0.685, 0.701, 0.69, 0.849, 0.833] "
     ]
    }
   ],
   "source": [
    "print (svm_val_acc, end = \"\\n\")\n",
    "print (svm_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.808, 0.843, 0.84, 0.877, 0.875, 0.845, 0.832, 0.883, 0.842]\n",
      "[0.813, 0.813, 0.813, 0.813, 0.813, 0.813, 0.813, 0.813, 0.813] "
     ]
    }
   ],
   "source": [
    "print (rf_val_acc, end = \"\\n\")\n",
    "print (rf_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
