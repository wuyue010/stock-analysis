{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import math \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/Desktop/analysis/code\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/wuyue/Desktop/analysis/stock/\"\n",
    "files = os.listdir(path)\n",
    "valid_file = []\n",
    "\n",
    "for file in files:\n",
    "    if file[-4:] == \".csv\":\n",
    "        valid_file.append(file)\n",
    "        \n",
    "print (len(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the fuctions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sign of a number\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    else:\n",
    "        return (0)\n",
    "    \n",
    "  \n",
    "def sgn_0(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    if x < 0:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "# the number of pos and neg in a list determine the general trend\n",
    "def sgn_num(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += 1\n",
    "        if i <= 0:\n",
    "            ne += 1\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)    \n",
    "\n",
    "# the value of pos and neg sum determine the \n",
    "def sgn_total(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += i\n",
    "        if i <= 0:\n",
    "            ne += abs(i)\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "def sqrt_abs(x):\n",
    "    if x > 0:\n",
    "        return math.log(x, 10)\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -math.log(abs(x), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_split(l, m):\n",
    "    n = int(math.ceil(len(l)/float(m)))\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def mix(l):\n",
    "    res_sum = []\n",
    "    for i in range(0, len(l[0])):\n",
    "        res = []\n",
    "        for lst in l:\n",
    "            res.append(lst[i])\n",
    "        res_sum.append(res)\n",
    "    return res_sum\n",
    "\n",
    "def cut(l, n):\n",
    "    res = []\n",
    "    for i in range(0, n):\n",
    "        res.append(l[i::n])\n",
    "    return res\n",
    "\n",
    "def slic(l, n, m):\n",
    "    res = []\n",
    "    for i in range (1, n+1):\n",
    "        res.append(l[60*i+1:60*i+m+1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n",
      "31.136723716666665 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "training_data_total = []\n",
    "training_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_part = open_price[-700:]\n",
    "            open_price_list = open_price[-700:-100]\n",
    "            open_price_list_split = chunks(open_price_list, 60)\n",
    "            open_price_list_testing = open_price[-100:]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_part = high_price[-700:]\n",
    "            high_price_list = high_price[-700:-100]\n",
    "            high_price_list_split = chunks(high_price_list, 60)\n",
    "            high_price_list_testing = high_price[-100:]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_part = low_price[-700:]\n",
    "            low_price_list = low_price[-700:-100]\n",
    "            low_price_list_split = chunks(low_price_list, 60)\n",
    "            low_price_list_testing = low_price[-100:]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_part = close_price[-700:]\n",
    "            close_price_list = close_price[-700:-100]\n",
    "            close_price_list_split = chunks(close_price_list, 60)\n",
    "            close_price_list_testing = close_price[-100:]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_part = volume[-700:]\n",
    "            volume_list = volume[-700:-100]\n",
    "            volume_list_split = chunks(volume_list, 60)\n",
    "            volume_list_testing = volume[-100:]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_part = change[-700:]\n",
    "            change_list = change[-700:-100]\n",
    "            change_list_split = chunks(change_list, 60)\n",
    "            change_list_testing = change[-100:]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_part = typical_price[-700:]\n",
    "            typical_price_list = typical_price[-700:-100]\n",
    "            typical_price_list_split = chunks(typical_price_list, 60)\n",
    "            typical_price_list_testing = typical_price[-100:]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_part = middle_price[-700:]\n",
    "            middle_price_list = middle_price[-700:-100]\n",
    "            middle_price_list_split = chunks(middle_price_list, 60)\n",
    "            middle_price_list_testing = middle_price[-100:]\n",
    "    \n",
    "    training_list = [open_price_list_split, high_price_list_split, low_price_list_split, close_price_list_split, \\\n",
    "                    volume_list_split, change_list_split, typical_price_list_split, middle_price_list_split]\n",
    "\n",
    "    training_list_mixed = mix(training_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in training_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 49\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/51\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/26\n",
    "        EMA_25 = []\n",
    "        for i in range(26,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-24:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        training_data = stock_feature_list[:-1]\n",
    "        training_data_total.append(training_data)\n",
    "        \n",
    "        training_label = stock_feature_list[-1]\n",
    "        training_label_total.append(training_label)\n",
    "        \n",
    "\n",
    "print (len(training_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n"
     ]
    }
   ],
   "source": [
    "transformer = RobustScaler().fit(training_data_total)\n",
    "data = transformer.transform(training_data_total)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the validation model 5 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46035\n",
      "26.20882273333334 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "validation_data_total = []\n",
    "validation_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list = open_price[-700:]\n",
    "            open_price_list_split_5 = slic(open_price_list, 9, 60)\n",
    "            \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list = high_price[-700:]\n",
    "            high_price_list_split_5 = slic(high_price_list, 9, 60)\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list = low_price[-700:]\n",
    "            low_price_list_split_5 = slic(low_price_list, 9, 60)\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list = close_price[-700:]\n",
    "            close_price_list_split_5 = slic(close_price_list, 9, 60)\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list = volume[-700:]\n",
    "            volume_list_split_5 = slic(volume_list, 9, 60)\n",
    "        \n",
    "            change.append(row[7])\n",
    "            change_list = change[-700:]\n",
    "            change_list_split_5 = slic(change_list, 9, 60)\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list = typical_price[-700:]\n",
    "            typical_price_list_split_5 = slic(typical_price_list, 9, 60)\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list = middle_price[-700:]\n",
    "            middle_price_list_split_5 = slic(middle_price_list, 9, 60)\n",
    "    \n",
    "    validation_list = [open_price_list_split_5, high_price_list_split_5, low_price_list_split_5, close_price_list_split_5, \\\n",
    "                    volume_list_split_5, change_list_split_5, typical_price_list_split_5, middle_price_list_split_5]\n",
    "\n",
    "    validation_list_mixed = mix(validation_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in validation_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/(negative_money_flow+1))\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 4\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/6\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/3\n",
    "        EMA_25 = []\n",
    "        for i in range(3,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-2:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/(1+cr_neg_sum))\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        validation_data = stock_feature_list[:-1]\n",
    "        validation_data_total.append(validation_data)\n",
    "        \n",
    "        validation_label = stock_feature_list[-1]\n",
    "        validation_label_total.append(validation_label)\n",
    "        \n",
    "\n",
    "print (len(validation_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_v = RobustScaler().fit(validation_data_total)\n",
    "validation_data = transformer_v.transform(validation_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2.0111024499999983 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "testing_data_total = []\n",
    "testing_label_total = []\n",
    "testing_list_total = []\n",
    "\n",
    "count_term=1\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list_testing = open_price[-100:-40]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list_testing = high_price[-100:-40]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list_testing = low_price[-100:-40]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list_testing = close_price[-100:-40]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list_testing = volume[-100:-40]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_list_testing = change[-100:-40]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list_testing = typical_price[-100:-40]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list_testing = middle_price[-100:-40]\n",
    "    \n",
    "    testing_list = [open_price_list_testing, high_price_list_testing, low_price_list_testing, close_price_list_testing, \\\n",
    "                    volume_list_testing, change_list_testing, typical_price_list_testing, middle_price_list_testing]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_list = []\n",
    "    abs_list = []\n",
    "    \n",
    "    for flt in testing_list[5]:\n",
    "        abs_list.append(abs(flt))\n",
    "        if flt > 0:\n",
    "            pos_list.append(flt)\n",
    "    \n",
    "    abs_sum = float('%.3f' % sum(abs_list))\n",
    "    pos_sum = float('%.3f' % sum(pos_list))\n",
    "    raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "    RSI = float('%.3f' % raw_rsi)\n",
    "    stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    indicator_list = [0.5] \n",
    "    \n",
    "    money_flow_list = [vol*tp for vol, tp in zip(testing_list[4], testing_list[6])]\n",
    "    total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "    for i in range(len(testing_list[6])-1):\n",
    "        det = sgn(float('%.2f' % (testing_list[6][i+1] - testing_list[6][i])))\n",
    "        indicator_list.append(det)\n",
    "       \n",
    "    positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "    positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "    negative_money_flow = total_money_flow - positive_money_flow\n",
    "    money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "    raw_mfi = 100-100/(1+money_rate)\n",
    "    MFI = float('%.3f' % raw_mfi)\n",
    "    stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "    if len(testing_list[3]) >= 3:\n",
    "        raw_rsv = 100*(close_price_list_testing[-1] - min(close_price_list_testing))/(max(close_price_list_testing) - min(close_price_list_testing))\n",
    "    RSV = float('%.3f' % raw_rsv)\n",
    "    stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = testing_list[3][-1] - testing_list[3][-5]\n",
    "    bx = testing_list[3][-5]\n",
    "    raw_roc = 100*ax/bx\n",
    "    ROC = float('%.3f' % raw_roc)\n",
    "    stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "    square_sum_5 = []\n",
    "    TP_5 = mean(testing_list[6][-5:])\n",
    "    MA_5 = mean(testing_list[3][-5:])\n",
    "    for i in testing_list[3][-5:]:\n",
    "        square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "    raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "    CCI = float('%.3f' % raw_cci)\n",
    "    stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "    vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(testing_list[3], testing_list[1], testing_list[2])))\n",
    "    \n",
    "    va = []\n",
    "    va_change_list = []\n",
    "    va.append(testing_list[4][0])\n",
    "    \n",
    "    for i in range(0, len(testing_list[4])-1):\n",
    "        va.append(va[i] + vol_para[i]*testing_list[4][i+1])\n",
    "    \n",
    "    for i in range(0, len(va)-1):\n",
    "        va_change_list.append(va[i+1] - va[i])\n",
    "    va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "    if abs(va_change_rate) > 0.1:\n",
    "        VA = sgn(va_change_rate)\n",
    "    else:\n",
    "        VA = sgn_num(va_change_list)\n",
    "    stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    closing_change_list = []\n",
    "\n",
    "    for i in range(0, len(testing_list[3])-1):\n",
    "        closing_change_list.append(testing_list[3][i+1]-testing_list[3][i])\n",
    "   \n",
    "    closing_price_list_pvt = testing_list[3][1:]\n",
    "    volume_list_pvt = volume_list_testing[1:]\n",
    "    pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "    raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "    PVT = float('%.3f' % raw_pvt)\n",
    "    stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sign_closing_change_list = []\n",
    "    for i in closing_change_list:\n",
    "        sign_closing_change_list.append(sgn_0(i))\n",
    "    obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, testing_list[4][1:])))\n",
    "    raw_obv = sqrt_abs(sum(obv_list))\n",
    "    OBV = float('%.3f' % raw_obv)\n",
    "    stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exp_len = 49\n",
    "    exp_starting = len(testing_list[3]) - exp_len\n",
    "    price_list_50 = [mean(testing_list[3][:exp_starting])] + testing_list[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "    const_50 = 2/51\n",
    "    EMA_50 = []\n",
    "    for i in range(1,len(price_list_50)):\n",
    "        raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "        ema_50 = float('%.3f' % raw_ema_50)\n",
    "        EMA_50.append(ema_50)\n",
    "    \n",
    "    const_25 = 2/26\n",
    "    EMA_25 = []\n",
    "    for i in range(26,len(price_list_50)):\n",
    "        raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "        ema_25 = float('%.3f' % raw_ema_25)\n",
    "        EMA_25.append(ema_25)\n",
    "        \n",
    "    EMA_50c = EMA_50[-24:]\n",
    "    EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "    EMA_mean = np.mean(EMA_diff)*100\n",
    "    EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "    stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "    stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "    stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cr_pos = []\n",
    "    cr_neg = []\n",
    "    \n",
    "    middle_price_list_c = testing_list[7][:-1]\n",
    "    closing_price_list_c = testing_list[3][1:]\n",
    "    cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "    for i in cr_list:\n",
    "        if i > 0:\n",
    "            cr_pos.append(i)\n",
    "        else:\n",
    "            cr_neg.append(abs(i))\n",
    "    \n",
    "    cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "    cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "    raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "    CR = float('%.3f' % raw_cr)\n",
    "    stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "    square_sum = []\n",
    "    MA = mean(testing_list[3])\n",
    "    MB = mean(testing_list[3][:-1])\n",
    "    \n",
    "    for i in testing_list[3]:\n",
    "        square_sum.append((i-MA)**2)\n",
    "    MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "    raw_UP = MB+2*MD\n",
    "    raw_DN = MB-2*MD\n",
    "    UP = float('%.3f' % raw_UP)\n",
    "    DN = float('%.3f' % raw_DN)\n",
    "    stock_feature_dict[\"UP\"] = UP\n",
    "    stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        \n",
    "    if testing_list[3][-1] > testing_list[3][0]:\n",
    "        stock_feature_dict[\"change_c\"] = 1\n",
    "    else:\n",
    "        stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "    stock_feature_list = list(stock_feature_dict.values())\n",
    "    stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "    stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "    testing_data = stock_feature_list[:-1]\n",
    "    testing_data_total.append(testing_data)\n",
    "        \n",
    "    testing_label = stock_feature_list[-1]\n",
    "    testing_label_total.append(testing_label)\n",
    "    \n",
    "    \n",
    "    \n",
    "print (len(testing_list_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_testing = RobustScaler().fit(testing_data_total)\n",
    "data_testing = transformer_testing.transform(testing_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree has accuracy on validation 0.7980449657869013\n",
      "decision tree has precision on validation 0.7144790257104194\n",
      "decision tree has recall on validation 0.7983870967741935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.80      0.83      3131\n",
      "           1       0.71      0.80      0.75      1984\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.80      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[2498  633]\n",
      " [ 400 1584]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.4095796676441838\n",
      "decision tree has precision on testing 0.6845238095238095\n",
      "decision tree has recall on testing 0.03731343283582089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.97      0.57      2033\n",
      "           1       0.68      0.04      0.07      3082\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.54      0.51      0.32      5115\n",
      "weighted avg       0.57      0.41      0.27      5115\n",
      "\n",
      "[[1980   53]\n",
      " [2967  115]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.81544477028348\n",
      "log reg has precision on validation 0.6943198804185351\n",
      "log reg has recall on validation 0.936491935483871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.74      0.83      3131\n",
      "           1       0.69      0.94      0.80      1984\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.82      0.84      0.81      5115\n",
      "weighted avg       0.85      0.82      0.82      5115\n",
      "\n",
      "[[2313  818]\n",
      " [ 126 1858]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.39745845552297165\n",
      "log reg has precision on testing 0.0\n",
      "log reg has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.40821114369501466\n",
      "naive bayes has precision on validation 0.3955119214586255\n",
      "naive bayes has recall on validation 0.9949596774193549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.04      0.07      3131\n",
      "           1       0.40      0.99      0.57      1984\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.66      0.52      0.32      5115\n",
      "weighted avg       0.72      0.41      0.26      5115\n",
      "\n",
      "[[ 114 3017]\n",
      " [  10 1974]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.39745845552297165\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8164222873900293\n",
      "svm has precision on validation 0.6954732510288066\n",
      "svm has recall on validation 0.9369959677419355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.74      0.83      3131\n",
      "           1       0.70      0.94      0.80      1984\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.82      0.84      0.81      5115\n",
      "weighted avg       0.85      0.82      0.82      5115\n",
      "\n",
      "[[2317  814]\n",
      " [ 125 1859]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3976539589442815\n",
      "svm has precision on testing 1.0\n",
      "svm has recall on testing 0.0003244646333549643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       1.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.70      0.50      0.28      5115\n",
      "weighted avg       0.76      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3081    1]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.835386119257087\n",
      "random forest has precision on validation 0.7403198653198653\n",
      "random forest has recall on validation 0.8865927419354839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.80      0.86      3131\n",
      "           1       0.74      0.89      0.81      1984\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.83      0.84      0.83      5115\n",
      "weighted avg       0.85      0.84      0.84      5115\n",
      "\n",
      "[[2514  617]\n",
      " [ 225 1759]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7976539589442815\n",
      "random forest has precision on testing 0.837677334213131\n",
      "random forest has recall on testing 0.8238157040882543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75      2033\n",
      "           1       0.84      0.82      0.83      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1541  492]\n",
      " [ 543 2539]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8089931573802541\n",
      "decision tree has precision on validation 0.7276404494382023\n",
      "decision tree has recall on validation 0.8135678391959799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.81      0.84      3125\n",
      "           1       0.73      0.81      0.77      1990\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.81      0.80      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[2519  606]\n",
      " [ 371 1619]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7808406647116325\n",
      "decision tree has precision on testing 0.8681937664288396\n",
      "decision tree has recall on testing 0.7501622323166774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.83      0.75      2033\n",
      "           1       0.87      0.75      0.80      3082\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.79      0.78      5115\n",
      "weighted avg       0.80      0.78      0.78      5115\n",
      "\n",
      "[[1682  351]\n",
      " [ 770 2312]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8422287390029326\n",
      "log reg has precision on validation 0.7423187218353134\n",
      "log reg has recall on validation 0.9105527638190954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.80      0.86      3125\n",
      "           1       0.74      0.91      0.82      1990\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.85      0.84      5115\n",
      "weighted avg       0.86      0.84      0.84      5115\n",
      "\n",
      "[[2496  629]\n",
      " [ 178 1812]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.5530791788856305\n",
      "log reg has precision on testing 0.9950248756218906\n",
      "log reg has recall on testing 0.25957170668397145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      1.00      0.64      2033\n",
      "           1       1.00      0.26      0.41      3082\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5115\n",
      "   macro avg       0.73      0.63      0.53      5115\n",
      "weighted avg       0.79      0.55      0.50      5115\n",
      "\n",
      "[[2029    4]\n",
      " [2282  800]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.4195503421309873\n",
      "naive bayes has precision on validation 0.40129058277878604\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.05      0.10      3125\n",
      "           1       0.40      1.00      0.57      1990\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.70      0.52      0.33      5115\n",
      "weighted avg       0.77      0.42      0.28      5115\n",
      "\n",
      "[[ 156 2969]\n",
      " [   0 1990]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.39824046920821116\n",
      "naive bayes has precision on testing 0.7\n",
      "naive bayes has recall on testing 0.0022712524334847503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.70      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.55      0.50      0.29      5115\n",
      "weighted avg       0.58      0.40      0.23      5115\n",
      "\n",
      "[[2030    3]\n",
      " [3075    7]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.829325513196481\n",
      "svm has precision on validation 0.7179087007413187\n",
      "svm has recall on validation 0.9246231155778895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.77      0.85      3125\n",
      "           1       0.72      0.92      0.81      1990\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.83      0.85      0.83      5115\n",
      "weighted avg       0.85      0.83      0.83      5115\n",
      "\n",
      "[[2402  723]\n",
      " [ 150 1840]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.39745845552297165\n",
      "svm has precision on testing 0.0\n",
      "svm has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8461388074291301\n",
      "random forest has precision on validation 0.7503121098626716\n",
      "random forest has recall on validation 0.9060301507537688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.81      0.87      3125\n",
      "           1       0.75      0.91      0.82      1990\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.84      0.86      0.84      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[2525  600]\n",
      " [ 187 1803]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8009775171065494\n",
      "random forest has precision on testing 0.83055733504164\n",
      "random forest has recall on testing 0.8413367942894224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.74      0.75      2033\n",
      "           1       0.83      0.84      0.84      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1504  529]\n",
      " [ 489 2593]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.860019550342131\n",
      "decision tree has precision on validation 0.6814545454545454\n",
      "decision tree has recall on validation 0.77119341563786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.89      0.91      3900\n",
      "           1       0.68      0.77      0.72      1215\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.80      0.83      0.81      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[3462  438]\n",
      " [ 278  937]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.3571847507331378\n",
      "decision tree has precision on testing 0.3271812080536913\n",
      "decision tree has recall on testing 0.06327060350421804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.36      0.80      0.50      2033\n",
      "           1       0.33      0.06      0.11      3082\n",
      "\n",
      "   micro avg       0.36      0.36      0.36      5115\n",
      "   macro avg       0.34      0.43      0.30      5115\n",
      "weighted avg       0.34      0.36      0.26      5115\n",
      "\n",
      "[[1632  401]\n",
      " [2887  195]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8705767350928642\n",
      "log reg has precision on validation 0.6608493310063991\n",
      "log reg has recall on validation 0.9349794238683128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.85      0.91      3900\n",
      "           1       0.66      0.93      0.77      1215\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.82      0.89      0.84      5115\n",
      "weighted avg       0.90      0.87      0.88      5115\n",
      "\n",
      "[[3317  583]\n",
      " [  79 1136]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.39745845552297165\n",
      "log reg has precision on testing 0.0\n",
      "log reg has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.42306940371456503\n",
      "naive bayes has precision on validation 0.2915465898174832\n",
      "naive bayes has recall on validation 0.9991769547325103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.24      0.39      3900\n",
      "           1       0.29      1.00      0.45      1215\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.65      0.62      0.42      5115\n",
      "weighted avg       0.83      0.42      0.41      5115\n",
      "\n",
      "[[ 950 2950]\n",
      " [   1 1214]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3972629521016618\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2032    1]\n",
      " [3082    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8701857282502444\n",
      "svm has precision on validation 0.6619635508524397\n",
      "svm has recall on validation 0.9267489711934156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.85      0.91      3900\n",
      "           1       0.66      0.93      0.77      1215\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.82      0.89      0.84      5115\n",
      "weighted avg       0.90      0.87      0.88      5115\n",
      "\n",
      "[[3325  575]\n",
      " [  89 1126]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.39745845552297165\n",
      "svm has precision on testing 0.0\n",
      "svm has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8883675464320626\n",
      "random forest has precision on validation 0.7158176943699732\n",
      "random forest has recall on validation 0.8790123456790123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.89      0.92      3900\n",
      "           1       0.72      0.88      0.79      1215\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      5115\n",
      "   macro avg       0.84      0.89      0.86      5115\n",
      "weighted avg       0.90      0.89      0.89      5115\n",
      "\n",
      "[[3476  424]\n",
      " [ 147 1068]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8033235581622679\n",
      "random forest has precision on testing 0.8255959849435383\n",
      "random forest has recall on testing 0.853990914990266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.73      0.75      2033\n",
      "           1       0.83      0.85      0.84      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1477  556]\n",
      " [ 450 2632]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8594330400782013\n",
      "decision tree has precision on validation 0.92575\n",
      "decision tree has recall on validation 0.8976969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.70      0.66       990\n",
      "           1       0.93      0.90      0.91      4125\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.77      0.80      0.78      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[ 693  297]\n",
      " [ 422 3703]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7331378299120235\n",
      "decision tree has precision on testing 0.7872198059551689\n",
      "decision tree has recall on testing 0.763465282284231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.69      0.67      2033\n",
      "           1       0.79      0.76      0.78      3082\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5115\n",
      "   macro avg       0.72      0.73      0.72      5115\n",
      "weighted avg       0.74      0.73      0.73      5115\n",
      "\n",
      "[[1397  636]\n",
      " [ 729 2353]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.5929618768328446\n",
      "log reg has precision on validation 0.8456852791878172\n",
      "log reg has recall on validation 0.6058181818181818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.25      0.54      0.34       990\n",
      "           1       0.85      0.61      0.71      4125\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.55      0.57      0.52      5115\n",
      "weighted avg       0.73      0.59      0.63      5115\n",
      "\n",
      "[[ 534  456]\n",
      " [1626 2499]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.5718475073313783\n",
      "log reg has precision on testing 0.640960809102402\n",
      "log reg has recall on testing 0.6580142764438677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.44      0.45      2033\n",
      "           1       0.64      0.66      0.65      3082\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      5115\n",
      "   macro avg       0.55      0.55      0.55      5115\n",
      "weighted avg       0.57      0.57      0.57      5115\n",
      "\n",
      "[[ 897 1136]\n",
      " [1054 2028]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.8064516129032258\n",
      "naive bayes has precision on validation 0.8064516129032258\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       990\n",
      "           1       0.81      1.00      0.89      4125\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.40      0.50      0.45      5115\n",
      "weighted avg       0.65      0.81      0.72      5115\n",
      "\n",
      "[[   0  990]\n",
      " [   0 4125]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.6025415444770283\n",
      "naive bayes has precision on testing 0.6025415444770283\n",
      "naive bayes has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2033\n",
      "           1       0.60      1.00      0.75      3082\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.30      0.50      0.38      5115\n",
      "weighted avg       0.36      0.60      0.45      5115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 2033]\n",
      " [   0 3082]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.9057673509286412\n",
      "svm has precision on validation 0.9108955560568464\n",
      "svm has recall on validation 0.978909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.60      0.71       990\n",
      "           1       0.91      0.98      0.94      4125\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      5115\n",
      "   macro avg       0.89      0.79      0.83      5115\n",
      "weighted avg       0.90      0.91      0.90      5115\n",
      "\n",
      "[[ 595  395]\n",
      " [  87 4038]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.39745845552297165\n",
      "svm has precision on testing 0.0\n",
      "svm has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest has accuracy on validation 0.9038123167155425\n",
      "random forest has precision on validation 0.9283187927375619\n",
      "random forest has recall on validation 0.9544242424242424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.69      0.74       990\n",
      "           1       0.93      0.95      0.94      4125\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      5115\n",
      "   macro avg       0.86      0.82      0.84      5115\n",
      "weighted avg       0.90      0.90      0.90      5115\n",
      "\n",
      "[[ 686  304]\n",
      " [ 188 3937]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7990224828934507\n",
      "random forest has precision on testing 0.8402915838303512\n",
      "random forest has recall on testing 0.8228423101881895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75      2033\n",
      "           1       0.84      0.82      0.83      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1551  482]\n",
      " [ 546 2536]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8160312805474096\n",
      "decision tree has precision on validation 0.8646341463414634\n",
      "decision tree has recall on validation 0.8508850885088509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.75      0.74      1782\n",
      "           1       0.86      0.85      0.86      3333\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1338  444]\n",
      " [ 497 2836]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.45767350928641254\n",
      "decision tree has precision on testing 0.602803738317757\n",
      "decision tree has recall on testing 0.2929915639195328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.71      0.51      2033\n",
      "           1       0.60      0.29      0.39      3082\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      5115\n",
      "   macro avg       0.50      0.50      0.45      5115\n",
      "weighted avg       0.52      0.46      0.44      5115\n",
      "\n",
      "[[1438  595]\n",
      " [2179  903]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8535679374389051\n",
      "log reg has precision on validation 0.8294237633860275\n",
      "log reg has recall on validation 0.975997599759976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.62      0.75      1782\n",
      "           1       0.83      0.98      0.90      3333\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.88      0.80      0.82      5115\n",
      "weighted avg       0.87      0.85      0.85      5115\n",
      "\n",
      "[[1113  669]\n",
      " [  80 3253]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.39745845552297165\n",
      "log reg has precision on testing 0.0\n",
      "log reg has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes has accuracy on validation 0.7016617790811339\n",
      "naive bayes has precision on validation 0.6866349927700888\n",
      "naive bayes has recall on validation 0.9972997299729973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.15      0.26      1782\n",
      "           1       0.69      1.00      0.81      3333\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.83      0.57      0.54      5115\n",
      "weighted avg       0.78      0.70      0.62      5115\n",
      "\n",
      "[[ 265 1517]\n",
      " [   9 3324]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.39745845552297165\n",
      "naive bayes has precision on testing 0.5\n",
      "naive bayes has recall on testing 0.000973393900064893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.50      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.45      0.50      0.29      5115\n",
      "weighted avg       0.46      0.40      0.23      5115\n",
      "\n",
      "[[2030    3]\n",
      " [3079    3]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8516129032258064\n",
      "svm has precision on validation 0.8268156424581006\n",
      "svm has recall on validation 0.976897689768977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.62      0.74      1782\n",
      "           1       0.83      0.98      0.90      3333\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.88      0.80      0.82      5115\n",
      "weighted avg       0.86      0.85      0.84      5115\n",
      "\n",
      "[[1100  682]\n",
      " [  77 3256]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3976539589442815\n",
      "svm has precision on testing 1.0\n",
      "svm has recall on testing 0.0003244646333549643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       1.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.70      0.50      0.28      5115\n",
      "weighted avg       0.76      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3081    1]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8651026392961877\n",
      "random forest has precision on validation 0.8568728058331083\n",
      "random forest has recall on validation 0.951995199519952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.70      0.78      1782\n",
      "           1       0.86      0.95      0.90      3333\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.83      0.84      5115\n",
      "weighted avg       0.87      0.87      0.86      5115\n",
      "\n",
      "[[1252  530]\n",
      " [ 160 3173]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7986314760508308\n",
      "random forest has precision on testing 0.8326848249027238\n",
      "random forest has recall on testing 0.8332251784555483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.75      0.75      2033\n",
      "           1       0.83      0.83      0.83      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1517  516]\n",
      " [ 514 2568]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.806256109481916\n",
      "decision tree has precision on validation 0.8195286195286196\n",
      "decision tree has recall on validation 0.8425060574593285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.76      0.77      2226\n",
      "           1       0.82      0.84      0.83      2889\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.80      0.80      0.80      5115\n",
      "weighted avg       0.81      0.81      0.81      5115\n",
      "\n",
      "[[1690  536]\n",
      " [ 455 2434]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.46314760508308894\n",
      "decision tree has precision on testing 0.5486392588303416\n",
      "decision tree has recall on testing 0.6148604802076574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.23      0.26      2033\n",
      "           1       0.55      0.61      0.58      3082\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      5115\n",
      "   macro avg       0.42      0.42      0.42      5115\n",
      "weighted avg       0.44      0.46      0.45      5115\n",
      "\n",
      "[[ 474 1559]\n",
      " [1187 1895]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8435972629521017\n",
      "log reg has precision on validation 0.8017913897717422\n",
      "log reg has recall on validation 0.960539979231568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.69      0.79      2226\n",
      "           1       0.80      0.96      0.87      2889\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.87      0.83      0.83      5115\n",
      "weighted avg       0.86      0.84      0.84      5115\n",
      "\n",
      "[[1540  686]\n",
      " [ 114 2775]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.39745845552297165\n",
      "log reg has precision on testing 0.0\n",
      "log reg has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes has accuracy on validation 0.6981427174975562\n",
      "naive bayes has precision on validation 0.652183751980086\n",
      "naive bayes has recall on validation 0.9975770162686051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.31      0.47      2226\n",
      "           1       0.65      1.00      0.79      2889\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5115\n",
      "   macro avg       0.82      0.65      0.63      5115\n",
      "weighted avg       0.80      0.70      0.65      5115\n",
      "\n",
      "[[ 689 1537]\n",
      " [   7 2882]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.39745845552297165\n",
      "naive bayes has precision on testing 0.5\n",
      "naive bayes has recall on testing 0.0003244646333549643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.50      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.45      0.50      0.28      5115\n",
      "weighted avg       0.46      0.40      0.23      5115\n",
      "\n",
      "[[2032    1]\n",
      " [3081    1]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.844574780058651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has precision on validation 0.8054259043173863\n",
      "svm has recall on validation 0.9556940117687781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.70      0.80      2226\n",
      "           1       0.81      0.96      0.87      2889\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.86      0.83      0.84      5115\n",
      "weighted avg       0.86      0.84      0.84      5115\n",
      "\n",
      "[[1559  667]\n",
      " [ 128 2761]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3980449657869013\n",
      "svm has precision on testing 1.0\n",
      "svm has recall on testing 0.000973393900064893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       1.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.70      0.50      0.29      5115\n",
      "weighted avg       0.76      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3079    3]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8666666666666667\n",
      "random forest has precision on validation 0.8466855168080427\n",
      "random forest has recall on validation 0.9328487365870544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.78      0.84      2226\n",
      "           1       0.85      0.93      0.89      2889\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.86      0.86      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1738  488]\n",
      " [ 194 2695]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.7990224828934507\n",
      "random forest has precision on testing 0.8430193720774883\n",
      "random forest has recall on testing 0.8189487345879299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.77      0.75      2033\n",
      "           1       0.84      0.82      0.83      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1563  470]\n",
      " [ 558 2524]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8273704789833822\n",
      "decision tree has precision on validation 0.8410414525522439\n",
      "decision tree has recall on validation 0.8542101600556715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.79      0.80      2241\n",
      "           1       0.84      0.85      0.85      2874\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.83      0.82      0.82      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1777  464]\n",
      " [ 419 2455]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.21407624633431085\n",
      "decision tree has precision on testing 0.291740674955595\n",
      "decision tree has recall on testing 0.21317326411421156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.22      0.18      2033\n",
      "           1       0.29      0.21      0.25      3082\n",
      "\n",
      "   micro avg       0.21      0.21      0.21      5115\n",
      "   macro avg       0.22      0.21      0.21      5115\n",
      "weighted avg       0.24      0.21      0.22      5115\n",
      "\n",
      "[[ 438 1595]\n",
      " [2425  657]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8598240469208212\n",
      "log reg has precision on validation 0.8315401168152474\n",
      "log reg has recall on validation 0.941196938065414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.76      0.83      2241\n",
      "           1       0.83      0.94      0.88      2874\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.85      0.85      5115\n",
      "weighted avg       0.87      0.86      0.86      5115\n",
      "\n",
      "[[1693  548]\n",
      " [ 169 2705]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.3976539589442815\n",
      "log reg has precision on testing 1.0\n",
      "log reg has recall on testing 0.0003244646333549643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       1.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.70      0.50      0.28      5115\n",
      "weighted avg       0.76      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3081    1]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.8113391984359726\n",
      "naive bayes has precision on validation 0.7638927287807575\n",
      "naive bayes has recall on validation 0.9613778705636743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.62      0.74      2241\n",
      "           1       0.76      0.96      0.85      2874\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.84      0.79      0.80      5115\n",
      "weighted avg       0.83      0.81      0.80      5115\n",
      "\n",
      "[[1387  854]\n",
      " [ 111 2763]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.39745845552297165\n",
      "naive bayes has precision on testing 0.0\n",
      "naive bayes has recall on testing 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       0.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.20      0.50      0.28      5115\n",
      "weighted avg       0.16      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3082    0]]\n",
      "============================================================\n",
      "svm has accuracy on validation 0.8594330400782013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has precision on validation 0.8322540857230959\n",
      "svm has recall on validation 0.9391092553931802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.76      0.83      2241\n",
      "           1       0.83      0.94      0.88      2874\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.85      0.85      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1697  544]\n",
      " [ 175 2699]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.3980449657869013\n",
      "svm has precision on testing 1.0\n",
      "svm has recall on testing 0.000973393900064893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      1.00      0.57      2033\n",
      "           1       1.00      0.00      0.00      3082\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.70      0.50      0.29      5115\n",
      "weighted avg       0.76      0.40      0.23      5115\n",
      "\n",
      "[[2033    0]\n",
      " [3079    3]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8596285434995112\n",
      "random forest has precision on validation 0.8588548601864181\n",
      "random forest has recall on validation 0.8977035490605428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.81      0.84      2241\n",
      "           1       0.86      0.90      0.88      2874\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.85      0.86      5115\n",
      "weighted avg       0.86      0.86      0.86      5115\n",
      "\n",
      "[[1817  424]\n",
      " [ 294 2580]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.798435972629521\n",
      "random forest has precision on testing 0.8358991156239765\n",
      "random forest has recall on testing 0.8280337443218689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.75      0.75      2033\n",
      "           1       0.84      0.83      0.83      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1532  501]\n",
      " [ 530 2552]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8344086021505376\n",
      "decision tree has precision on validation 0.8528864059590316\n",
      "decision tree has recall on validation 0.8804870233899391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.76      0.78      1994\n",
      "           1       0.85      0.88      0.87      3121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.83      0.82      0.82      5115\n",
      "weighted avg       0.83      0.83      0.83      5115\n",
      "\n",
      "[[1520  474]\n",
      " [ 373 2748]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5515151515151515\n",
      "decision tree has precision on testing 0.6536661466458659\n",
      "decision tree has recall on testing 0.5438027255029202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.56      0.50      2033\n",
      "           1       0.65      0.54      0.59      3082\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5115\n",
      "   macro avg       0.55      0.55      0.55      5115\n",
      "weighted avg       0.57      0.55      0.56      5115\n",
      "\n",
      "[[1145  888]\n",
      " [1406 1676]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.7925708699902249\n",
      "log reg has precision on validation 0.7988972721996518\n",
      "log reg has recall on validation 0.8820890740147389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.65      0.71      1994\n",
      "           1       0.80      0.88      0.84      3121\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.77      0.77      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1301  693]\n",
      " [ 368 2753]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6025415444770283\n",
      "log reg has precision on testing 0.6025415444770283\n",
      "log reg has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2033\n",
      "           1       0.60      1.00      0.75      3082\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.30      0.50      0.38      5115\n",
      "weighted avg       0.36      0.60      0.45      5115\n",
      "\n",
      "[[   0 2033]\n",
      " [   0 3082]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6217008797653959\n",
      "naive bayes has precision on validation 0.6186\n",
      "naive bayes has recall on validation 0.9910285165011214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.04      0.08      1994\n",
      "           1       0.62      0.99      0.76      3121\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      5115\n",
      "   macro avg       0.69      0.52      0.42      5115\n",
      "weighted avg       0.67      0.62      0.50      5115\n",
      "\n",
      "[[  87 1907]\n",
      " [  28 3093]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.33470185728250246\n",
      "naive bayes has precision on testing 0.45675020210185935\n",
      "naive bayes has recall on testing 0.5499675535366645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      0.01      0.01      2033\n",
      "           1       0.46      0.55      0.50      3082\n",
      "\n",
      "   micro avg       0.33      0.33      0.33      5115\n",
      "   macro avg       0.23      0.28      0.25      5115\n",
      "weighted avg       0.28      0.33      0.30      5115\n",
      "\n",
      "[[  17 2016]\n",
      " [1387 1695]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8207233626588465\n",
      "svm has precision on validation 0.7812659520163349\n",
      "svm has recall on validation 0.9807753925024031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.57      0.71      1994\n",
      "           1       0.78      0.98      0.87      3121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.87      0.78      0.79      5115\n",
      "weighted avg       0.85      0.82      0.81      5115\n",
      "\n",
      "[[1137  857]\n",
      " [  60 3061]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8570869990224829\n",
      "svm has precision on testing 0.9681401831939467\n",
      "svm has recall on testing 0.7887735236859182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.96      0.84      2033\n",
      "           1       0.97      0.79      0.87      3082\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.86      0.87      0.86      5115\n",
      "weighted avg       0.88      0.86      0.86      5115\n",
      "\n",
      "[[1953   80]\n",
      " [ 651 2431]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8758553274682307\n",
      "random forest has precision on validation 0.8653733098177543\n",
      "random forest has recall on validation 0.9432874078820891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.77      0.83      1994\n",
      "           1       0.87      0.94      0.90      3121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.88      0.86      0.87      5115\n",
      "weighted avg       0.88      0.88      0.87      5115\n",
      "\n",
      "[[1536  458]\n",
      " [ 177 2944]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8011730205278592\n",
      "random forest has precision on testing 0.8287169691181152\n",
      "random forest has recall on testing 0.8445814406229721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.74      0.75      2033\n",
      "           1       0.83      0.84      0.84      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1495  538]\n",
      " [ 479 2603]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.820136852394917\n",
      "decision tree has precision on validation 0.8586350974930362\n",
      "decision tree has recall on validation 0.8275167785234899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.81      0.79      2135\n",
      "           1       0.86      0.83      0.84      2980\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.81      0.82      0.82      5115\n",
      "weighted avg       0.82      0.82      0.82      5115\n",
      "\n",
      "[[1729  406]\n",
      " [ 514 2466]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.601564027370479\n",
      "decision tree has precision on testing 0.603202846975089\n",
      "decision tree has recall on testing 0.9899415963659961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.01      0.02      2033\n",
      "           1       0.60      0.99      0.75      3082\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.53      0.50      0.39      5115\n",
      "weighted avg       0.54      0.60      0.46      5115\n",
      "\n",
      "[[  26 2007]\n",
      " [  31 3051]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8220918866080157\n",
      "log reg has precision on validation 0.7852811466372657\n",
      "log reg has recall on validation 0.9560402684563758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.64      0.75      2135\n",
      "           1       0.79      0.96      0.86      2980\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.85      0.80      0.81      5115\n",
      "weighted avg       0.84      0.82      0.81      5115\n",
      "\n",
      "[[1356  779]\n",
      " [ 131 2849]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6023460410557184\n",
      "log reg has precision on testing 0.6024638247946813\n",
      "log reg has recall on testing 0.999675535366645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2033\n",
      "           1       0.60      1.00      0.75      3082\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.30      0.50      0.38      5115\n",
      "weighted avg       0.36      0.60      0.45      5115\n",
      "\n",
      "[[   0 2033]\n",
      " [   1 3081]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6328445747800586\n",
      "naive bayes has precision on validation 0.614743856726364\n",
      "naive bayes has recall on validation 0.9906040268456375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.13      0.23      2135\n",
      "           1       0.61      0.99      0.76      2980\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.76      0.56      0.50      5115\n",
      "weighted avg       0.74      0.63      0.54      5115\n",
      "\n",
      "[[ 285 1850]\n",
      " [  28 2952]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.3106549364613881\n",
      "naive bayes has precision on testing 0.4379541643376188\n",
      "naive bayes has recall on testing 0.5084360804672291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      0.01      0.01      2033\n",
      "           1       0.44      0.51      0.47      3082\n",
      "\n",
      "   micro avg       0.31      0.31      0.31      5115\n",
      "   macro avg       0.23      0.26      0.24      5115\n",
      "weighted avg       0.27      0.31      0.29      5115\n",
      "\n",
      "[[  22 2011]\n",
      " [1515 1567]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8504398826979472\n",
      "svm has precision on validation 0.8156169848959818\n",
      "svm has recall on validation 0.9604026845637584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.70      0.80      2135\n",
      "           1       0.82      0.96      0.88      2980\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.87      0.83      0.84      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[1488  647]\n",
      " [ 118 2862]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8694037145650049\n",
      "svm has precision on testing 0.961038961038961\n",
      "svm has recall on testing 0.8163530175210902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.95      0.85      2033\n",
      "           1       0.96      0.82      0.88      3082\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.88      0.87      5115\n",
      "weighted avg       0.89      0.87      0.87      5115\n",
      "\n",
      "[[1931  102]\n",
      " [ 566 2516]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8848484848484849\n",
      "random forest has precision on validation 0.8880233690360273\n",
      "random forest has recall on validation 0.9181208053691275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.84      0.86      2135\n",
      "           1       0.89      0.92      0.90      2980\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      5115\n",
      "   macro avg       0.88      0.88      0.88      5115\n",
      "weighted avg       0.88      0.88      0.88      5115\n",
      "\n",
      "[[1790  345]\n",
      " [ 244 2736]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8017595307917889\n",
      "random forest has precision on testing 0.8272151898734177\n",
      "random forest has recall on testing 0.8481505515898767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.73      0.75      2033\n",
      "           1       0.83      0.85      0.84      3082\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.79      0.79      0.79      5115\n",
      "weighted avg       0.80      0.80      0.80      5115\n",
      "\n",
      "[[1487  546]\n",
      " [ 468 2614]]\n",
      "============================================================\n",
      "20.352020000000266 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.clock()\n",
    "\n",
    "dt_val_acc = []\n",
    "dt_testing_acc = []\n",
    "\n",
    "log_val_acc = []\n",
    "log_testing_acc = []\n",
    "\n",
    "nb_val_acc = []\n",
    "nb_testing_acc = []\n",
    "\n",
    "svm_val_acc = []\n",
    "svm_testing_acc = []\n",
    "\n",
    "rf_val_acc = []\n",
    "rf_testing_acc = []\n",
    "\n",
    "\n",
    "training_data_split = cut(data, 9)\n",
    "training_label_split = cut(training_label_total, 9)\n",
    "\n",
    "validation_data_split = cut(validation_data, 9)\n",
    "validation_label_split = cut(validation_label_total, 9)\n",
    "\n",
    "# print (training_data_split[2])\n",
    "\n",
    "for i in range (0, 9):\n",
    "    training_sub_list = []\n",
    "    training_sub_list.append(training_data_split[i])\n",
    "    training_sub_list.append(training_label_split[i])\n",
    "    \n",
    "    validation_sub_list = []\n",
    "    validation_sub_list.append(validation_data_split[i])\n",
    "    validation_sub_list.append(validation_label_split[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1 = tree.DecisionTreeClassifier()\n",
    "    dt_model = model1.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    dt_result = dt_model.predict(validation_sub_list[0])\n",
    "    dt_testing_result = dt_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"decision tree has accuracy on validation\", accuracy_score(validation_sub_list[-1], dt_result))\n",
    "    dt_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], dt_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on validation\", precision_score(validation_sub_list[-1], dt_result))\n",
    "    print (\"decision tree has recall on validation\", recall_score(validation_sub_list[-1], dt_result))\n",
    "    print (classification_report(validation_sub_list[-1], dt_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], dt_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"decision tree has accuracy on testing\", accuracy_score(testing_label_total, dt_testing_result))\n",
    "    dt_testing_acc.append(float(format(accuracy_score(testing_label_total, dt_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on testing\", precision_score(testing_label_total, dt_testing_result))\n",
    "    print (\"decision tree has recall on testing\", recall_score(testing_label_total, dt_testing_result))\n",
    "    print (classification_report(testing_label_total, dt_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, dt_testing_result))    \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model2 = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr')\n",
    "    log_model = model2.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    log_result = log_model.predict(validation_sub_list[0])\n",
    "    log_testing_result = log_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"log reg has accuracy on validation\", accuracy_score(validation_sub_list[-1], log_result))\n",
    "    log_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], log_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on validation\", precision_score(validation_sub_list[-1], log_result))\n",
    "    print (\"log reg has recall on validation\", recall_score(validation_sub_list[-1], log_result))\n",
    "    print (classification_report(validation_sub_list[-1], log_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], log_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"log reg has accuracy on testing\", accuracy_score(testing_label_total, log_testing_result))\n",
    "    log_testing_acc.append(float(format(accuracy_score(testing_label_total, log_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on testing\", precision_score(testing_label_total, log_testing_result))\n",
    "    print (\"log reg has recall on testing\", recall_score(testing_label_total, log_testing_result))\n",
    "    print (classification_report(testing_label_total, log_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, log_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "   \n",
    "\n",
    "    \n",
    "    model3 = GaussianNB()\n",
    "    nb_model = model3.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    nb_result = nb_model.predict(validation_sub_list[0])\n",
    "    nb_testing_result = nb_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"naive bayes has accuracy on validation\", accuracy_score(validation_sub_list[-1], nb_result))\n",
    "    nb_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], nb_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on validation\", precision_score(validation_sub_list[-1], nb_result))\n",
    "    print (\"naive bayes has recall on validation\", recall_score(validation_sub_list[-1], nb_result))\n",
    "    print (classification_report(validation_sub_list[-1], nb_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], nb_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"naive bayes has accuracy on testing\", accuracy_score(testing_label_total, nb_testing_result))\n",
    "    nb_testing_acc.append(float(format(accuracy_score(testing_label_total, nb_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on testing\", precision_score(testing_label_total, nb_testing_result))\n",
    "    print (\"naive bayes has recall on testing\", recall_score(testing_label_total, nb_testing_result))\n",
    "    print (classification_report(testing_label_total, nb_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, nb_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model4 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    svm_model = model4.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    svm_result = svm_model.predict(validation_sub_list[0])\n",
    "    svm_testing_result = svm_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"svm has accuracy on validation\", accuracy_score(validation_sub_list[-1], svm_result))\n",
    "    svm_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], svm_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on validation\", precision_score(validation_sub_list[-1], svm_result))\n",
    "    print (\"svm has recall on validation\", recall_score(validation_sub_list[-1], svm_result))\n",
    "    print (classification_report(validation_sub_list[-1], svm_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], svm_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"svm has accuracy on testing\", accuracy_score(testing_label_total, svm_testing_result))\n",
    "    svm_testing_acc.append(float(format(accuracy_score(testing_label_total, svm_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on testing\", precision_score(testing_label_total, svm_testing_result))\n",
    "    print (\"svm has recall on testing\", recall_score(testing_label_total, svm_testing_result))\n",
    "    print (classification_report(testing_label_total, svm_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, svm_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model5 = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n",
    "    rf_model = model5.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    rf_result = rf_model.predict(validation_sub_list[0])\n",
    "    rf_testing_result = rf_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"random forest has accuracy on validation\", accuracy_score(validation_sub_list[-1], rf_result))\n",
    "    rf_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], rf_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on validation\", precision_score(validation_sub_list[-1], rf_result))\n",
    "    print (\"random forest has recall on validation\", recall_score(validation_sub_list[-1], rf_result))\n",
    "    print (classification_report(validation_sub_list[-1], rf_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], rf_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"random forest has accuracy on testing\", accuracy_score(testing_label_total, rf_testing_result))\n",
    "    rf_testing_acc.append(float(format(accuracy_score(testing_label_total, rf_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on testing\", precision_score(testing_label_total, rf_testing_result))\n",
    "    print (\"random forest has recall on testing\", recall_score(testing_label_total, rf_testing_result))\n",
    "    print (classification_report(testing_label_total, rf_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, rf_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "end = time.clock()\n",
    "print ((end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.798, 0.809, 0.86, 0.859, 0.816, 0.806, 0.827, 0.834, 0.82]\n",
      "[0.41, 0.781, 0.357, 0.733, 0.458, 0.463, 0.214, 0.552, 0.602] "
     ]
    }
   ],
   "source": [
    "print (dt_val_acc, end = \"\\n\")\n",
    "print (dt_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815, 0.842, 0.871, 0.593, 0.854, 0.844, 0.86, 0.793, 0.822]\n",
      "[0.397, 0.553, 0.397, 0.572, 0.397, 0.397, 0.398, 0.603, 0.602] "
     ]
    }
   ],
   "source": [
    "print (log_val_acc, end = \"\\n\")\n",
    "print (log_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.408, 0.42, 0.423, 0.806, 0.702, 0.698, 0.811, 0.622, 0.633]\n",
      "[0.397, 0.398, 0.397, 0.603, 0.397, 0.397, 0.397, 0.335, 0.311] "
     ]
    }
   ],
   "source": [
    "print (nb_val_acc, end = \"\\n\")\n",
    "print (nb_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.816, 0.829, 0.87, 0.906, 0.852, 0.845, 0.859, 0.821, 0.85]\n",
      "[0.398, 0.397, 0.397, 0.397, 0.398, 0.398, 0.398, 0.857, 0.869] "
     ]
    }
   ],
   "source": [
    "print (svm_val_acc, end = \"\\n\")\n",
    "print (svm_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.835, 0.846, 0.888, 0.904, 0.865, 0.867, 0.86, 0.876, 0.885]\n",
      "[0.798, 0.801, 0.803, 0.799, 0.799, 0.799, 0.798, 0.801, 0.802] "
     ]
    }
   ],
   "source": [
    "print (rf_val_acc, end = \"\\n\")\n",
    "print (rf_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
