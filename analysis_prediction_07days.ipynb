{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statistics\n",
    "import math \n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/Desktop/analysis/code\n"
     ]
    }
   ],
   "source": [
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/wuyue/Desktop/analysis/stock/\"\n",
    "files = os.listdir(path)\n",
    "valid_file = []\n",
    "\n",
    "for file in files:\n",
    "    if file[-4:] == \".csv\":\n",
    "        valid_file.append(file)\n",
    "        \n",
    "print (len(valid_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the fuctions will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sign of a number\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    else:\n",
    "        return (0)\n",
    "    \n",
    "  \n",
    "def sgn_0(x):\n",
    "    if x > 0:\n",
    "        return (1)\n",
    "    if x == 0:\n",
    "        return (0)\n",
    "    if x < 0:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "# the number of pos and neg in a list determine the general trend\n",
    "def sgn_num(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += 1\n",
    "        if i <= 0:\n",
    "            ne += 1\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)    \n",
    "\n",
    "# the value of pos and neg sum determine the \n",
    "def sgn_total(x):\n",
    "    po = 0\n",
    "    ne = 0\n",
    "    for i in x:\n",
    "        if i > 0:\n",
    "            po += i\n",
    "        if i <= 0:\n",
    "            ne += abs(i)\n",
    "    if po > ne:\n",
    "        return (1)\n",
    "    if po <= ne:\n",
    "        return (-1)\n",
    "    \n",
    "    \n",
    "def sqrt_abs(x):\n",
    "    if x > 0:\n",
    "        return math.log(x, 10)\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -math.log(abs(x), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_split(l, m):\n",
    "    n = int(math.ceil(len(l)/float(m)))\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def chunks(l, n):\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "def mix(l):\n",
    "    res_sum = []\n",
    "    for i in range(0, len(l[0])):\n",
    "        res = []\n",
    "        for lst in l:\n",
    "            res.append(lst[i])\n",
    "        res_sum.append(res)\n",
    "    return res_sum\n",
    "\n",
    "def cut(l, n):\n",
    "    res = []\n",
    "    for i in range(0, n):\n",
    "        res.append(l[i::n])\n",
    "    return res\n",
    "\n",
    "def slic(l, n, m):\n",
    "    res = []\n",
    "    for i in range (1, n+1):\n",
    "        res.append(l[60*i+1:60*i+m+1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n",
      "31.1100217 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "training_data_total = []\n",
    "training_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_part = open_price[-700:]\n",
    "            open_price_list = open_price[-700:-100]\n",
    "            open_price_list_split = chunks(open_price_list, 60)\n",
    "            open_price_list_testing = open_price[-100:]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_part = high_price[-700:]\n",
    "            high_price_list = high_price[-700:-100]\n",
    "            high_price_list_split = chunks(high_price_list, 60)\n",
    "            high_price_list_testing = high_price[-100:]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_part = low_price[-700:]\n",
    "            low_price_list = low_price[-700:-100]\n",
    "            low_price_list_split = chunks(low_price_list, 60)\n",
    "            low_price_list_testing = low_price[-100:]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_part = close_price[-700:]\n",
    "            close_price_list = close_price[-700:-100]\n",
    "            close_price_list_split = chunks(close_price_list, 60)\n",
    "            close_price_list_testing = close_price[-100:]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_part = volume[-700:]\n",
    "            volume_list = volume[-700:-100]\n",
    "            volume_list_split = chunks(volume_list, 60)\n",
    "            volume_list_testing = volume[-100:]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_part = change[-700:]\n",
    "            change_list = change[-700:-100]\n",
    "            change_list_split = chunks(change_list, 60)\n",
    "            change_list_testing = change[-100:]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_part = typical_price[-700:]\n",
    "            typical_price_list = typical_price[-700:-100]\n",
    "            typical_price_list_split = chunks(typical_price_list, 60)\n",
    "            typical_price_list_testing = typical_price[-100:]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_part = middle_price[-700:]\n",
    "            middle_price_list = middle_price[-700:-100]\n",
    "            middle_price_list_split = chunks(middle_price_list, 60)\n",
    "            middle_price_list_testing = middle_price[-100:]\n",
    "    \n",
    "    training_list = [open_price_list_split, high_price_list_split, low_price_list_split, close_price_list_split, \\\n",
    "                    volume_list_split, change_list_split, typical_price_list_split, middle_price_list_split]\n",
    "\n",
    "    training_list_mixed = mix(training_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in training_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 49\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/51\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/26\n",
    "        EMA_25 = []\n",
    "        for i in range(26,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-24:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/cr_neg_sum)\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        training_data = stock_feature_list[:-1]\n",
    "        training_data_total.append(training_data)\n",
    "        \n",
    "        training_label = stock_feature_list[-1]\n",
    "        training_label_total.append(training_label)\n",
    "        \n",
    "\n",
    "print (len(training_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51150\n"
     ]
    }
   ],
   "source": [
    "transformer = RobustScaler().fit(training_data_total)\n",
    "data = transformer.transform(training_data_total)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the validation model 5 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:139: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46035\n",
      "22.49112288333333 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "validation_data_total = []\n",
    "validation_label_total = []\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list = open_price[-700:]\n",
    "            open_price_list_split_5 = slic(open_price_list, 9, 7)\n",
    "            \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list = high_price[-700:]\n",
    "            high_price_list_split_5 = slic(high_price_list, 9, 7)\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list = low_price[-700:]\n",
    "            low_price_list_split_5 = slic(low_price_list, 9, 7)\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list = close_price[-700:]\n",
    "            close_price_list_split_5 = slic(close_price_list, 9, 7)\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list = volume[-700:]\n",
    "            volume_list_split_5 = slic(volume_list, 9, 7)\n",
    "        \n",
    "            change.append(row[7])\n",
    "            change_list = change[-700:]\n",
    "            change_list_split_5 = slic(change_list, 9, 7)\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list = typical_price[-700:]\n",
    "            typical_price_list_split_5 = slic(typical_price_list, 9, 7)\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list = middle_price[-700:]\n",
    "            middle_price_list_split_5 = slic(middle_price_list, 9, 7)\n",
    "    \n",
    "    validation_list = [open_price_list_split_5, high_price_list_split_5, low_price_list_split_5, close_price_list_split_5, \\\n",
    "                    volume_list_split_5, change_list_split_5, typical_price_list_split_5, middle_price_list_split_5]\n",
    "\n",
    "    validation_list_mixed = mix(validation_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    for item in validation_list_mixed:\n",
    "    \n",
    "        pos_list = []\n",
    "        abs_list = []\n",
    "    \n",
    "        for flt in item[5]:\n",
    "            abs_list.append(abs(flt))\n",
    "            if flt > 0:\n",
    "                pos_list.append(flt)\n",
    "    \n",
    "        abs_sum = float('%.3f' % sum(abs_list))\n",
    "        pos_sum = float('%.3f' % sum(pos_list))\n",
    "        raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "        RSI = float('%.3f' % raw_rsi)\n",
    "        stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        indicator_list = [0.5] \n",
    "    \n",
    "        money_flow_list = [vol*tp for vol, tp in zip(item[4], item[6])]\n",
    "        total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "        for i in range(len(item[6])-1):\n",
    "            det = sgn(float('%.2f' % (item[6][i+1] - item[6][i])))\n",
    "            indicator_list.append(det)\n",
    "       \n",
    "        positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "        positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "        negative_money_flow = total_money_flow - positive_money_flow\n",
    "        money_rate = (positive_money_flow/(negative_money_flow+1))\n",
    "    \n",
    "        raw_mfi = 100-100/(1+money_rate)\n",
    "        MFI = float('%.3f' % raw_mfi)\n",
    "        stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "        if len(item[3]) >= 3:\n",
    "            raw_rsv = 100*(close_price_list[-1] - min(close_price_list))/(max(close_price_list) - min(close_price_list))\n",
    "        RSV = float('%.3f' % raw_rsv)\n",
    "        stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "        ax = item[3][-1] - item[3][-5]\n",
    "        bx = item[3][-5]\n",
    "        raw_roc = 100*ax/bx\n",
    "        ROC = float('%.3f' % raw_roc)\n",
    "        stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "        square_sum_5 = []\n",
    "        TP_5 = mean(item[6][-5:])\n",
    "        MA_5 = mean(item[3][-5:])\n",
    "        for i in item[3][-5:]:\n",
    "            square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "        raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "        CCI = float('%.3f' % raw_cci)\n",
    "        stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "        vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(item[3], item[1], item[2])))\n",
    "    \n",
    "        va = []\n",
    "        va_change_list = []\n",
    "        va.append(item[4][0])\n",
    "    \n",
    "        for i in range(0, len(item[4])-1):\n",
    "            va.append(va[i] + vol_para[i]*item[4][i+1])\n",
    "    \n",
    "        for i in range(0, len(va)-1):\n",
    "            va_change_list.append(va[i+1] - va[i])\n",
    "        va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "        if abs(va_change_rate) > 0.1:\n",
    "            VA = sgn(va_change_rate)\n",
    "        else:\n",
    "            VA = sgn_num(va_change_list)\n",
    "        stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        closing_change_list = []\n",
    "\n",
    "        for i in range(0, len(item[3])-1):\n",
    "            closing_change_list.append(item[3][i+1]-item[3][i])\n",
    "   \n",
    "        closing_price_list_pvt = item[3][1:]\n",
    "        volume_list_pvt = volume_list[1:]\n",
    "        pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "        raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "        PVT = float('%.3f' % raw_pvt)\n",
    "        stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        sign_closing_change_list = []\n",
    "        for i in closing_change_list:\n",
    "            sign_closing_change_list.append(sgn_0(i))\n",
    "        obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, item[4][1:])))\n",
    "        raw_obv = sqrt_abs(sum(obv_list))\n",
    "        OBV = float('%.3f' % raw_obv)\n",
    "        stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        exp_len = 4\n",
    "        exp_starting = len(item[3]) - exp_len\n",
    "        price_list_50 = [mean(item[3][:exp_starting])] + item[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "        const_50 = 2/6\n",
    "        EMA_50 = []\n",
    "        for i in range(1,len(price_list_50)):\n",
    "            raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "            ema_50 = float('%.3f' % raw_ema_50)\n",
    "            EMA_50.append(ema_50)\n",
    "    \n",
    "        const_25 = 2/3\n",
    "        EMA_25 = []\n",
    "        for i in range(3,len(price_list_50)):\n",
    "            raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "            ema_25 = float('%.3f' % raw_ema_25)\n",
    "            EMA_25.append(ema_25)\n",
    "        \n",
    "        EMA_50c = EMA_50[-2:]\n",
    "        EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "        EMA_mean = np.mean(EMA_diff)*100\n",
    "        EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "        stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "        stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "        stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        cr_pos = []\n",
    "        cr_neg = []\n",
    "    \n",
    "        middle_price_list_c = item[7][:-1]\n",
    "        closing_price_list_c = item[3][1:]\n",
    "        cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "        for i in cr_list:\n",
    "            if i > 0:\n",
    "                cr_pos.append(i)\n",
    "            else:\n",
    "                cr_neg.append(abs(i))\n",
    "    \n",
    "        cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "        cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "        raw_cr = 100*(cr_pos_sum/(1+cr_neg_sum))\n",
    "        CR = float('%.3f' % raw_cr)\n",
    "        stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "        square_sum = []\n",
    "        MA = mean(item[3])\n",
    "        MB = mean(item[3][:-1])\n",
    "    \n",
    "        for i in item[3]:\n",
    "            square_sum.append((i-MA)**2)\n",
    "        MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "        raw_UP = MB+2*MD\n",
    "        raw_DN = MB-2*MD\n",
    "        UP = float('%.3f' % raw_UP)\n",
    "        DN = float('%.3f' % raw_DN)\n",
    "        stock_feature_dict[\"UP\"] = UP\n",
    "        stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        if item[3][-1] > item[3][0]:\n",
    "            stock_feature_dict[\"change_c\"] = 1\n",
    "        else:\n",
    "            stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "        stock_feature_list = list(stock_feature_dict.values())\n",
    "        stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "        stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "        validation_data = stock_feature_list[:-1]\n",
    "        validation_data_total.append(validation_data)\n",
    "        \n",
    "        validation_label = stock_feature_list[-1]\n",
    "        validation_label_total.append(validation_label)\n",
    "        \n",
    "\n",
    "print (len(validation_data_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_v = RobustScaler().fit(validation_data_total)\n",
    "validation_data = transformer_v.transform(validation_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: 'U' mode is deprecated\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:135: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3.736557850000001 min\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "testing_data_total = []\n",
    "testing_label_total = []\n",
    "testing_list_total = []\n",
    "\n",
    "count_term=1\n",
    "\n",
    "for file in valid_file:\n",
    "    \n",
    "    open_price = []\n",
    "    high_price = []\n",
    "    low_price = []\n",
    "    close_price = []\n",
    "    volume = []\n",
    "    change = []\n",
    "    typical_price = []\n",
    "    middle_price = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = path + file\n",
    "    \n",
    "    \n",
    "    with open(file_name, \"rU\", encoding = \"ISO-8859-1\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        for row in reader:            \n",
    "            \n",
    "            diff = float(row[4]) - float(row[1])\n",
    "            tp = (float(row[2]) + float(row[3]) + float(row[4]))/3\n",
    "            mp = (float(row[2]) + float(row[3]))/2\n",
    "        \n",
    "            # tp = typical price, mp = middle price\n",
    "            \n",
    "            row.append(float('%.3f' % diff))\n",
    "            row.append(float('%.3f' % tp))\n",
    "            row.append(float('%.3f' % mp))\n",
    "        \n",
    "        \n",
    "            open_price.append(float(row[1]))\n",
    "            open_price_list_testing = open_price[-100:-93]\n",
    "        \n",
    "        \n",
    "            high_price.append(float(row[2]))\n",
    "            high_price_list_testing = high_price[-100:-93]\n",
    "            \n",
    "            low_price.append(float(row[3]))\n",
    "            low_price_list_testing = low_price[-100:-93]\n",
    "            \n",
    "            close_price.append(float(row[4]))\n",
    "            close_price_list_testing = close_price[-100:-93]\n",
    "            \n",
    "            volume.append(float(row[5]))\n",
    "            volume_list_testing = volume[-100:-93]\n",
    "            \n",
    "            change.append(row[7])\n",
    "            change_list_testing = change[-100:-93]\n",
    "            \n",
    "            typical_price.append(row[8])\n",
    "            typical_price_list_testing = typical_price[-100:-93]\n",
    "            \n",
    "            middle_price.append(row[9])\n",
    "            middle_price_list_testing = middle_price[-100:-93]\n",
    "    \n",
    "    testing_list = [open_price_list_testing, high_price_list_testing, low_price_list_testing, close_price_list_testing, \\\n",
    "                    volume_list_testing, change_list_testing, typical_price_list_testing, middle_price_list_testing]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    stock_feature_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    pos_list = []\n",
    "    abs_list = []\n",
    "    \n",
    "    for flt in testing_list[5]:\n",
    "        abs_list.append(abs(flt))\n",
    "        if flt > 0:\n",
    "            pos_list.append(flt)\n",
    "    \n",
    "    abs_sum = float('%.3f' % sum(abs_list))\n",
    "    pos_sum = float('%.3f' % sum(pos_list))\n",
    "    raw_rsi = (pos_sum/(1+abs_sum))*100\n",
    "    RSI = float('%.3f' % raw_rsi)\n",
    "    stock_feature_dict['RSI'] = RSI \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    indicator_list = [0.5] \n",
    "    \n",
    "    money_flow_list = [vol*tp for vol, tp in zip(testing_list[4], testing_list[6])]\n",
    "    total_money_flow = float('%.2f' % sum(money_flow_list))\n",
    "    \n",
    "    for i in range(len(testing_list[6])-1):\n",
    "        det = sgn(float('%.2f' % (testing_list[6][i+1] - testing_list[6][i])))\n",
    "        indicator_list.append(det)\n",
    "       \n",
    "    positive_money_flow_list = [ind*mf for ind, mf in zip(indicator_list, money_flow_list)]\n",
    "    positive_money_flow = float('%.2f' % sum(positive_money_flow_list))\n",
    "    negative_money_flow = total_money_flow - positive_money_flow\n",
    "    money_rate = (positive_money_flow/negative_money_flow)\n",
    "    \n",
    "    raw_mfi = 100-100/(1+money_rate)\n",
    "    MFI = float('%.3f' % raw_mfi)\n",
    "    stock_feature_dict['MFI'] = MFI   \n",
    "    \n",
    "    \n",
    "    if len(testing_list[3]) >= 3:\n",
    "        raw_rsv = 100*(close_price_list_testing[-1] - min(close_price_list_testing))/(max(close_price_list_testing) - min(close_price_list_testing))\n",
    "    RSV = float('%.3f' % raw_rsv)\n",
    "    stock_feature_dict['RSV'] = RSV\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax = testing_list[3][-1] - testing_list[3][-5]\n",
    "    bx = testing_list[3][-5]\n",
    "    raw_roc = 100*ax/bx\n",
    "    ROC = float('%.3f' % raw_roc)\n",
    "    stock_feature_dict['ROC'] = ROC\n",
    "    \n",
    "    \n",
    "    square_sum_5 = []\n",
    "    TP_5 = mean(testing_list[6][-5:])\n",
    "    MA_5 = mean(testing_list[3][-5:])\n",
    "    for i in testing_list[3][-5:]:\n",
    "        square_sum_5.append((i-MA_5)**2)\n",
    "        MD_5 = math.sqrt(mean(square_sum_5))\n",
    "    \n",
    "    raw_cci = (TP_5 - MA_5)/(MD_5*0.015)\n",
    "    CCI = float('%.3f' % raw_cci)\n",
    "    stock_feature_dict[\"CCI\"] = CCI\n",
    "    \n",
    "    \n",
    "    vol_para = list(map(lambda x: (2*x[0]-x[1]-x[2])/exp(x[1]-x[2]), zip(testing_list[3], testing_list[1], testing_list[2])))\n",
    "    \n",
    "    va = []\n",
    "    va_change_list = []\n",
    "    va.append(testing_list[4][0])\n",
    "    \n",
    "    for i in range(0, len(testing_list[4])-1):\n",
    "        va.append(va[i] + vol_para[i]*testing_list[4][i+1])\n",
    "    \n",
    "    for i in range(0, len(va)-1):\n",
    "        va_change_list.append(va[i+1] - va[i])\n",
    "    va_change_rate = (va[-1] - va[0])/va[0]\n",
    "    \n",
    "    if abs(va_change_rate) > 0.1:\n",
    "        VA = sgn(va_change_rate)\n",
    "    else:\n",
    "        VA = sgn_num(va_change_list)\n",
    "    stock_feature_dict[\"VA\"] = VA\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    closing_change_list = []\n",
    "\n",
    "    for i in range(0, len(testing_list[3])-1):\n",
    "        closing_change_list.append(testing_list[3][i+1]-testing_list[3][i])\n",
    "   \n",
    "    closing_price_list_pvt = testing_list[3][1:]\n",
    "    volume_list_pvt = volume_list_testing[1:]\n",
    "    pvt_list = list(map(lambda x: x[0]*x[1]/x[2], zip(closing_change_list, volume_list_pvt, closing_price_list_pvt)))\n",
    "    raw_pvt = sqrt_abs(sum(pvt_list))\n",
    "    PVT = float('%.3f' % raw_pvt)\n",
    "    stock_feature_dict[\"PVT\"] = PVT\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sign_closing_change_list = []\n",
    "    for i in closing_change_list:\n",
    "        sign_closing_change_list.append(sgn_0(i))\n",
    "    obv_list = list(map(lambda x: x[0]*x[1], zip(sign_closing_change_list, testing_list[4][1:])))\n",
    "    raw_obv = sqrt_abs(sum(obv_list))\n",
    "    OBV = float('%.3f' % raw_obv)\n",
    "    stock_feature_dict[\"OBV\"] = OBV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exp_len = 49\n",
    "    exp_starting = len(testing_list[3]) - exp_len\n",
    "    price_list_50 = [mean(testing_list[3][:exp_starting])] + testing_list[3][-exp_len:]\n",
    "    \n",
    "    \n",
    "    const_50 = 2/51\n",
    "    EMA_50 = []\n",
    "    for i in range(1,len(price_list_50)):\n",
    "        raw_ema_50 = const_50*price_list_50[i-1] + (1-const_50)*price_list_50[i]\n",
    "        ema_50 = float('%.3f' % raw_ema_50)\n",
    "        EMA_50.append(ema_50)\n",
    "    \n",
    "    const_25 = 2/26\n",
    "    EMA_25 = []\n",
    "    for i in range(26,len(price_list_50)):\n",
    "        raw_ema_25 = const_25*price_list_50[i-1] + (1-const_25)*price_list_50[i]\n",
    "        ema_25 = float('%.3f' % raw_ema_25)\n",
    "        EMA_25.append(ema_25)\n",
    "        \n",
    "    EMA_50c = EMA_50[-24:]\n",
    "    EMA_diff = list(map(lambda x: x[0]-x[1], zip(EMA_50c, EMA_25)))\n",
    "    EMA_mean = np.mean(EMA_diff)*100\n",
    "    EMA_diff_mean = float('%.5f' % np.mean(EMA_mean))\n",
    "    stock_feature_dict['EMA_DIFF'] = EMA_diff_mean\n",
    "    stock_feature_dict['EMA_TREND'] = sgn_num(EMA_diff)\n",
    "    stock_feature_dict['EMA_OVERALL'] = sgn_total(EMA_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cr_pos = []\n",
    "    cr_neg = []\n",
    "    \n",
    "    middle_price_list_c = testing_list[7][:-1]\n",
    "    closing_price_list_c = testing_list[3][1:]\n",
    "    cr_list = list(map(lambda x: x[0]-x[1], zip(middle_price_list_c, closing_price_list_c)))\n",
    "    for i in cr_list:\n",
    "        if i > 0:\n",
    "            cr_pos.append(i)\n",
    "        else:\n",
    "            cr_neg.append(abs(i))\n",
    "    \n",
    "    cr_pos_sum = float('%.3f' % sum(cr_pos))\n",
    "    cr_neg_sum = float('%.3f' % sum(cr_neg))\n",
    "    raw_cr = 100*(cr_pos_sum/(cr_neg_sum+1))\n",
    "    CR = float('%.3f' % raw_cr)\n",
    "    stock_feature_dict[\"CR\"] = CR\n",
    "    \n",
    "    \n",
    "    \n",
    "    square_sum = []\n",
    "    MA = mean(testing_list[3])\n",
    "    MB = mean(testing_list[3][:-1])\n",
    "    \n",
    "    for i in testing_list[3]:\n",
    "        square_sum.append((i-MA)**2)\n",
    "    MD = math.sqrt(mean(square_sum))\n",
    "    \n",
    "    raw_UP = MB+2*MD\n",
    "    raw_DN = MB-2*MD\n",
    "    UP = float('%.3f' % raw_UP)\n",
    "    DN = float('%.3f' % raw_DN)\n",
    "    stock_feature_dict[\"UP\"] = UP\n",
    "    stock_feature_dict[\"DN\"] = DN\n",
    "        \n",
    "        \n",
    "        \n",
    "    if testing_list[3][-1] > testing_list[3][0]:\n",
    "        stock_feature_dict[\"change_c\"] = 1\n",
    "    else:\n",
    "        stock_feature_dict[\"change_c\"] = -1\n",
    "            \n",
    "            \n",
    "    stock_feature_list = list(stock_feature_dict.values())\n",
    "    stock_feature_list = [-100 if math.isnan(x) else x for x in stock_feature_list]\n",
    "    stock_feature_list = [100 if math.isinf(x) else x for x in stock_feature_list]\n",
    "        \n",
    "        \n",
    "    testing_data = stock_feature_list[:-1]\n",
    "    testing_data_total.append(testing_data)\n",
    "        \n",
    "    testing_label = stock_feature_list[-1]\n",
    "    testing_label_total.append(testing_label)\n",
    "\n",
    "    \n",
    "    \n",
    "print (len(testing_list_total))\n",
    "\n",
    "\n",
    "end = time.clock()\n",
    "print ((end-start)/60, \"min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_testing = RobustScaler().fit(testing_data_total)\n",
    "data_testing = transformer_testing.transform(testing_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree has accuracy on validation 0.7558162267839688\n",
      "decision tree has precision on validation 0.6785553047404064\n",
      "decision tree has recall on validation 0.736764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.77      0.79      3075\n",
      "           1       0.68      0.74      0.71      2040\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.75      0.75      0.75      5115\n",
      "weighted avg       0.76      0.76      0.76      5115\n",
      "\n",
      "[[2363  712]\n",
      " [ 537 1503]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7642228739002933\n",
      "decision tree has precision on testing 0.8733333333333333\n",
      "decision tree has recall on testing 0.6991327551701134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.86      0.75      2117\n",
      "           1       0.87      0.70      0.78      2998\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.77      0.78      0.76      5115\n",
      "weighted avg       0.79      0.76      0.77      5115\n",
      "\n",
      "[[1813  304]\n",
      " [ 902 2096]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7726295210166177\n",
      "log reg has precision on validation 0.6803784450843274\n",
      "log reg has recall on validation 0.8107843137254902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.75      0.80      3075\n",
      "           1       0.68      0.81      0.74      2040\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.78      0.77      5115\n",
      "weighted avg       0.79      0.77      0.77      5115\n",
      "\n",
      "[[2298  777]\n",
      " [ 386 1654]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6222873900293255\n",
      "log reg has precision on testing 0.9509306260575296\n",
      "log reg has recall on testing 0.3749166110740494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.97      0.68      2117\n",
      "           1       0.95      0.37      0.54      2998\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      5115\n",
      "   macro avg       0.74      0.67      0.61      5115\n",
      "weighted avg       0.77      0.62      0.60      5115\n",
      "\n",
      "[[2059   58]\n",
      " [1874 1124]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.45083088954056694\n",
      "naive bayes has precision on validation 0.42040985303249845\n",
      "naive bayes has recall on validation 0.9955882352941177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.09      0.16      3075\n",
      "           1       0.42      1.00      0.59      2040\n",
      "\n",
      "   micro avg       0.45      0.45      0.45      5115\n",
      "   macro avg       0.69      0.54      0.38      5115\n",
      "weighted avg       0.75      0.45      0.33      5115\n",
      "\n",
      "[[ 275 2800]\n",
      " [   9 2031]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.4142717497556207\n",
      "naive bayes has precision on testing 0.75\n",
      "naive bayes has recall on testing 0.0010006671114076052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      1.00      0.59      2117\n",
      "           1       0.75      0.00      0.00      2998\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.58      0.50      0.29      5115\n",
      "weighted avg       0.61      0.41      0.24      5115\n",
      "\n",
      "[[2116    1]\n",
      " [2995    3]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7736070381231671\n",
      "svm has precision on validation 0.6813322368421053\n",
      "svm has recall on validation 0.8122549019607843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.75      0.80      3075\n",
      "           1       0.68      0.81      0.74      2040\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.77      0.78      0.77      5115\n",
      "weighted avg       0.79      0.77      0.78      5115\n",
      "\n",
      "[[2300  775]\n",
      " [ 383 1657]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6250244379276637\n",
      "svm has precision on testing 0.9515050167224081\n",
      "svm has recall on testing 0.37958639092728486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.97      0.68      2117\n",
      "           1       0.95      0.38      0.54      2998\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.74      0.68      0.61      5115\n",
      "weighted avg       0.78      0.63      0.60      5115\n",
      "\n",
      "[[2059   58]\n",
      " [1860 1138]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.7843597262952101\n",
      "random forest has precision on validation 0.6760616309658023\n",
      "random forest has recall on validation 0.8818627450980392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.72      0.80      3075\n",
      "           1       0.68      0.88      0.77      2040\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.79      0.80      0.78      5115\n",
      "weighted avg       0.81      0.78      0.79      5115\n",
      "\n",
      "[[2213  862]\n",
      " [ 241 1799]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8109481915933529\n",
      "random forest has precision on testing 0.8865626189569852\n",
      "random forest has recall on testing 0.776851234156104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 669 2329]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7933528836754643\n",
      "decision tree has precision on validation 0.7448275862068966\n",
      "decision tree has recall on validation 0.8109540636042403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.78      0.81      2851\n",
      "           1       0.74      0.81      0.78      2264\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.80      0.79      5115\n",
      "weighted avg       0.80      0.79      0.79      5115\n",
      "\n",
      "[[2222  629]\n",
      " [ 428 1836]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.8115347018572825\n",
      "decision tree has precision on testing 0.8866920152091254\n",
      "decision tree has recall on testing 0.7778519012675117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 666 2332]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8619745845552297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has precision on validation 0.7883049592894152\n",
      "log reg has recall on validation 0.9408127208480566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.80      0.87      2851\n",
      "           1       0.79      0.94      0.86      2264\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.87      0.87      0.86      5115\n",
      "weighted avg       0.88      0.86      0.86      5115\n",
      "\n",
      "[[2279  572]\n",
      " [ 134 2130]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.838514173998045\n",
      "log reg has precision on testing 0.8347718865598027\n",
      "log reg has recall on testing 0.9032688458972649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.75      0.79      2117\n",
      "           1       0.83      0.90      0.87      2998\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.84      0.83      0.83      5115\n",
      "weighted avg       0.84      0.84      0.84      5115\n",
      "\n",
      "[[1581  536]\n",
      " [ 290 2708]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.55386119257087\n",
      "naive bayes has precision on validation 0.498016747465844\n",
      "naive bayes has recall on validation 0.9982332155477032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.20      0.33      2851\n",
      "           1       0.50      1.00      0.66      2264\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      5115\n",
      "   macro avg       0.75      0.60      0.50      5115\n",
      "weighted avg       0.77      0.55      0.48      5115\n",
      "\n",
      "[[ 573 2278]\n",
      " [   4 2260]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.41524926686217006\n",
      "naive bayes has precision on testing 0.524822695035461\n",
      "naive bayes has recall on testing 0.024683122081387593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.97      0.58      2117\n",
      "           1       0.52      0.02      0.05      2998\n",
      "\n",
      "   micro avg       0.42      0.42      0.42      5115\n",
      "   macro avg       0.47      0.50      0.31      5115\n",
      "weighted avg       0.48      0.42      0.27      5115\n",
      "\n",
      "[[2050   67]\n",
      " [2924   74]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7982404692082111\n",
      "svm has precision on validation 0.722704266088214\n",
      "svm has recall on validation 0.8829505300353356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.73      0.80      2851\n",
      "           1       0.72      0.88      0.79      2264\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.80      0.81      0.80      5115\n",
      "weighted avg       0.81      0.80      0.80      5115\n",
      "\n",
      "[[2084  767]\n",
      " [ 265 1999]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.5964809384164222\n",
      "svm has precision on testing 0.9447619047619048\n",
      "svm has recall on testing 0.33088725817211473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.97      0.67      2117\n",
      "           1       0.94      0.33      0.49      2998\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.73      0.65      0.58      5115\n",
      "weighted avg       0.76      0.60      0.56      5115\n",
      "\n",
      "[[2059   58]\n",
      " [2006  992]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8197458455522971\n",
      "random forest has precision on validation 0.7346153846153847\n",
      "random forest has recall on validation 0.9280035335689046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.73      0.82      2851\n",
      "           1       0.73      0.93      0.82      2264\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.83      0.83      0.82      5115\n",
      "weighted avg       0.84      0.82      0.82      5115\n",
      "\n",
      "[[2092  759]\n",
      " [ 163 2101]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8109481915933529\n",
      "random forest has precision on testing 0.8865626189569852\n",
      "random forest has recall on testing 0.776851234156104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 669 2329]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7554252199413489\n",
      "decision tree has precision on validation 0.7429854096520763\n",
      "decision tree has recall on validation 0.7788235294117647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.73      0.75      2565\n",
      "           1       0.74      0.78      0.76      2550\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5115\n",
      "   macro avg       0.76      0.76      0.76      5115\n",
      "weighted avg       0.76      0.76      0.76      5115\n",
      "\n",
      "[[1878  687]\n",
      " [ 564 1986]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7116324535679375\n",
      "decision tree has precision on testing 0.7724508050089446\n",
      "decision tree has recall on testing 0.7201467645096731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.70      0.67      2117\n",
      "           1       0.77      0.72      0.75      2998\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5115\n",
      "   macro avg       0.71      0.71      0.71      5115\n",
      "weighted avg       0.72      0.71      0.71      5115\n",
      "\n",
      "[[1481  636]\n",
      " [ 839 2159]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7820136852394917\n",
      "log reg has precision on validation 0.7439646378782727\n",
      "log reg has recall on validation 0.8580392156862745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.71      0.76      2565\n",
      "           1       0.74      0.86      0.80      2550\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.79      0.78      0.78      5115\n",
      "weighted avg       0.79      0.78      0.78      5115\n",
      "\n",
      "[[1812  753]\n",
      " [ 362 2188]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.644574780058651\n",
      "log reg has precision on testing 0.9344624447717231\n",
      "log reg has recall on testing 0.42328218812541696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.96      0.69      2117\n",
      "           1       0.93      0.42      0.58      2998\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.74      0.69      0.64      5115\n",
      "weighted avg       0.77      0.64      0.63      5115\n",
      "\n",
      "[[2028   89]\n",
      " [1729 1269]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5869012707722385\n",
      "naive bayes has precision on validation 0.5469589512142704\n",
      "naive bayes has recall on validation 0.9980392156862745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.18      0.30      2565\n",
      "           1       0.55      1.00      0.71      2550\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.77      0.59      0.50      5115\n",
      "weighted avg       0.77      0.59      0.50      5115\n",
      "\n",
      "[[ 457 2108]\n",
      " [   5 2545]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.41036168132942324\n",
      "naive bayes has precision on testing 0.36764705882352944\n",
      "naive bayes has recall on testing 0.008338892595063376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.98      0.58      2117\n",
      "           1       0.37      0.01      0.02      2998\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.39      0.49      0.30      5115\n",
      "weighted avg       0.39      0.41      0.25      5115\n",
      "\n",
      "[[2074   43]\n",
      " [2973   25]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.7800586510263929\n",
      "svm has precision on validation 0.7444253859348199\n",
      "svm has recall on validation 0.8509803921568627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.71      0.76      2565\n",
      "           1       0.74      0.85      0.79      2550\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.79      0.78      0.78      5115\n",
      "weighted avg       0.79      0.78      0.78      5115\n",
      "\n",
      "[[1820  745]\n",
      " [ 380 2170]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6287390029325514\n",
      "svm has precision on testing 0.9364575059571089\n",
      "svm has recall on testing 0.3932621747831888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.96      0.68      2117\n",
      "           1       0.94      0.39      0.55      2998\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      5115\n",
      "   macro avg       0.73      0.68      0.62      5115\n",
      "weighted avg       0.77      0.63      0.61      5115\n",
      "\n",
      "[[2037   80]\n",
      " [1819 1179]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8023460410557185\n",
      "random forest has precision on validation 0.7451417648932781\n",
      "random forest has recall on validation 0.9172549019607843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.69      0.78      2565\n",
      "           1       0.75      0.92      0.82      2550\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.82      0.80      0.80      5115\n",
      "weighted avg       0.82      0.80      0.80      5115\n",
      "\n",
      "[[1765  800]\n",
      " [ 211 2339]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.810752688172043\n",
      "random forest has precision on testing 0.8868140243902439\n",
      "random forest has recall on testing 0.776184122748499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1820  297]\n",
      " [ 671 2327]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7816226783968719\n",
      "decision tree has precision on validation 0.8803535010197144\n",
      "decision tree has recall on validation 0.7719821162444114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.80      0.72      1760\n",
      "           1       0.88      0.77      0.82      3355\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.76      0.79      0.77      5115\n",
      "weighted avg       0.80      0.78      0.79      5115\n",
      "\n",
      "[[1408  352]\n",
      " [ 765 2590]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.4258064516129032\n",
      "decision tree has precision on testing 0.9178082191780822\n",
      "decision tree has recall on testing 0.022348232154769845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      1.00      0.59      2117\n",
      "           1       0.92      0.02      0.04      2998\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      5115\n",
      "   macro avg       0.67      0.51      0.32      5115\n",
      "weighted avg       0.71      0.43      0.27      5115\n",
      "\n",
      "[[2111    6]\n",
      " [2931   67]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.6598240469208211\n",
      "log reg has precision on validation 0.8491137051448335\n",
      "log reg has recall on validation 0.5853949329359165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.80      0.62      1760\n",
      "           1       0.85      0.59      0.69      3355\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5115\n",
      "   macro avg       0.68      0.69      0.66      5115\n",
      "weighted avg       0.73      0.66      0.67      5115\n",
      "\n",
      "[[1411  349]\n",
      " [1391 1964]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6737047898338221\n",
      "log reg has precision on testing 0.8174868609651218\n",
      "log reg has recall on testing 0.5707138092061375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.82      0.68      2117\n",
      "           1       0.82      0.57      0.67      2998\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      5115\n",
      "   macro avg       0.70      0.70      0.67      5115\n",
      "weighted avg       0.72      0.67      0.67      5115\n",
      "\n",
      "[[1735  382]\n",
      " [1287 1711]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6559139784946236\n",
      "naive bayes has precision on validation 0.6559139784946236\n",
      "naive bayes has recall on validation 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1760\n",
      "           1       0.66      1.00      0.79      3355\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5115\n",
      "   macro avg       0.33      0.50      0.40      5115\n",
      "weighted avg       0.43      0.66      0.52      5115\n",
      "\n",
      "[[   0 1760]\n",
      " [   0 3355]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.586119257086999\n",
      "naive bayes has precision on testing 0.586119257086999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive bayes has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      2117\n",
      "           1       0.59      1.00      0.74      2998\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.29      0.50      0.37      5115\n",
      "weighted avg       0.34      0.59      0.43      5115\n",
      "\n",
      "[[   0 2117]\n",
      " [   0 2998]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8535679374389051\n",
      "svm has precision on validation 0.8809941520467837\n",
      "svm has recall on validation 0.8980625931445604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.77      0.78      1760\n",
      "           1       0.88      0.90      0.89      3355\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.84      0.83      0.84      5115\n",
      "weighted avg       0.85      0.85      0.85      5115\n",
      "\n",
      "[[1353  407]\n",
      " [ 342 3013]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6111436950146627\n",
      "svm has precision on testing 0.9500446030330062\n",
      "svm has recall on testing 0.3552368245496998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.97      0.67      2117\n",
      "           1       0.95      0.36      0.52      2998\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      5115\n",
      "   macro avg       0.73      0.66      0.60      5115\n",
      "weighted avg       0.77      0.61      0.58      5115\n",
      "\n",
      "[[2061   56]\n",
      " [1933 1065]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8701857282502444\n",
      "random forest has precision on validation 0.8691358024691358\n",
      "random forest has recall on validation 0.9442622950819672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.73      0.79      1760\n",
      "           1       0.87      0.94      0.91      3355\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.84      0.85      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1283  477]\n",
      " [ 187 3168]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.810752688172043\n",
      "random forest has precision on testing 0.8871090770404272\n",
      "random forest has recall on testing 0.7758505670446965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1821  296]\n",
      " [ 672 2326]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7943304007820137\n",
      "decision tree has precision on validation 0.8142267386471895\n",
      "decision tree has recall on validation 0.8459254371494557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.72      0.74      2084\n",
      "           1       0.81      0.85      0.83      3031\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      5115\n",
      "   macro avg       0.79      0.78      0.79      5115\n",
      "weighted avg       0.79      0.79      0.79      5115\n",
      "\n",
      "[[1499  585]\n",
      " [ 467 2564]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.7425219941348974\n",
      "decision tree has precision on testing 0.7765712405396512\n",
      "decision tree has recall on testing 0.7871914609739826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.68      0.69      2117\n",
      "           1       0.78      0.79      0.78      2998\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      5115\n",
      "   macro avg       0.73      0.73      0.73      5115\n",
      "weighted avg       0.74      0.74      0.74      5115\n",
      "\n",
      "[[1438  679]\n",
      " [ 638 2360]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8281524926686217\n",
      "log reg has precision on validation 0.8083094555873925\n",
      "log reg has recall on validation 0.930715935334873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.68      0.76      2084\n",
      "           1       0.81      0.93      0.87      3031\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.80      0.81      5115\n",
      "weighted avg       0.83      0.83      0.82      5115\n",
      "\n",
      "[[1415  669]\n",
      " [ 210 2821]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6404692082111437\n",
      "log reg has precision on testing 0.9454265949269792\n",
      "log reg has recall on testing 0.41027351567711806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.97      0.69      2117\n",
      "           1       0.95      0.41      0.57      2998\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.74      0.69      0.63      5115\n",
      "weighted avg       0.78      0.64      0.62      5115\n",
      "\n",
      "[[2046   71]\n",
      " [1768 1230]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6823069403714564\n",
      "naive bayes has precision on validation 0.6517702936096719\n",
      "naive bayes has recall on validation 0.9960409105905642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.23      0.37      2084\n",
      "           1       0.65      1.00      0.79      3031\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      5115\n",
      "   macro avg       0.81      0.61      0.58      5115\n",
      "weighted avg       0.78      0.68      0.62      5115\n",
      "\n",
      "[[ 471 1613]\n",
      " [  12 3019]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.4109481915933529\n",
      "naive bayes has precision on testing 0.42718446601941745\n",
      "naive bayes has recall on testing 0.01467645096731154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.97      0.58      2117\n",
      "           1       0.43      0.01      0.03      2998\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.42      0.49      0.30      5115\n",
      "weighted avg       0.42      0.41      0.26      5115\n",
      "\n",
      "[[2058   59]\n",
      " [2954   44]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8301075268817204\n",
      "svm has precision on validation 0.8076266363118952\n",
      "svm has recall on validation 0.9363246453315738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.68      0.76      2084\n",
      "           1       0.81      0.94      0.87      3031\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.81      0.82      5115\n",
      "weighted avg       0.84      0.83      0.83      5115\n",
      "\n",
      "[[1408  676]\n",
      " [ 193 2838]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.635386119257087\n",
      "svm has precision on testing 0.9443137254901961\n",
      "svm has recall on testing 0.4016010673782522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.97      0.69      2117\n",
      "           1       0.94      0.40      0.56      2998\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.74      0.68      0.63      5115\n",
      "weighted avg       0.77      0.64      0.61      5115\n",
      "\n",
      "[[2046   71]\n",
      " [1794 1204]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8346041055718475\n",
      "random forest has precision on validation 0.7990692581439912\n",
      "random forest has recall on validation 0.9630484988452656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.65      0.76      2084\n",
      "           1       0.80      0.96      0.87      3031\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.86      0.81      0.82      5115\n",
      "weighted avg       0.85      0.83      0.83      5115\n",
      "\n",
      "[[1350  734]\n",
      " [ 112 2919]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8105571847507331\n",
      "random forest has precision on testing 0.8864761904761905\n",
      "random forest has recall on testing 0.776184122748499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 671 2327]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7818181818181819\n",
      "decision tree has precision on validation 0.7847244601998067\n",
      "decision tree has recall on validation 0.8446063128685397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.70      0.74      2232\n",
      "           1       0.78      0.84      0.81      2883\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.78      0.77      0.78      5115\n",
      "weighted avg       0.78      0.78      0.78      5115\n",
      "\n",
      "[[1564  668]\n",
      " [ 448 2435]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.5890518084066472\n",
      "decision tree has precision on testing 0.6008554705087799\n",
      "decision tree has recall on testing 0.890260173448966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.16      0.25      2117\n",
      "           1       0.60      0.89      0.72      2998\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      5115\n",
      "   macro avg       0.56      0.53      0.48      5115\n",
      "weighted avg       0.56      0.59      0.52      5115\n",
      "\n",
      "[[ 344 1773]\n",
      " [ 329 2669]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.8043010752688172\n",
      "log reg has precision on validation 0.7770906949352179\n",
      "log reg has recall on validation 0.9153659382587582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.66      0.75      2232\n",
      "           1       0.78      0.92      0.84      2883\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.82      0.79      0.79      5115\n",
      "weighted avg       0.81      0.80      0.80      5115\n",
      "\n",
      "[[1475  757]\n",
      " [ 244 2639]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6496578690127077\n",
      "log reg has precision on testing 0.9440353460972017\n",
      "log reg has recall on testing 0.4276184122748499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.96      0.69      2117\n",
      "           1       0.94      0.43      0.59      2998\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.74      0.70      0.64      5115\n",
      "weighted avg       0.78      0.65      0.63      5115\n",
      "\n",
      "[[2041   76]\n",
      " [1716 1282]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6858260019550342\n",
      "naive bayes has precision on validation 0.6427931960608774\n",
      "naive bayes has recall on validation 0.9961845300034686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.28      0.44      2232\n",
      "           1       0.64      1.00      0.78      2883\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      5115\n",
      "   macro avg       0.81      0.64      0.61      5115\n",
      "weighted avg       0.79      0.69      0.63      5115\n",
      "\n",
      "[[ 636 1596]\n",
      " [  11 2872]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.413880742913001\n",
      "naive bayes has precision on testing 0.5\n",
      "naive bayes has recall on testing 0.0020013342228152103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      1.00      0.58      2117\n",
      "           1       0.50      0.00      0.00      2998\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.46      0.50      0.29      5115\n",
      "weighted avg       0.46      0.41      0.24      5115\n",
      "\n",
      "[[2111    6]\n",
      " [2992    6]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8084066471163245\n",
      "svm has precision on validation 0.7814256137237504\n",
      "svm has recall on validation 0.916406520985085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.67      0.75      2232\n",
      "           1       0.78      0.92      0.84      2883\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.82      0.79      0.80      5115\n",
      "weighted avg       0.82      0.81      0.80      5115\n",
      "\n",
      "[[1493  739]\n",
      " [ 241 2642]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.6478983382209189\n",
      "svm has precision on testing 0.9530658591975776\n",
      "svm has recall on testing 0.4199466310873916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.97      0.70      2117\n",
      "           1       0.95      0.42      0.58      2998\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5115\n",
      "   macro avg       0.75      0.70      0.64      5115\n",
      "weighted avg       0.78      0.65      0.63      5115\n",
      "\n",
      "[[2055   62]\n",
      " [1739 1259]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8207233626588465\n",
      "random forest has precision on validation 0.785092807424594\n",
      "random forest has recall on validation 0.9389524800554977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.67      0.76      2232\n",
      "           1       0.79      0.94      0.86      2883\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.84      0.80      0.81      5115\n",
      "weighted avg       0.83      0.82      0.82      5115\n",
      "\n",
      "[[1491  741]\n",
      " [ 176 2707]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8109481915933529\n",
      "random forest has precision on testing 0.8865626189569852\n",
      "random forest has recall on testing 0.776851234156104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 669 2329]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.776930596285435\n",
      "decision tree has precision on validation 0.563710499490316\n",
      "decision tree has recall on validation 0.7951114306254493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.91      0.77      0.83      3724\n",
      "           1       0.56      0.80      0.66      1391\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      5115\n",
      "   macro avg       0.74      0.78      0.75      5115\n",
      "weighted avg       0.82      0.78      0.79      5115\n",
      "\n",
      "[[2868  856]\n",
      " [ 285 1106]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.18553274682306942\n",
      "decision tree has precision on testing 0.2465277777777778\n",
      "decision tree has recall on testing 0.1894596397598399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.14      0.18      0.15      2117\n",
      "           1       0.25      0.19      0.21      2998\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      5115\n",
      "   macro avg       0.19      0.18      0.18      5115\n",
      "weighted avg       0.20      0.19      0.19      5115\n",
      "\n",
      "[[ 381 1736]\n",
      " [2430  568]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.7992179863147605\n",
      "log reg has precision on validation 0.5897435897435898\n",
      "log reg has recall on validation 0.8598130841121495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.78      0.85      3724\n",
      "           1       0.59      0.86      0.70      1391\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.76      0.82      0.77      5115\n",
      "weighted avg       0.84      0.80      0.81      5115\n",
      "\n",
      "[[2892  832]\n",
      " [ 195 1196]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6604105571847507\n",
      "log reg has precision on testing 0.9315537303216974\n",
      "log reg has recall on testing 0.45396931287525016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.95      0.70      2117\n",
      "           1       0.93      0.45      0.61      2998\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5115\n",
      "   macro avg       0.74      0.70      0.65      5115\n",
      "weighted avg       0.77      0.66      0.65      5115\n",
      "\n",
      "[[2017  100]\n",
      " [1637 1361]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.7382209188660802\n",
      "naive bayes has precision on validation 0.5097087378640777\n",
      "naive bayes has recall on validation 0.9813084112149533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.65      0.78      3724\n",
      "           1       0.51      0.98      0.67      1391\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      5115\n",
      "   macro avg       0.75      0.81      0.73      5115\n",
      "weighted avg       0.86      0.74      0.75      5115\n",
      "\n",
      "[[2411 1313]\n",
      " [  26 1365]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.41407624633431084\n",
      "naive bayes has precision on testing 1.0\n",
      "naive bayes has recall on testing 0.000333555703802535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      1.00      0.59      2117\n",
      "           1       1.00      0.00      0.00      2998\n",
      "\n",
      "   micro avg       0.41      0.41      0.41      5115\n",
      "   macro avg       0.71      0.50      0.29      5115\n",
      "weighted avg       0.76      0.41      0.24      5115\n",
      "\n",
      "[[2117    0]\n",
      " [2997    1]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8007820136852395\n",
      "svm has precision on validation 0.592079207920792\n",
      "svm has recall on validation 0.8598130841121495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.78      0.85      3724\n",
      "           1       0.59      0.86      0.70      1391\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.76      0.82      0.78      5115\n",
      "weighted avg       0.84      0.80      0.81      5115\n",
      "\n",
      "[[2900  824]\n",
      " [ 195 1196]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.636950146627566\n",
      "svm has precision on testing 0.9453551912568307\n",
      "svm has recall on testing 0.4039359573048699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.97      0.69      2117\n",
      "           1       0.95      0.40      0.57      2998\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      5115\n",
      "   macro avg       0.74      0.69      0.63      5115\n",
      "weighted avg       0.78      0.64      0.62      5115\n",
      "\n",
      "[[2047   70]\n",
      " [1787 1211]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8189638318670577\n",
      "random forest has precision on validation 0.6096181046676096\n",
      "random forest has recall on validation 0.9295470884255931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.78      0.86      3724\n",
      "           1       0.61      0.93      0.74      1391\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      5115\n",
      "   macro avg       0.79      0.85      0.80      5115\n",
      "weighted avg       0.87      0.82      0.83      5115\n",
      "\n",
      "[[2896  828]\n",
      " [  98 1293]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8109481915933529\n",
      "random forest has precision on testing 0.8865626189569852\n",
      "random forest has recall on testing 0.776851234156104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1819  298]\n",
      " [ 669 2329]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.8043010752688172\n",
      "decision tree has precision on validation 0.8691733996270976\n",
      "decision tree has recall on validation 0.8282499259697956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.76      0.72      1738\n",
      "           1       0.87      0.83      0.85      3377\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      5115\n",
      "   macro avg       0.78      0.79      0.79      5115\n",
      "weighted avg       0.81      0.80      0.81      5115\n",
      "\n",
      "[[1317  421]\n",
      " [ 580 2797]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.4635386119257087\n",
      "decision tree has precision on testing 0.9884615384615385\n",
      "decision tree has recall on testing 0.0857238158772515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.44      1.00      0.61      2117\n",
      "           1       0.99      0.09      0.16      2998\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      5115\n",
      "   macro avg       0.71      0.54      0.38      5115\n",
      "weighted avg       0.76      0.46      0.34      5115\n",
      "\n",
      "[[2114    3]\n",
      " [2741  257]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log reg has accuracy on validation 0.8713587487781036\n",
      "log reg has precision on validation 0.8826343934703068\n",
      "log reg has recall on validation 0.9286348830322771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.76      0.80      1738\n",
      "           1       0.88      0.93      0.91      3377\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.86      0.84      0.85      5115\n",
      "weighted avg       0.87      0.87      0.87      5115\n",
      "\n",
      "[[1321  417]\n",
      " [ 241 3136]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.6054740957966764\n",
      "log reg has precision on testing 0.5976874003189793\n",
      "log reg has recall on testing 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.05      0.09      2117\n",
      "           1       0.60      1.00      0.75      2998\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      5115\n",
      "   macro avg       0.80      0.52      0.42      5115\n",
      "weighted avg       0.76      0.61      0.48      5115\n",
      "\n",
      "[[  99 2018]\n",
      " [   0 2998]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.6604105571847507\n",
      "naive bayes has precision on validation 0.6624405705229794\n",
      "naive bayes has recall on validation 0.990228013029316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.51      0.02      0.04      1738\n",
      "           1       0.66      0.99      0.79      3377\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      5115\n",
      "   macro avg       0.58      0.50      0.42      5115\n",
      "weighted avg       0.61      0.66      0.54      5115\n",
      "\n",
      "[[  34 1704]\n",
      " [  33 3344]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.1544477028347996\n",
      "naive bayes has precision on testing 0.12703766160764474\n",
      "naive bayes has recall on testing 0.07538358905937291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.17      0.27      0.21      2117\n",
      "           1       0.13      0.08      0.09      2998\n",
      "\n",
      "   micro avg       0.15      0.15      0.15      5115\n",
      "   macro avg       0.15      0.17      0.15      5115\n",
      "weighted avg       0.14      0.15      0.14      5115\n",
      "\n",
      "[[ 564 1553]\n",
      " [2772  226]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8635386119257087\n",
      "svm has precision on validation 0.8390280941533789\n",
      "svm has recall on validation 0.9816405093278058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.63      0.76      1738\n",
      "           1       0.84      0.98      0.90      3377\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5115\n",
      "   macro avg       0.89      0.81      0.83      5115\n",
      "weighted avg       0.88      0.86      0.86      5115\n",
      "\n",
      "[[1102  636]\n",
      " [  62 3315]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8531769305962854\n",
      "svm has precision on testing 0.8194483935172021\n",
      "svm has recall on testing 0.9613075383589059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.70      0.80      2117\n",
      "           1       0.82      0.96      0.88      2998\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      5115\n",
      "   macro avg       0.87      0.83      0.84      5115\n",
      "weighted avg       0.86      0.85      0.85      5115\n",
      "\n",
      "[[1482  635]\n",
      " [ 116 2882]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8652981427174976\n",
      "random forest has precision on validation 0.8644251626898047\n",
      "random forest has recall on validation 0.9440331655315368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.71      0.78      1738\n",
      "           1       0.86      0.94      0.90      3377\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      5115\n",
      "   macro avg       0.87      0.83      0.84      5115\n",
      "weighted avg       0.87      0.87      0.86      5115\n",
      "\n",
      "[[1238  500]\n",
      " [ 189 3188]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8111436950146628\n",
      "random forest has precision on testing 0.8871951219512195\n",
      "random forest has recall on testing 0.7765176784523016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1821  296]\n",
      " [ 670 2328]]\n",
      "============================================================\n",
      "decision tree has accuracy on validation 0.7481915933528837\n",
      "decision tree has precision on validation 0.7499056959637872\n",
      "decision tree has recall on validation 0.7608113279755071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.74      0.74      2502\n",
      "           1       0.75      0.76      0.76      2613\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5115\n",
      "   macro avg       0.75      0.75      0.75      5115\n",
      "weighted avg       0.75      0.75      0.75      5115\n",
      "\n",
      "[[1839  663]\n",
      " [ 625 1988]]\n",
      "===========================\n",
      "decision tree has accuracy on testing 0.39530791788856307\n",
      "decision tree has precision on testing 0.48787337247893797\n",
      "decision tree has recall on testing 0.6374249499666444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.05      0.07      2117\n",
      "           1       0.49      0.64      0.55      2998\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      5115\n",
      "   macro avg       0.29      0.34      0.31      5115\n",
      "weighted avg       0.32      0.40      0.35      5115\n",
      "\n",
      "[[ 111 2006]\n",
      " [1087 1911]]\n",
      "============================================================\n",
      "log reg has accuracy on validation 0.773802541544477\n",
      "log reg has precision on validation 0.6980413492927094\n",
      "log reg has recall on validation 0.9820130118637581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.56      0.71      2502\n",
      "           1       0.70      0.98      0.82      2613\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5115\n",
      "   macro avg       0.83      0.77      0.76      5115\n",
      "weighted avg       0.83      0.77      0.76      5115\n",
      "\n",
      "[[1392 1110]\n",
      " [  47 2566]]\n",
      "===========================\n",
      "log reg has accuracy on testing 0.601564027370479\n",
      "log reg has precision on testing 0.5953516090584029\n",
      "log reg has recall on testing 0.9996664442961974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      0.04      0.07      2117\n",
      "           1       0.60      1.00      0.75      2998\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      5115\n",
      "   macro avg       0.79      0.52      0.41      5115\n",
      "weighted avg       0.76      0.60      0.47      5115\n",
      "\n",
      "[[  80 2037]\n",
      " [   1 2997]]\n",
      "============================================================\n",
      "naive bayes has accuracy on validation 0.5360703812316715\n",
      "naive bayes has precision on validation 0.5243210376976084\n",
      "naive bayes has recall on validation 0.9900497512437811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.06      0.12      2502\n",
      "           1       0.52      0.99      0.69      2613\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      5115\n",
      "   macro avg       0.69      0.53      0.40      5115\n",
      "weighted avg       0.69      0.54      0.41      5115\n",
      "\n",
      "[[ 155 2347]\n",
      " [  26 2587]]\n",
      "===========================\n",
      "naive bayes has accuracy on testing 0.18826979472140762\n",
      "naive bayes has precision on testing 0.07697947214076246\n",
      "naive bayes has recall on testing 0.03502334889926618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.23      0.41      0.29      2117\n",
      "           1       0.08      0.04      0.05      2998\n",
      "\n",
      "   micro avg       0.19      0.19      0.19      5115\n",
      "   macro avg       0.15      0.22      0.17      5115\n",
      "weighted avg       0.14      0.19      0.15      5115\n",
      "\n",
      "[[ 858 1259]\n",
      " [2893  105]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wuyue/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm has accuracy on validation 0.8269794721407625\n",
      "svm has precision on validation 0.7585278276481149\n",
      "svm has recall on validation 0.9701492537313433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.68      0.79      2502\n",
      "           1       0.76      0.97      0.85      2613\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.86      0.82      0.82      5115\n",
      "weighted avg       0.86      0.83      0.82      5115\n",
      "\n",
      "[[1695  807]\n",
      " [  78 2535]]\n",
      "===========================\n",
      "svm has accuracy on testing 0.8391006842619746\n",
      "svm has precision on testing 0.7977005201204489\n",
      "svm has recall on testing 0.9719813208805871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.65      0.77      2117\n",
      "           1       0.80      0.97      0.88      2998\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5115\n",
      "   macro avg       0.87      0.81      0.82      5115\n",
      "weighted avg       0.86      0.84      0.83      5115\n",
      "\n",
      "[[1378  739]\n",
      " [  84 2914]]\n",
      "============================================================\n",
      "random forest has accuracy on validation 0.8295210166177908\n",
      "random forest has precision on validation 0.7906510851419032\n",
      "random forest has recall on validation 0.9062380405663988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.75      0.81      2502\n",
      "           1       0.79      0.91      0.84      2613\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      5115\n",
      "   macro avg       0.84      0.83      0.83      5115\n",
      "weighted avg       0.84      0.83      0.83      5115\n",
      "\n",
      "[[1875  627]\n",
      " [ 245 2368]]\n",
      "===========================\n",
      "random forest has accuracy on testing 0.8109481915933529\n",
      "random forest has precision on testing 0.8871521158978269\n",
      "random forest has recall on testing 0.776184122748499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79      2117\n",
      "           1       0.89      0.78      0.83      2998\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      5115\n",
      "   macro avg       0.81      0.82      0.81      5115\n",
      "weighted avg       0.82      0.81      0.81      5115\n",
      "\n",
      "[[1821  296]\n",
      " [ 671 2327]]\n",
      "============================================================\n",
      "31.25366299999996 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.clock()\n",
    "\n",
    "dt_val_acc = []\n",
    "dt_testing_acc = []\n",
    "\n",
    "log_val_acc = []\n",
    "log_testing_acc = []\n",
    "\n",
    "nb_val_acc = []\n",
    "nb_testing_acc = []\n",
    "\n",
    "svm_val_acc = []\n",
    "svm_testing_acc = []\n",
    "\n",
    "rf_val_acc = []\n",
    "rf_testing_acc = []\n",
    "\n",
    "\n",
    "training_data_split = cut(data, 9)\n",
    "training_label_split = cut(training_label_total, 9)\n",
    "\n",
    "validation_data_split = cut(validation_data, 9)\n",
    "validation_label_split = cut(validation_label_total, 9)\n",
    "\n",
    "# print (training_data_split[2])\n",
    "\n",
    "for i in range (0, 9):\n",
    "    training_sub_list = []\n",
    "    training_sub_list.append(training_data_split[i])\n",
    "    training_sub_list.append(training_label_split[i])\n",
    "    \n",
    "    validation_sub_list = []\n",
    "    validation_sub_list.append(validation_data_split[i])\n",
    "    validation_sub_list.append(validation_label_split[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1 = tree.DecisionTreeClassifier()\n",
    "    dt_model = model1.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    dt_result = dt_model.predict(validation_sub_list[0])\n",
    "    dt_testing_result = dt_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"decision tree has accuracy on validation\", accuracy_score(validation_sub_list[-1], dt_result))\n",
    "    dt_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], dt_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on validation\", precision_score(validation_sub_list[-1], dt_result))\n",
    "    print (\"decision tree has recall on validation\", recall_score(validation_sub_list[-1], dt_result))\n",
    "    print (classification_report(validation_sub_list[-1], dt_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], dt_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"decision tree has accuracy on testing\", accuracy_score(testing_label_total, dt_testing_result))\n",
    "    dt_testing_acc.append(float(format(accuracy_score(testing_label_total, dt_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"decision tree has precision on testing\", precision_score(testing_label_total, dt_testing_result))\n",
    "    print (\"decision tree has recall on testing\", recall_score(testing_label_total, dt_testing_result))\n",
    "    print (classification_report(testing_label_total, dt_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, dt_testing_result))    \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model2 = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr')\n",
    "    log_model = model2.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    log_result = log_model.predict(validation_sub_list[0])\n",
    "    log_testing_result = log_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"log reg has accuracy on validation\", accuracy_score(validation_sub_list[-1], log_result))\n",
    "    log_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], log_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on validation\", precision_score(validation_sub_list[-1], log_result))\n",
    "    print (\"log reg has recall on validation\", recall_score(validation_sub_list[-1], log_result))\n",
    "    print (classification_report(validation_sub_list[-1], log_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], log_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"log reg has accuracy on testing\", accuracy_score(testing_label_total, log_testing_result))\n",
    "    log_testing_acc.append(float(format(accuracy_score(testing_label_total, log_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"log reg has precision on testing\", precision_score(testing_label_total, log_testing_result))\n",
    "    print (\"log reg has recall on testing\", recall_score(testing_label_total, log_testing_result))\n",
    "    print (classification_report(testing_label_total, log_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, log_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "   \n",
    "\n",
    "    \n",
    "    model3 = GaussianNB()\n",
    "    nb_model = model3.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    nb_result = nb_model.predict(validation_sub_list[0])\n",
    "    nb_testing_result = nb_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"naive bayes has accuracy on validation\", accuracy_score(validation_sub_list[-1], nb_result))\n",
    "    nb_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], nb_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on validation\", precision_score(validation_sub_list[-1], nb_result))\n",
    "    print (\"naive bayes has recall on validation\", recall_score(validation_sub_list[-1], nb_result))\n",
    "    print (classification_report(validation_sub_list[-1], nb_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], nb_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"naive bayes has accuracy on testing\", accuracy_score(testing_label_total, nb_testing_result))\n",
    "    nb_testing_acc.append(float(format(accuracy_score(testing_label_total, nb_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"naive bayes has precision on testing\", precision_score(testing_label_total, nb_testing_result))\n",
    "    print (\"naive bayes has recall on testing\", recall_score(testing_label_total, nb_testing_result))\n",
    "    print (classification_report(testing_label_total, nb_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, nb_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model4 = LinearSVC(random_state=0, tol=1e-5)\n",
    "    svm_model = model4.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    svm_result = svm_model.predict(validation_sub_list[0])\n",
    "    svm_testing_result = svm_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"svm has accuracy on validation\", accuracy_score(validation_sub_list[-1], svm_result))\n",
    "    svm_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], svm_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on validation\", precision_score(validation_sub_list[-1], svm_result))\n",
    "    print (\"svm has recall on validation\", recall_score(validation_sub_list[-1], svm_result))\n",
    "    print (classification_report(validation_sub_list[-1], svm_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], svm_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"svm has accuracy on testing\", accuracy_score(testing_label_total, svm_testing_result))\n",
    "    svm_testing_acc.append(float(format(accuracy_score(testing_label_total, svm_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"svm has precision on testing\", precision_score(testing_label_total, svm_testing_result))\n",
    "    print (\"svm has recall on testing\", recall_score(testing_label_total, svm_testing_result))\n",
    "    print (classification_report(testing_label_total, svm_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, svm_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model5 = RandomForestClassifier(n_estimators=500, max_depth=2, random_state=0)\n",
    "    rf_model = model5.fit(training_sub_list[0], training_sub_list[-1])\n",
    "    rf_result = rf_model.predict(validation_sub_list[0])\n",
    "    rf_testing_result = rf_model.predict(testing_data_total)\n",
    "    \n",
    "    print (\"random forest has accuracy on validation\", accuracy_score(validation_sub_list[-1], rf_result))\n",
    "    rf_val_acc.append(float(format(accuracy_score(validation_sub_list[-1], rf_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on validation\", precision_score(validation_sub_list[-1], rf_result))\n",
    "    print (\"random forest has recall on validation\", recall_score(validation_sub_list[-1], rf_result))\n",
    "    print (classification_report(validation_sub_list[-1], rf_result))\n",
    "    print (confusion_matrix(validation_sub_list[-1], rf_result))\n",
    "    print (\"===========================\")\n",
    "    print (\"random forest has accuracy on testing\", accuracy_score(testing_label_total, rf_testing_result))\n",
    "    rf_testing_acc.append(float(format(accuracy_score(testing_label_total, rf_testing_result), '.3f')))\n",
    "    \n",
    "    print (\"random forest has precision on testing\", precision_score(testing_label_total, rf_testing_result))\n",
    "    print (\"random forest has recall on testing\", recall_score(testing_label_total, rf_testing_result))\n",
    "    print (classification_report(testing_label_total, rf_testing_result))\n",
    "    print (confusion_matrix(testing_label_total, rf_testing_result)) \n",
    "    print (\"============================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "end = time.clock()\n",
    "print ((end-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.756, 0.793, 0.755, 0.782, 0.794, 0.782, 0.777, 0.804, 0.748]\n",
      "[0.764, 0.812, 0.712, 0.426, 0.743, 0.589, 0.186, 0.464, 0.395] "
     ]
    }
   ],
   "source": [
    "print (dt_val_acc, end = \"\\n\")\n",
    "print (dt_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773, 0.862, 0.782, 0.66, 0.828, 0.804, 0.799, 0.871, 0.774]\n",
      "[0.622, 0.839, 0.645, 0.674, 0.64, 0.65, 0.66, 0.605, 0.602] "
     ]
    }
   ],
   "source": [
    "print (log_val_acc, end = \"\\n\")\n",
    "print (log_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.451, 0.554, 0.587, 0.656, 0.682, 0.686, 0.738, 0.66, 0.536]\n",
      "[0.414, 0.415, 0.41, 0.586, 0.411, 0.414, 0.414, 0.154, 0.188] "
     ]
    }
   ],
   "source": [
    "print (nb_val_acc, end = \"\\n\")\n",
    "print (nb_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.774, 0.798, 0.78, 0.854, 0.83, 0.808, 0.801, 0.864, 0.827]\n",
      "[0.625, 0.596, 0.629, 0.611, 0.635, 0.648, 0.637, 0.853, 0.839] "
     ]
    }
   ],
   "source": [
    "print (svm_val_acc, end = \"\\n\")\n",
    "print (svm_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.784, 0.82, 0.802, 0.87, 0.835, 0.821, 0.819, 0.865, 0.83]\n",
      "[0.811, 0.811, 0.811, 0.811, 0.811, 0.811, 0.811, 0.811, 0.811] "
     ]
    }
   ],
   "source": [
    "print (rf_val_acc, end = \"\\n\")\n",
    "print (rf_testing_acc, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
